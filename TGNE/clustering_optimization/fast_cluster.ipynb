{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelbertagna/anaconda3/envs/debug_tgne.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import scipy.stats as st\n",
    "import scipy.spatial\n",
    "import scipy.cluster.hierarchy\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "import umap\n",
    "# import pymde\n",
    "\n",
    "# import torch\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import bokeh\n",
    "from bokeh.plotting import show as show_interactive, output_file, output_notebook\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import (\n",
    "    CustomJS,\n",
    "    TextInput,\n",
    "    LassoSelectTool,\n",
    "    Select,\n",
    "    MultiSelect,\n",
    "    ColorBar,\n",
    "    Legend,\n",
    "    LegendItem,\n",
    "    DataTable,\n",
    "    DateFormatter,\n",
    "    TableColumn,\n",
    "    Button,\n",
    "    HTMLTemplateFormatter,\n",
    "    FactorRange,\n",
    ")\n",
    "from bokeh.events import SelectionGeometry\n",
    "from bokeh.transform import linear_cmap, jitter\n",
    "\n",
    "from matplotlib.pyplot import show as show_static\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from pynndescent import NNDescent\n",
    "\n",
    "from csv import DictWriter\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20326, 20327)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>TTHERM_000000042</th>\n",
       "      <th>TTHERM_000000045</th>\n",
       "      <th>TTHERM_00000010</th>\n",
       "      <th>TTHERM_00000020</th>\n",
       "      <th>TTHERM_00000030</th>\n",
       "      <th>TTHERM_00000040</th>\n",
       "      <th>TTHERM_00000070</th>\n",
       "      <th>TTHERM_000001189</th>\n",
       "      <th>TTHERM_000001241</th>\n",
       "      <th>...</th>\n",
       "      <th>TTHERM_02091560</th>\n",
       "      <th>TTHERM_02094560</th>\n",
       "      <th>TTHERM_02096560</th>\n",
       "      <th>TTHERM_02105572</th>\n",
       "      <th>TTHERM_02272860</th>\n",
       "      <th>TTHERM_02293890</th>\n",
       "      <th>TTHERM_02385080</th>\n",
       "      <th>TTHERM_02555200</th>\n",
       "      <th>TTHERM_02607240</th>\n",
       "      <th>TTHERM_02653470</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.506963</td>\n",
       "      <td>2.200162</td>\n",
       "      <td>1.766007</td>\n",
       "      <td>0.046840</td>\n",
       "      <td>0.225868</td>\n",
       "      <td>1.825975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325549</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403905</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326196</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.019517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>1.506963</td>\n",
       "      <td>0.863134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.829012</td>\n",
       "      <td>2.493440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349718</td>\n",
       "      <td>1.912393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.474013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.268221</td>\n",
       "      <td>1.130958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>0.143249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>2.200162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.829012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.052325</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>2.813094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000030</td>\n",
       "      <td>1.766007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.493440</td>\n",
       "      <td>3.052325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.678441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.858570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471134</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  TTHERM_000000042  TTHERM_000000045  TTHERM_00000010  \\\n",
       "0  TTHERM_000000042          0.000000          0.000000         1.506963   \n",
       "1  TTHERM_000000045          0.000000          0.000000         0.863134   \n",
       "2   TTHERM_00000010          1.506963          0.863134         0.000000   \n",
       "3   TTHERM_00000020          2.200162          0.000000         2.829012   \n",
       "4   TTHERM_00000030          1.766007          0.000000         2.493440   \n",
       "\n",
       "   TTHERM_00000020  TTHERM_00000030  TTHERM_00000040  TTHERM_00000070  \\\n",
       "0         2.200162         1.766007         0.046840         0.225868   \n",
       "1         0.000000         0.000000         0.000000         0.403905   \n",
       "2         2.829012         2.493440         0.000000         0.349718   \n",
       "3         0.000000         3.052325         0.497379         0.398990   \n",
       "4         3.052325         0.000000         2.678441         0.000000   \n",
       "\n",
       "   TTHERM_000001189  TTHERM_000001241  ...  TTHERM_02091560  TTHERM_02094560  \\\n",
       "0          1.825975          0.000000  ...         0.000000              0.0   \n",
       "1          0.203517          0.003814  ...         0.000000              0.0   \n",
       "2          1.912393          0.000000  ...         0.686328              0.0   \n",
       "3          2.813094          0.000000  ...         1.230303              0.0   \n",
       "4          2.858570          0.000000  ...         0.000000              0.0   \n",
       "\n",
       "   TTHERM_02096560  TTHERM_02105572  TTHERM_02272860  TTHERM_02293890  \\\n",
       "0         0.000000              0.0         0.000000         0.000000   \n",
       "1         0.000000              0.0         0.326196         0.078071   \n",
       "2         1.474013              0.0         0.000000         1.268221   \n",
       "3         0.000000              0.0         0.000000         0.000000   \n",
       "4         0.369241              0.0         0.000000         0.000000   \n",
       "\n",
       "   TTHERM_02385080  TTHERM_02555200  TTHERM_02607240  TTHERM_02653470  \n",
       "0         0.000000         0.000000         1.325549         0.000000  \n",
       "1         0.019517         0.000000         0.000000         0.000000  \n",
       "2         1.130958         0.000000         0.040282         0.143249  \n",
       "3         0.000000         0.000000         0.000000         0.000000  \n",
       "4         0.000000         0.471134         0.070106         0.000000  \n",
       "\n",
       "[5 rows x 20327 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.read_csv('./clr_network_for_distances.csv')\n",
    "clr_df.rename(columns={'Unnamed: 0':'TTHERM_ID'}, inplace=True)\n",
    "print(clr_df.shape)\n",
    "clr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.2832981872387"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_zscore = clr_df.max(axis=None, numeric_only=True)\n",
    "max_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_zscore = clr_df.min(axis=None, numeric_only=True)\n",
    "min_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.50696259, ..., 0.        , 1.32554853,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.8631345 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.50696259, 0.8631345 , 0.        , ..., 0.        , 0.04028212,\n",
       "        0.14324939],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.83724257,\n",
       "        2.20228469],\n",
       "       [1.32554853, 0.        , 0.04028212, ..., 1.83724257, 0.        ,\n",
       "        0.20059729],\n",
       "       [0.        , 0.        , 0.14324939, ..., 2.20228469, 0.20059729,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore_arr = clr_df.loc[:,clr_df.columns[1:]].to_numpy()\n",
    "zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0, ..., 20325, 20325, 20325]),\n",
       " array([    0,     1,     8, ..., 20317, 20318, 20325]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_zscore_idxs = np.where(zscore_arr == 0)\n",
    "zero_zscore_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177366646,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_zscore_idxs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/xzj6jd1x4d9cy2w36g2v23b00000gn/T/ipykernel_32081/929516180.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  inverse_zscore_arr = 1 / zscore_arr\n"
     ]
    }
   ],
   "source": [
    "inverse_zscore_arr = 1 / zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        inf,         inf,  0.66358648, ...,         inf,\n",
       "         0.75440467,         inf],\n",
       "       [        inf,         inf,  1.15856799, ...,         inf,\n",
       "                inf,         inf],\n",
       "       [ 0.66358648,  1.15856799,         inf, ...,         inf,\n",
       "        24.82490999,  6.98083234],\n",
       "       ...,\n",
       "       [        inf,         inf,         inf, ...,         inf,\n",
       "         0.54429394,  0.4540739 ],\n",
       "       [ 0.75440467,         inf, 24.82490999, ...,  0.54429394,\n",
       "                inf,  4.9851121 ],\n",
       "       [        inf,         inf,  6.98083234, ...,  0.4540739 ,\n",
       "         4.9851121 ,         inf]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177366646"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(inverse_zscore_arr == float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_2d_arr(arr: np.array):\n",
    "\n",
    "    flat_arr = arr.flatten()\n",
    "\n",
    "    non_inf_mask = flat_arr != float('inf')\n",
    "\n",
    "    max_val = max(flat_arr[non_inf_mask])\n",
    "    min_val = min(flat_arr)\n",
    "\n",
    "    print(max_val)\n",
    "    print(min_val)\n",
    "\n",
    "    scaled_arr = (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74455098.3625645\n",
      "0.03955180184936206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[           inf,            inf, 8.38135591e-09, ...,\n",
       "                   inf, 9.60112714e-09,            inf],\n",
       "       [           inf,            inf, 1.50294099e-08, ...,\n",
       "                   inf,            inf,            inf],\n",
       "       [8.38135591e-09, 1.50294099e-08,            inf, ...,\n",
       "                   inf, 3.32890007e-07, 9.32277399e-08],\n",
       "       ...,\n",
       "       [           inf,            inf,            inf, ...,\n",
       "                   inf, 6.77914812e-09, 5.56741054e-09],\n",
       "       [9.60112714e-09,            inf, 3.32890007e-07, ...,\n",
       "        6.77914812e-09,            inf, 6.64233936e-08],\n",
       "       [           inf,            inf, 9.32277399e-08, ...,\n",
       "        5.56741054e-09, 6.64233936e-08,            inf]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inverse_zscore_arr = min_max_scale_2d_arr(inverse_zscore_arr)\n",
    "scaled_inverse_zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177366646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(scaled_inverse_zscore_arr == float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0, ..., 20325, 20325, 20325]),\n",
       " array([    0,     1,     8, ..., 20317, 20318, 20325]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(scaled_inverse_zscore_arr == float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(zero_zscore_idxs[0])):\n",
    "    scaled_inverse_zscore_arr[zero_zscore_idxs[0][idx]][zero_zscore_idxs[1][idx]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.00000000e+00, 8.38135591e-09, ...,\n",
       "        1.00000000e+00, 9.60112714e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.50294099e-08, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [8.38135591e-09, 1.50294099e-08, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 3.32890007e-07, 9.32277399e-08],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 6.77914812e-09, 5.56741054e-09],\n",
       "       [9.60112714e-09, 1.00000000e+00, 3.32890007e-07, ...,\n",
       "        6.77914812e-09, 1.00000000e+00, 6.64233936e-08],\n",
       "       [1.00000000e+00, 1.00000000e+00, 9.32277399e-08, ...,\n",
       "        5.56741054e-09, 6.64233936e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inverse_zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15819, 19949]), array([19949, 15819]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(scaled_inverse_zscore_arr == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(scaled_inverse_zscore_arr == float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale zscores linearly from 0 to 1\n",
    "\n",
    "\n",
    "# distance metric of 1/zscore\n",
    "\n",
    "\n",
    "# 1/zscore for everything not zero, scale 0 to 1 linearly, assign 1s to previous zeros\n",
    "\n",
    "inverted_zscore_arr = (max_zscore + min_zscore) - zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_zscore_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_zscore_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(inverted_zscore_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inverted_zscore_arr.shape[0] * inverted_zscore_arr.shape[1]) - np.count_nonzero(inverted_zscore_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_idxs = np.where(inverted_zscore_arr == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "nonzero_inverted_zscore_arr = copy.deepcopy(inverted_zscore_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_pair in zero_idxs:\n",
    "    nonzero_inverted_zscore_arr[idx_pair[0]][idx_pair[1]] = 1e-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(nonzero_inverted_zscore_arr == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(nonzero_inverted_zscore_arr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_row(row):\n",
    "    shuffled_row = row.values.copy()\n",
    "    np.random.shuffle(shuffled_row)\n",
    "    return pd.Series(shuffled_row, index=row.index)\n",
    "\n",
    "def shuffle_rows(df):\n",
    "    columns_to_shuffle = df.columns[1:]\n",
    "    df[columns_to_shuffle] = df[columns_to_shuffle].apply(shuffle_row, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom_mean_expression(expression_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to take an expression dataframe from the microarrays and collapse it into the means of\n",
    "    all replicate chips.\n",
    "    \"\"\"\n",
    "    # C2 and S12 got removed during quality control\n",
    "    x = [\n",
    "        'Ll', \n",
    "        'Lm', \n",
    "        'Lh', \n",
    "        'S0', \n",
    "        'S3', \n",
    "        'S6', \n",
    "        'S9', \n",
    "        # 'S12', \n",
    "        'S15', \n",
    "        'S24', \n",
    "        'C0', \n",
    "        # 'C2', \n",
    "        'C4', \n",
    "        'C6', \n",
    "        'C8', \n",
    "        'C10', \n",
    "        'C12', \n",
    "        'C14', \n",
    "        'C16', \n",
    "        'C18']\n",
    "    \n",
    "    # cols = expression_df.columns[1:]\n",
    "    # x = [c for c in x if c in cols]\n",
    "    \n",
    "    condition_expr_dict = {c.split(\"_\")[0]: [] for c in expression_df.columns[1:]}\n",
    "    \n",
    "    for c in list(expression_df.columns)[1:]:\n",
    "        \n",
    "        cond = c.split('_')[0]\n",
    "        if cond in condition_expr_dict.keys():\n",
    "            expr_list = condition_expr_dict.get(cond, [])\n",
    "\n",
    "            # Need to avoid true zeros\n",
    "            expr_list.append(expression_df[c].values)\n",
    "            condition_expr_dict[cond] = expr_list\n",
    "        \n",
    "    condition_mean_dict = {c: (st.mstats.gmean(np.array(condition_expr_dict[c]) + 1, 0) - 1) for c in condition_expr_dict.keys() if c in x}\n",
    "    \n",
    "    mean_expr_df = pd.DataFrame(condition_mean_dict)\n",
    "    mean_expr_df['TTHERM_ID'] = expression_df['TTHERM_ID'].values\n",
    "    cols = list(mean_expr_df.columns)\n",
    "    reorder = cols[-1:] + cols[:-1]\n",
    "    mean_expr_df = mean_expr_df[reorder]\n",
    "    \n",
    "    return mean_expr_df\n",
    "\n",
    "def normalizer(array):\n",
    "    \"\"\"\n",
    "    Normalizes the values of an array to range from zero to one\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(array)\n",
    "    \n",
    "    normalized = (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_expression_per_gene(expression_df):\n",
    "    \"\"\"\n",
    "    Function to normalize all gene expression to range from zero to one.\n",
    "    \"\"\"\n",
    "    if 'TTHERM_ID' in expression_df.columns:\n",
    "        ttids = expression_df['TTHERM_ID'].values\n",
    "        data = expression_df[list(expression_df.columns)[1:]]\n",
    "        \n",
    "        norm_expression_df = data.apply(lambda row: normalizer(row), axis=1)\n",
    "        norm_expression_df['TTHERM_ID'] = ttids\n",
    "        \n",
    "        columns = norm_expression_df.columns.tolist()\n",
    "        \n",
    "        rearrangment = columns[-1:] + columns[:-1]\n",
    "        \n",
    "        norm_expression_df = norm_expression_df[rearrangment]\n",
    "        \n",
    "    else:\n",
    "        norm_expression_df = expression_df.apply(lambda row: normalizer(row), axis=1)\n",
    "    \n",
    "    return norm_expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_distance_matrix(data_df, metric, n_jobs=-1, p_minkowski=1):\n",
    "\n",
    "    if metric == 'minkowski':\n",
    "        pair_dists = pairwise_distances(data_df, metric=metric, n_jobs=n_jobs, p=p_minkowski)\n",
    "    else:\n",
    "        pair_dists = pairwise_distances(data_df, metric=metric, n_jobs=n_jobs)\n",
    "    \n",
    "    return pair_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nns(data_df, nn, metric, random_state=42, n_jobs=-1, p_minkowski=1, distance_matrix=None):\n",
    "    \n",
    "    # if metric == 'clr':\n",
    "    num_neighbors = NearestNeighbors(n_neighbors=nn-1, metric='precomputed', n_jobs=-1).fit(distance_matrix)\n",
    "    nn_dists, nn_idxs = num_neighbors.kneighbors(return_distance=True)\n",
    "\n",
    "    nn_dists_list = []\n",
    "    nn_idxs_list = []\n",
    "\n",
    "    # add the node itself to the nearest neighbors data \n",
    "    for idx in range(len(nn_dists)):\n",
    "        nn_dists_list.append(np.flip(np.append(np.flip(nn_dists[idx]), 0)))\n",
    "        nn_idxs_list.append(np.flip(np.append(np.flip(nn_idxs[idx]), idx)))\n",
    "\n",
    "    return np.array(nn_idxs_list), np.array(nn_dists_list)\n",
    "\n",
    "\n",
    "    # n_trees = min(64, 5 + int(round((data_df.shape[0]) ** 0.5 / 20.0)))\n",
    "    # n_iters = max(5, int(round(np.log2(data_df.shape[0]))))\n",
    "\n",
    "    # if metric == 'minkowski':\n",
    "    #     knn_search_index = NNDescent(\n",
    "    #             data_df,\n",
    "    #             n_neighbors=nn,\n",
    "    #             metric=metric,\n",
    "    #             metric_kwds={'p': p_minkowski},\n",
    "    #             random_state=random_state,\n",
    "    #             n_trees=n_trees,\n",
    "    #             n_iters=n_iters,\n",
    "    #             max_candidates=60,\n",
    "    #             # low_memory=low_memory,\n",
    "    #             n_jobs=n_jobs,\n",
    "    #             verbose=False,\n",
    "    #             compressed=False,\n",
    "    #         )\n",
    "    # else:\n",
    "    #     knn_search_index = NNDescent(\n",
    "    #                 data_df,\n",
    "    #                 n_neighbors=nn,\n",
    "    #                 metric=metric,\n",
    "    #                 # metric_kwds=metric_kwds,\n",
    "    #                 random_state=random_state,\n",
    "    #                 n_trees=n_trees,\n",
    "    #                 n_iters=n_iters,\n",
    "    #                 max_candidates=60,\n",
    "    #                 # low_memory=low_memory,\n",
    "    #                 n_jobs=n_jobs,\n",
    "    #                 verbose=False,\n",
    "    #                 compressed=False,\n",
    "    #             )\n",
    "    # nn_idxs, nn_dists = knn_search_index.neighbor_graph\n",
    "\n",
    "    # return nn_idxs, nn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anns(data_df, nn, metric, random_state=42, n_jobs=-1, p_minkowski=1, distance_matrix=None):\n",
    "\n",
    "    n_trees = min(64, 5 + int(round((data_df.shape[0]) ** 0.5 / 20.0)))\n",
    "    n_iters = max(5, int(round(np.log2(data_df.shape[0]))))\n",
    "\n",
    "    if metric == 'minkowski':\n",
    "        knn_search_index = NNDescent(\n",
    "                data_df,\n",
    "                n_neighbors=nn,\n",
    "                metric=metric,\n",
    "                metric_kwds={'p': p_minkowski},\n",
    "                random_state=random_state,\n",
    "                n_trees=n_trees,\n",
    "                n_iters=n_iters,\n",
    "                max_candidates=60,\n",
    "                # low_memory=low_memory,\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=False,\n",
    "                compressed=False,\n",
    "            )\n",
    "    else:\n",
    "        knn_search_index = NNDescent(\n",
    "                    data_df,\n",
    "                    n_neighbors=nn,\n",
    "                    metric=metric,\n",
    "                    # metric_kwds=metric_kwds,\n",
    "                    random_state=random_state,\n",
    "                    n_trees=n_trees,\n",
    "                    n_iters=n_iters,\n",
    "                    max_candidates=60,\n",
    "                    # low_memory=low_memory,\n",
    "                    n_jobs=n_jobs,\n",
    "                    verbose=False,\n",
    "                    compressed=False,\n",
    "                )\n",
    "    nn_idxs, nn_dists = knn_search_index.neighbor_graph\n",
    "\n",
    "    return nn_idxs, nn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_umap_graph(data_df, nn, metric, nn_idxs, nn_dists):\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data_df, nn, 42, metric, knn_indices=nn_idxs, knn_dists=nn_dists, return_dists=True)\n",
    "\n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "\n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leiden_partition(graph, resolution_parameter, random_state=42):\n",
    "        \n",
    "        partition = la.find_partition(graph, la.CPMVertexPartition, resolution_parameter = resolution_parameter, seed=random_state, weights='weight')\n",
    "        # partition = la.find_partition(g, la.ModularityVertexPartition, seed=42, weights='weight')\n",
    "\n",
    "        leiden_modules = np.array(partition.membership)\n",
    "\n",
    "        return leiden_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_communities(parition, idx_labels):\n",
    "    communities = {}\n",
    "\n",
    "    for idx, membership in enumerate(parition):\n",
    "        if membership not in communities:\n",
    "            communities[membership] = []\n",
    "        communities[membership].append(idx_labels[idx])\n",
    "\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_silhouette_score(distance_matrix, parition):\n",
    "    return silhouette_score(distance_matrix, parition, metric='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_modularity(graph, communities):\n",
    "    nx_g = nx.Graph(graph.get_edgelist())\n",
    "    return nx.community.quality.modularity(nx_g, communities, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_parition_for_enrichment(df, parition):\n",
    "    edf = pd.DataFrame.from_dict({'TTHERM_ID': []})\n",
    "    edf['TTHERM_ID'] = df['TTHERM_ID'].values\n",
    "    edf[f'leiden_label_full'] = parition\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment(df, parition):\n",
    "    edf = format_parition_for_enrichment(df, parition)\n",
    "\n",
    "    temp_scan_file = './temp_scan_partition.csv'\n",
    "\n",
    "    temp_enrich_file = './temp_scan_enrich.csv'\n",
    "\n",
    "    edf.to_csv(temp_scan_file, index=False)\n",
    "\n",
    "    subprocess.run(['python3', './fast_enrichment_analysis.py', temp_scan_file, temp_enrich_file])\n",
    "\n",
    "    cedf = pd.read_csv(temp_enrich_file)\n",
    "    \n",
    "    remove_file(temp_scan_file)\n",
    "\n",
    "    remove_file(temp_enrich_file)\n",
    "\n",
    "    return cedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_clusters(parition, communities=None):\n",
    "    if communities is None:\n",
    "        return len(set(parition))\n",
    "    \n",
    "    if len(set(parition)) != len(communities):\n",
    "        raise ValueError(f'The number of clusters/modules ({len(set(parition))}) in the parition != the number of communities ({len(communities)}).')\n",
    "    \n",
    "    return len(set(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_sizes(communities):\n",
    "    return [len(community) for community in communities.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enriched_cluster_sizes(communities, cedf):\n",
    "    enriched_cluster_mods = set(cedf['module'].values)\n",
    "    return [len(community) for mod, community in communities.items() if mod in enriched_cluster_mods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_size_mean(cluster_sizes):\n",
    "    return np.mean(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_median(cluster_sizes):\n",
    "    return np.median(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_sd(cluster_sizes):\n",
    "    return np.std(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_sd(cluster_sizes):\n",
    "    return np.std(cluster_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_clusters(cedf):\n",
    "    return len(set(cedf['module'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_cluster_genes(edf, parition):\n",
    "    total_num_genes = 0\n",
    "\n",
    "    for m in set(edf['module'].values):\n",
    "        num_genes = np.count_nonzero(parition == int(m))\n",
    "        total_num_genes += num_genes\n",
    "    \n",
    "    return total_num_genes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(csv_file_path, data_item, header):\n",
    "    # Check if the CSV file exists and write header if it doesn't\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        with open(csv_file_path, 'w', newline='') as file:\n",
    "            writer = DictWriter(file, fieldnames=header)\n",
    "            writer.writeheader()\n",
    "\n",
    "    with open(csv_file_path, 'a', newline='') as file:\n",
    "        writer = DictWriter(file, fieldnames=header)\n",
    "        writer.writerow(data_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTER START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_type = 'EXP'\n",
    "num_iterations = 1\n",
    "full_filtered_df = pd.read_csv('../microarray_probe_alignment_and_filtering/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')\n",
    "full_filtered_df = full_filtered_df.rename(columns={'Unnamed: 0': 'TTHERM_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# X, _ = make_blobs(n_samples=10000, n_features=30, centers=350, cluster_std=1.0, random_state=42)  # Use only 2 features\n",
    "# # Convert X to a DataFrame\n",
    "# columns = ['feature' + str(i) for i in range(X.shape[1])]\n",
    "# df = pd.DataFrame(X, columns=columns)\n",
    "# raw_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 47\n",
    "\n",
    "sampler = st.qmc.LatinHypercube(d=dimensions)\n",
    "# sampler = st.qmc.Sobol(d=dimensions)\n",
    "hypercube_sample = sampler.random(n=20326)\n",
    "\n",
    "hypercube_sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hypercube_sample[1234], hypercube_sample[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_cores():\n",
    "    # If you're using Linux or macOS\n",
    "    if os.name == 'posix':\n",
    "        return os.cpu_count()\n",
    "\n",
    "    # If you're using Windows\n",
    "    elif os.name == 'nt':\n",
    "        return multiprocessing.cpu_count()\n",
    "\n",
    "    # If the operating system is not recognized\n",
    "    else:\n",
    "        return \"Unable to determine the number of CPU cores.\"\n",
    "\n",
    "# Get and print the number of CPU cores\n",
    "num_cores = get_cpu_cores()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_half_to_even(number):\n",
    "    return number // 4 * 2\n",
    "\n",
    "num_workers = floor_half_to_even(num_cores)\n",
    "num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.qmc.discrepancy(hypercube_sample, workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'manhattan'\n",
    "p_minkowski = 0.5\n",
    "n_jobs = -1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 5\n",
    "# nn = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = 0.035\n",
    "# rp = 0.030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_iterations = 100\n",
    "# partition_type = 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in tqdm.tqdm(range(num_iterations)):\n",
    "# for p_minkowski in np.arange(1.1, 2.1, 0.1):\n",
    "    \n",
    "    if partition_type == 'NC':\n",
    "        full_filtered_df = shuffle_rows(full_filtered_df)\n",
    "        \n",
    "    full_filtered_norm_df = normalize_expression_per_gene(full_filtered_df)\n",
    "    \n",
    "    raw_data = full_filtered_norm_df[list(full_filtered_norm_df.columns)[1:]].values\n",
    "    # partition_type = 'TNC'\n",
    "    # raw_data = pd.DataFrame(hypercube_sample)\n",
    "\n",
    "    idx_labels = list(range(raw_data.shape[0]))\n",
    "\n",
    "\n",
    "    distance_matrix = compute_pairwise_distance_matrix(raw_data, metric, n_jobs, p_minkowski)\n",
    "    # distance_matrix = nonzero_inverted_zscore_arr\n",
    "\n",
    "    ann_idxs, ann_dists = compute_anns(raw_data, nn, metric, random_state, n_jobs, p_minkowski, distance_matrix)\n",
    "\n",
    "    nn_idxs, nn_dists = compute_nns(raw_data, nn, metric, random_state, n_jobs, p_minkowski, distance_matrix)\n",
    "\n",
    "    nn_graph = compute_umap_graph(raw_data, nn, metric, ann_idxs, ann_dists)\n",
    "\n",
    "    parition = compute_leiden_partition(nn_graph, rp, random_state)\n",
    "\n",
    "    communities = compute_communities(parition, idx_labels)\n",
    "\n",
    "    sil_score = compute_silhouette_score(distance_matrix, parition)\n",
    "\n",
    "    modularity = compute_modularity(nn_graph, communities.values())\n",
    "\n",
    "    enrichment_df = compute_enrichment(full_filtered_norm_df, parition)\n",
    "\n",
    "    num_clusters = compute_num_clusters(parition, communities.values())\n",
    "\n",
    "    num_enriched_clusters = compute_num_enriched_clusters(enrichment_df)\n",
    "\n",
    "    num_enriched_cluster_genes = compute_num_enriched_cluster_genes(enrichment_df, parition)\n",
    "\n",
    "    cluster_sizes = compute_cluster_sizes(communities)\n",
    "\n",
    "    enriched_cluster_sizes = compute_enriched_cluster_sizes(communities, enrichment_df)\n",
    "\n",
    "    cluster_stats = {\n",
    "    'partition_type': partition_type,\n",
    "\n",
    "    'dimensionality': 'baseline',\n",
    "\n",
    "    'metric': metric,\n",
    "    # 'metric': 'clr',\n",
    "    'graph': 'umap_fuzzy_simplicial_set',\n",
    "    'nns': nn,\n",
    "\n",
    "    'clustering': 'leiden_cpm',\n",
    "    'parameter': rp,\n",
    "\n",
    "    'silhouette_score': sil_score,\n",
    "    'modularity': modularity,\n",
    "\n",
    "    'nclusters': num_clusters,\n",
    "    'mean_cluster_size': compute_cluster_size_mean(cluster_sizes),\n",
    "    'median_cluster_size': compute_cluster_size_median(cluster_sizes),\n",
    "    'sd_cluster_size': compute_cluster_size_sd(cluster_sizes),\n",
    "\n",
    "    'nenriched_clusters': num_enriched_clusters,\n",
    "    'mean_enriched_cluster_size': compute_cluster_size_mean(enriched_cluster_sizes),\n",
    "    'median_enriched_cluster_size': compute_cluster_size_median(enriched_cluster_sizes),\n",
    "    'sd_enriched_cluster_size': compute_cluster_size_sd(enriched_cluster_sizes),\n",
    "    'nenriched_cluster_genes': num_enriched_cluster_genes,\n",
    "\n",
    "    'datetime': curr_datetime\n",
    "    }\n",
    "\n",
    "    # write_to_csv('./scan_stats_v1.csv', cluster_stats, list(cluster_stats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_enriched_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_enriched_cluster_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_module_assignments(all_gene_labels, gene_list, parition):\n",
    "    gene_module_assignments = {}\n",
    "\n",
    "    for gene in gene_list:\n",
    "        if gene not in all_gene_labels:\n",
    "            raise ValueError(f'The gene {gene} is not in the list of all gene labels.')\n",
    "        gene_idx = all_gene_labels.index(gene)\n",
    "        module_num = parition[gene_idx]\n",
    "        if module_num not in gene_module_assignments:\n",
    "            gene_module_assignments[module_num] = []\n",
    "        gene_module_assignments[module_num].append(gene)\n",
    "\n",
    "    return gene_module_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_1 = [\"TTHERM_01055600\", \"TTHERM_01002870\", \"TTHERM_01002860\", \"TTHERM_00630470\", \"TTHERM_00624730\", \"TTHERM_00624720\", \"TTHERM_00527180\", \"TTHERM_00522600\", \"TTHERM_00378890\", \"TTHERM_00335830\", \"TTHERM_00221120\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_2 = [\"TTHERM_00420610\", \"TTHERM_00410210\", \"TTHERM_00313130\", \"TTHERM_00467390\"]\n",
    "#                                                                       MAYBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_3 = [\"TTHERM_01107420\", \"TTHERM_01004990\", \"TTHERM_00985020\", \"TTHERM_00899470\", \"TTHERM_00865150\", \"TTHERM_00858130\", \"TTHERM_00849480\", \"TTHERM_00829340\", \"TTHERM_00780750\", \"TTHERM_00716180\", \"TTHERM_00704030\", \"TTHERM_00691170\", \"TTHERM_00684590\", \"TTHERM_00670190\", \"TTHERM_00571880\", \"TTHERM_00561799\", \"TTHERM_00529890\", \"TTHERM_00526250\", \"TTHERM_00469140\", \"TTHERM_00455600\", \"TTHERM_00439330\", \"TTHERM_00439030\", \"TTHERM_00424700\", \"TTHERM_00316660\", \"TTHERM_00312120\", \"TTHERM_00301770\", \"TTHERM_00297130\", \"TTHERM_00292160\", \"TTHERM_00243710\", \"TTHERM_00113120\", \"TTHERM_000711791\", \"TTHERM_00069420\", \"TTHERM_00048890\", \"TTHERM_000463439\", \"TTHERM_000439109\", \"TTHERM_00037290\", \"TTHERM_000248319\", \"TTHERM_000086999\", \"TTHERM_01079170\", \"TTHERM_01005150\", \"TTHERM_00865050\", \"TTHERM_00773520\", \"TTHERM_00729230\", \"TTHERM_00704040\", \"TTHERM_00672040\", \"TTHERM_00667000\", \"TTHERM_00648920\", \"TTHERM_00614820\", \"TTHERM_00576890\", \"TTHERM_00572090\", \"TTHERM_00483610\", \"TTHERM_00446570\", \"TTHERM_00441870\", \"TTHERM_00219420\", \"TTHERM_00194810\", \"TTHERM_00161750\", \"TTHERM_00142290\", \"TTHERM_001000210\", \"TTHERM_00083540\", \"TTHERM_00058860\", \"TTHERM_00048980\", \"TTHERM_00046130\", \"TTHERM_000420919\", \"TTHERM_000383629\", \"TTHERM_00013120\", \"TTHERM_00011190\", \"TTHERM_01245640\", \"TTHERM_01197090\", \"TTHERM_01195950\", \"TTHERM_01016190\", \"TTHERM_00790790\", \"TTHERM_00585320\", \"TTHERM_00568050\", \"TTHERM_00554270\", \"TTHERM_00498190\", \"TTHERM_00487030\", \"TTHERM_00448570\", \"TTHERM_00277550\", \"TTHERM_00242370\", \"TTHERM_00143660\", \"TTHERM_00105150\", \"TTHERM_00092850\", \"TTHERM_000011759\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_module_assignments(list(full_filtered_norm_df['TTHERM_ID'].values), gene_list_1, list(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_module_assignments(list(full_filtered_norm_df['TTHERM_ID'].values), gene_list_2, list(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_module_assignments(list(full_filtered_norm_df['TTHERM_ID'].values), gene_list_3, list(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn_dists[1234])\n",
    "print(ann_dists[1234])\n",
    "print(nn_dists.shape)\n",
    "print(ann_dists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn_idxs[1234])\n",
    "print(ann_idxs[1234])\n",
    "print(nn_idxs.shape)\n",
    "print(ann_idxs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
