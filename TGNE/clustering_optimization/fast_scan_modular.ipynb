{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import scipy.stats as st\n",
    "import scipy.spatial\n",
    "import scipy.cluster.hierarchy\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "import umap\n",
    "import pymde\n",
    "\n",
    "import torch\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import bokeh\n",
    "from bokeh.plotting import show as show_interactive, output_file, output_notebook\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import (\n",
    "    CustomJS,\n",
    "    TextInput,\n",
    "    LassoSelectTool,\n",
    "    Select,\n",
    "    MultiSelect,\n",
    "    ColorBar,\n",
    "    Legend,\n",
    "    LegendItem,\n",
    "    DataTable,\n",
    "    DateFormatter,\n",
    "    TableColumn,\n",
    "    Button,\n",
    "    HTMLTemplateFormatter,\n",
    "    FactorRange,\n",
    ")\n",
    "from bokeh.events import SelectionGeometry\n",
    "from bokeh.transform import linear_cmap, jitter\n",
    "\n",
    "from matplotlib.pyplot import show as show_static\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from pynndescent import NNDescent\n",
    "\n",
    "from csv import DictWriter\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_row(row):\n",
    "    shuffled_row = row.values.copy()\n",
    "    np.random.shuffle(shuffled_row)\n",
    "    return pd.Series(shuffled_row, index=row.index)\n",
    "\n",
    "def shuffle_rows(df):\n",
    "    columns_to_shuffle = df.columns[1:]\n",
    "    df[columns_to_shuffle] = df[columns_to_shuffle].apply(shuffle_row, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom_mean_expression(expression_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to take an expression dataframe from the microarrays and collapse it into the means of\n",
    "    all replicate chips.\n",
    "    \"\"\"\n",
    "    # C2 and S12 got removed during quality control\n",
    "    x = [\n",
    "        'Ll', \n",
    "        'Lm', \n",
    "        'Lh', \n",
    "        'S0', \n",
    "        'S3', \n",
    "        'S6', \n",
    "        'S9', \n",
    "        # 'S12', \n",
    "        'S15', \n",
    "        'S24', \n",
    "        'C0', \n",
    "        # 'C2', \n",
    "        'C4', \n",
    "        'C6', \n",
    "        'C8', \n",
    "        'C10', \n",
    "        'C12', \n",
    "        'C14', \n",
    "        'C16', \n",
    "        'C18']\n",
    "    \n",
    "    # cols = expression_df.columns[1:]\n",
    "    # x = [c for c in x if c in cols]\n",
    "    \n",
    "    condition_expr_dict = {c.split(\"_\")[0]: [] for c in expression_df.columns[1:]}\n",
    "    \n",
    "    for c in list(expression_df.columns)[1:]:\n",
    "        \n",
    "        cond = c.split('_')[0]\n",
    "        if cond in condition_expr_dict.keys():\n",
    "            expr_list = condition_expr_dict.get(cond, [])\n",
    "\n",
    "            # Need to avoid true zeros\n",
    "            expr_list.append(expression_df[c].values)\n",
    "            condition_expr_dict[cond] = expr_list\n",
    "        \n",
    "    condition_mean_dict = {c: (st.mstats.gmean(np.array(condition_expr_dict[c]) + 1, 0) - 1) for c in condition_expr_dict.keys() if c in x}\n",
    "    \n",
    "    mean_expr_df = pd.DataFrame(condition_mean_dict)\n",
    "    mean_expr_df['TTHERM_ID'] = expression_df['TTHERM_ID'].values\n",
    "    cols = list(mean_expr_df.columns)\n",
    "    reorder = cols[-1:] + cols[:-1]\n",
    "    mean_expr_df = mean_expr_df[reorder]\n",
    "    \n",
    "    return mean_expr_df\n",
    "\n",
    "def normalizer(array):\n",
    "    \"\"\"\n",
    "    Normalizes the values of an array to range from zero to one\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(array)\n",
    "    \n",
    "    normalized = (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_expression_per_gene(expression_df):\n",
    "    \"\"\"\n",
    "    Function to normalize all gene expression to range from zero to one.\n",
    "    \"\"\"\n",
    "    if 'TTHERM_ID' in expression_df.columns:\n",
    "        ttids = expression_df['TTHERM_ID'].values\n",
    "        data = expression_df[list(expression_df.columns)[1:]]\n",
    "        \n",
    "        norm_expression_df = data.apply(lambda row: normalizer(row), axis=1)\n",
    "        norm_expression_df['TTHERM_ID'] = ttids\n",
    "        \n",
    "        columns = norm_expression_df.columns.tolist()\n",
    "        \n",
    "        rearrangment = columns[-1:] + columns[:-1]\n",
    "        \n",
    "        norm_expression_df = norm_expression_df[rearrangment]\n",
    "        \n",
    "    else:\n",
    "        norm_expression_df = expression_df.apply(lambda row: normalizer(row), axis=1)\n",
    "    \n",
    "    return norm_expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_annotation = pd.read_csv('../eggnog/complete_eggnog_annotation.csv')\n",
    "go_df = pd.read_csv('../enrichment/go_annotations.csv')\n",
    "kegg_df = pd.read_csv('../enrichment/kegg_annotations.csv')\n",
    "ec_df = pd.read_csv('../enrichment/ec_annotations.csv')\n",
    "\n",
    "go_df['GOs_description'].loc[go_df['GOs'] == 'GO:0000001'].values[0]\n",
    "\n",
    "# As of 2020 https://www.ncbi.nlm.nih.gov/research/cog/\n",
    "COG_dict = {\n",
    "    \"A\" : \"RNA processing and modification\",\n",
    "    \"B\" : \"Chromatin structure and dynamics\",\n",
    "    \"C\" : \"Energy production and conversion\",\n",
    "    \"D\" : \"Cell cycle control, cell division, chromosome partitioning\",\n",
    "    \"E\" : \"Amino acid transport and metabolism\",\n",
    "    \"F\" : \"Nucleotide transport and metabolism\",\n",
    "    \"G\" : \"Carbohydrate transport and metabolism\",\n",
    "    \"H\" : \"Coenzyme transport and metabolism\",\n",
    "    \"I\" : \"Lipid transport and metabolism\",\n",
    "    \"J\" : \"Translation, ribosomal structure and biogenesis\",\n",
    "    \"K\" : \"Transcription\",\n",
    "    \"L\" : \"Replication, recombination, and repair\",\n",
    "    \"M\" : \"Cell wall/membrane/envelope biogenesis\",\n",
    "    \"N\" : \"Cell motility\",\n",
    "    \"O\" : \"Posttranslational modification, protein turnover, chaperones\",\n",
    "    \"P\" : \"Inorganic ion transport and metabolism\",\n",
    "    \"Q\" : \"Secondary metabolites biosynthesis, transport and catabolism\",\n",
    "    \"T\" : \"Signal transduction mechanisms\",\n",
    "    \"U\" : \"Intracellular trafficking, secretion, and vesicular transport\",\n",
    "    \"V\" : \"Defense mechanisms\",\n",
    "    \"W\" : \"Extracellular structures\",\n",
    "    \"X\" : \"Mobilome: prophages, transposons\",\n",
    "    \"Y\" : \"Nuclear structure\",\n",
    "    \"Z\" : \"Cytoskeleton\",\n",
    "    \"R\" : \"General function prediction only\",\n",
    "    \"S\" : \"Function unknown\",\n",
    "}\n",
    "def term_count_dict_from_annotation_df(annot_df, term_column):\n",
    "    \n",
    "    column = annot_df[term_column].values\n",
    "    \n",
    "    funct_terms = []\n",
    "    for entry in column:\n",
    "        if entry != '-':\n",
    "            if term_column == 'COG_category':\n",
    "                # terms = [f'{e}: {COG_dict[e]}' for e in entry]\n",
    "                terms = list(entry)\n",
    "            else:\n",
    "                terms = entry.split(',')\n",
    "            for t in terms:\n",
    "                funct_terms.append(t)\n",
    "\n",
    "#     len(terms)\n",
    "    \n",
    "    term_count_dict = {}\n",
    "    \n",
    "    for t in funct_terms:\n",
    "        count = term_count_dict.get(t, 0)\n",
    "        count += 1\n",
    "        term_count_dict[t] = count\n",
    "        \n",
    "    return term_count_dict\n",
    "def enrichment_analysis(module, leiden_label_df, phases, background_annotation, term_column):\n",
    "    \n",
    "    module_ttids = leiden_label_df.loc[leiden_label_df[f'leiden_label_{phases}'] == module]['TTHERM_ID'].values\n",
    "    \n",
    "    module_annotation = background_annotation.loc[background_annotation['TTHERM_ID'].isin(module_ttids)]\n",
    "    \n",
    "    background_term_dict = term_count_dict_from_annotation_df(background_annotation, term_column)\n",
    "    module_term_dict = term_count_dict_from_annotation_df(module_annotation, term_column)\n",
    "    \n",
    "    bs = []\n",
    "    ps = []\n",
    "    folds = []\n",
    "    terms = []\n",
    "    \n",
    "    for t, module_count in module_term_dict.items():\n",
    "        \n",
    "        background_count = background_term_dict[t]\n",
    "        module_size = len(module_annotation)\n",
    "        background_size = len(background_annotation)\n",
    "        \n",
    "        standard_contingency_table = [\n",
    "                                [module_count, background_count - module_count], \n",
    "                                [module_size - module_count, background_size - module_size - (background_count - module_count)]\n",
    "                            ]\n",
    "        \n",
    "        # The -1 and +1 make this more conservative (see explanation from the DAVID database: \n",
    "        # https://david.ncifcrf.gov/helps/functional_annotation.html#geneenrich)\n",
    "        conservative_contingency_table = [\n",
    "                                [module_count - 1, background_count - module_count + 1], \n",
    "                                [module_size - module_count, background_size - module_size - (background_count - module_count)]\n",
    "                            ]\n",
    "        \n",
    "        \n",
    "        odds, p_standard = st.fisher_exact(standard_contingency_table, 'greater')\n",
    "        odds, p_conservative = st.fisher_exact(conservative_contingency_table, 'greater')\n",
    "        \n",
    "        p_reasonable = np.mean([p_standard, p_conservative])\n",
    "        \n",
    "        bonferroni  = p_reasonable * len(module_term_dict)\n",
    "\n",
    "        fold_enrichment = (module_count/module_size) / (background_count/background_size)\n",
    "\n",
    "        if bonferroni <= 0.05:\n",
    "            \n",
    "            ps.append(p_reasonable)\n",
    "            bs.append(bonferroni)\n",
    "            folds.append(fold_enrichment)\n",
    "            terms.append(t)\n",
    "            \n",
    "#         else:\n",
    "#             ps.append('')\n",
    "#             bs.append('')\n",
    "#             folds.append('')\n",
    "#             terms.append('')\n",
    "            \n",
    "    return ps, bs, folds, terms\n",
    "            \n",
    "            \n",
    "def get_GO_info(go_term):\n",
    "    \n",
    "    name = go_df['GOs_description'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    definition = go_df['GOs_definition'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    obsolete = go_df['GOs_obsolete'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    return name, definition, obsolete\n",
    "\n",
    "def get_KEGG_info(term):\n",
    "    return kegg_df['KEGG_ko_description'].loc[kegg_df['KEGG_ko'] == term].values[0]\n",
    "\n",
    "def get_EC_info(term):\n",
    "    return ec_df['EC_description'].loc[ec_df['EC'] == term].values[0]\n",
    "\n",
    "def get_enrichment_df(lldf, phases, background_annotation, term_columns=['COG_category', 'GOs', 'KEGG_ko', 'EC'], outfile=None):\n",
    "    \n",
    "    module_dfs = []\n",
    "    \n",
    "    for m in tqdm.tqdm(sorted(lldf[f'leiden_label_{phases}'].unique())):\n",
    "        \n",
    "        term_dfs = []\n",
    "\n",
    "        for tc in term_columns:\n",
    "        \n",
    "            ps, bs, folds, terms = enrichment_analysis(m, lldf, phases, background_annotation, tc)\n",
    "\n",
    "            # fl.write(f'Module {m}\\n')\n",
    "            \n",
    "            info = []\n",
    "\n",
    "            if tc == 'GOs':\n",
    "\n",
    "                for t in terms:\n",
    "                    name, definition, obsolete = get_GO_info(t)\n",
    "                    if obsolete:\n",
    "                        info.append(f'{name.capitalize()}: {definition} (obsolete)')\n",
    "                    else:\n",
    "                        info.append(f'{name.capitalize()}: {definition}')\n",
    "                        \n",
    "            elif tc == 'COG_category':\n",
    "                for t in terms:\n",
    "                    info.append(COG_dict[t])\n",
    "                                \n",
    "            elif tc == 'KEGG_ko':\n",
    "                for t in terms:\n",
    "                    info.append(get_KEGG_info(t))\n",
    "                    \n",
    "            elif tc == 'EC':\n",
    "                for t in terms:\n",
    "                    info.append(get_EC_info(t))\n",
    "                    \n",
    "            term_df = pd.DataFrame({'module': [m]*len(terms),\n",
    "                                    'term': terms,\n",
    "                                    'info': info,\n",
    "                                    'fold_change': folds,\n",
    "                                    'bonferroni': bs})\n",
    "            \n",
    "            term_dfs.append(term_df)\n",
    "            \n",
    "        module_df = pd.concat(term_dfs)\n",
    "        \n",
    "        module_dfs.append(module_df)\n",
    "        \n",
    "    all_enrichment_df = pd.concat(module_dfs)\n",
    "    \n",
    "    if outfile:\n",
    "        all_enrichment_df.to_csv(outfile, index=False)\n",
    "    \n",
    "    return all_enrichment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = False\n",
    "full_filtered_df = pd.read_csv('../microarray_probe_alignment_and_filtering/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')\n",
    "full_filtered_df = full_filtered_df.rename(columns={'Unnamed: 0': 'TTHERM_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>Ll_GSM283687</th>\n",
       "      <th>Ll_GSM284355</th>\n",
       "      <th>Ll_GSM284362</th>\n",
       "      <th>Lm_GSM283690</th>\n",
       "      <th>Lm_GSM284357</th>\n",
       "      <th>Lm_GSM284363</th>\n",
       "      <th>Lh_GSM283691</th>\n",
       "      <th>Lh_GSM284360</th>\n",
       "      <th>Lh_GSM284364</th>\n",
       "      <th>...</th>\n",
       "      <th>C12_GSM656237</th>\n",
       "      <th>C14_GSM285580</th>\n",
       "      <th>C14_GSM285593</th>\n",
       "      <th>C14_GSM656238</th>\n",
       "      <th>C16_GSM285582</th>\n",
       "      <th>C16_GSM285595</th>\n",
       "      <th>C16_GSM656239</th>\n",
       "      <th>C18_GSM285583</th>\n",
       "      <th>C18_GSM285596</th>\n",
       "      <th>C18_GSM656240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>6.928782</td>\n",
       "      <td>7.264201</td>\n",
       "      <td>6.934214</td>\n",
       "      <td>6.732989</td>\n",
       "      <td>6.970612</td>\n",
       "      <td>7.150978</td>\n",
       "      <td>6.126826</td>\n",
       "      <td>6.868968</td>\n",
       "      <td>6.641119</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450318</td>\n",
       "      <td>8.049750</td>\n",
       "      <td>7.788162</td>\n",
       "      <td>7.052154</td>\n",
       "      <td>6.517742</td>\n",
       "      <td>6.918501</td>\n",
       "      <td>6.048861</td>\n",
       "      <td>7.041619</td>\n",
       "      <td>6.757932</td>\n",
       "      <td>5.817246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>9.633489</td>\n",
       "      <td>9.977124</td>\n",
       "      <td>10.027529</td>\n",
       "      <td>9.720665</td>\n",
       "      <td>9.605762</td>\n",
       "      <td>10.225542</td>\n",
       "      <td>10.279608</td>\n",
       "      <td>10.459966</td>\n",
       "      <td>10.693337</td>\n",
       "      <td>...</td>\n",
       "      <td>11.130466</td>\n",
       "      <td>11.207738</td>\n",
       "      <td>11.009172</td>\n",
       "      <td>10.615417</td>\n",
       "      <td>11.038938</td>\n",
       "      <td>11.009222</td>\n",
       "      <td>10.216348</td>\n",
       "      <td>11.099187</td>\n",
       "      <td>11.172276</td>\n",
       "      <td>10.561021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>5.066343</td>\n",
       "      <td>4.767264</td>\n",
       "      <td>5.010981</td>\n",
       "      <td>6.139047</td>\n",
       "      <td>4.619361</td>\n",
       "      <td>4.751761</td>\n",
       "      <td>5.818550</td>\n",
       "      <td>5.342529</td>\n",
       "      <td>5.483750</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314438</td>\n",
       "      <td>7.423571</td>\n",
       "      <td>7.507645</td>\n",
       "      <td>7.417087</td>\n",
       "      <td>7.147801</td>\n",
       "      <td>7.747930</td>\n",
       "      <td>7.093641</td>\n",
       "      <td>7.672685</td>\n",
       "      <td>7.511290</td>\n",
       "      <td>6.890117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>4.696881</td>\n",
       "      <td>4.638401</td>\n",
       "      <td>4.956299</td>\n",
       "      <td>6.942556</td>\n",
       "      <td>5.101252</td>\n",
       "      <td>4.730307</td>\n",
       "      <td>8.457690</td>\n",
       "      <td>4.526411</td>\n",
       "      <td>4.908300</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250233</td>\n",
       "      <td>4.974993</td>\n",
       "      <td>5.747498</td>\n",
       "      <td>5.252167</td>\n",
       "      <td>5.210531</td>\n",
       "      <td>7.083187</td>\n",
       "      <td>5.252222</td>\n",
       "      <td>5.037613</td>\n",
       "      <td>5.495281</td>\n",
       "      <td>5.013987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000030</td>\n",
       "      <td>4.654278</td>\n",
       "      <td>4.537105</td>\n",
       "      <td>4.928739</td>\n",
       "      <td>5.063991</td>\n",
       "      <td>4.584168</td>\n",
       "      <td>4.911880</td>\n",
       "      <td>5.935311</td>\n",
       "      <td>4.519470</td>\n",
       "      <td>4.757861</td>\n",
       "      <td>...</td>\n",
       "      <td>4.651688</td>\n",
       "      <td>4.920573</td>\n",
       "      <td>4.636333</td>\n",
       "      <td>4.883712</td>\n",
       "      <td>4.779395</td>\n",
       "      <td>4.744335</td>\n",
       "      <td>4.513140</td>\n",
       "      <td>4.838428</td>\n",
       "      <td>4.961475</td>\n",
       "      <td>4.653340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  Ll_GSM283687  Ll_GSM284355  Ll_GSM284362  Lm_GSM283690  \\\n",
       "0  TTHERM_000000042      6.928782      7.264201      6.934214      6.732989   \n",
       "1  TTHERM_000000045      9.633489      9.977124     10.027529      9.720665   \n",
       "2   TTHERM_00000010      5.066343      4.767264      5.010981      6.139047   \n",
       "3   TTHERM_00000020      4.696881      4.638401      4.956299      6.942556   \n",
       "4   TTHERM_00000030      4.654278      4.537105      4.928739      5.063991   \n",
       "\n",
       "   Lm_GSM284357  Lm_GSM284363  Lh_GSM283691  Lh_GSM284360  Lh_GSM284364  ...  \\\n",
       "0      6.970612      7.150978      6.126826      6.868968      6.641119  ...   \n",
       "1      9.605762     10.225542     10.279608     10.459966     10.693337  ...   \n",
       "2      4.619361      4.751761      5.818550      5.342529      5.483750  ...   \n",
       "3      5.101252      4.730307      8.457690      4.526411      4.908300  ...   \n",
       "4      4.584168      4.911880      5.935311      4.519470      4.757861  ...   \n",
       "\n",
       "   C12_GSM656237  C14_GSM285580  C14_GSM285593  C14_GSM656238  C16_GSM285582  \\\n",
       "0       6.450318       8.049750       7.788162       7.052154       6.517742   \n",
       "1      11.130466      11.207738      11.009172      10.615417      11.038938   \n",
       "2       6.314438       7.423571       7.507645       7.417087       7.147801   \n",
       "3       5.250233       4.974993       5.747498       5.252167       5.210531   \n",
       "4       4.651688       4.920573       4.636333       4.883712       4.779395   \n",
       "\n",
       "   C16_GSM285595  C16_GSM656239  C18_GSM285583  C18_GSM285596  C18_GSM656240  \n",
       "0       6.918501       6.048861       7.041619       6.757932       5.817246  \n",
       "1      11.009222      10.216348      11.099187      11.172276      10.561021  \n",
       "2       7.747930       7.093641       7.672685       7.511290       6.890117  \n",
       "3       7.083187       5.252222       5.037613       5.495281       5.013987  \n",
       "4       4.744335       4.513140       4.838428       4.961475       4.653340  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_filtered_df = shuffle_rows(full_filtered_df)\n",
    "# shuffled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>Ll_GSM283687</th>\n",
       "      <th>Ll_GSM284355</th>\n",
       "      <th>Ll_GSM284362</th>\n",
       "      <th>Lm_GSM283690</th>\n",
       "      <th>Lm_GSM284357</th>\n",
       "      <th>Lm_GSM284363</th>\n",
       "      <th>Lh_GSM283691</th>\n",
       "      <th>Lh_GSM284360</th>\n",
       "      <th>Lh_GSM284364</th>\n",
       "      <th>...</th>\n",
       "      <th>C12_GSM656237</th>\n",
       "      <th>C14_GSM285580</th>\n",
       "      <th>C14_GSM285593</th>\n",
       "      <th>C14_GSM656238</th>\n",
       "      <th>C16_GSM285582</th>\n",
       "      <th>C16_GSM285595</th>\n",
       "      <th>C16_GSM656239</th>\n",
       "      <th>C18_GSM285583</th>\n",
       "      <th>C18_GSM285596</th>\n",
       "      <th>C18_GSM656240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>6.928782</td>\n",
       "      <td>7.264201</td>\n",
       "      <td>6.934214</td>\n",
       "      <td>6.732989</td>\n",
       "      <td>6.970612</td>\n",
       "      <td>7.150978</td>\n",
       "      <td>6.126826</td>\n",
       "      <td>6.868968</td>\n",
       "      <td>6.641119</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450318</td>\n",
       "      <td>8.049750</td>\n",
       "      <td>7.788162</td>\n",
       "      <td>7.052154</td>\n",
       "      <td>6.517742</td>\n",
       "      <td>6.918501</td>\n",
       "      <td>6.048861</td>\n",
       "      <td>7.041619</td>\n",
       "      <td>6.757932</td>\n",
       "      <td>5.817246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>9.633489</td>\n",
       "      <td>9.977124</td>\n",
       "      <td>10.027529</td>\n",
       "      <td>9.720665</td>\n",
       "      <td>9.605762</td>\n",
       "      <td>10.225542</td>\n",
       "      <td>10.279608</td>\n",
       "      <td>10.459966</td>\n",
       "      <td>10.693337</td>\n",
       "      <td>...</td>\n",
       "      <td>11.130466</td>\n",
       "      <td>11.207738</td>\n",
       "      <td>11.009172</td>\n",
       "      <td>10.615417</td>\n",
       "      <td>11.038938</td>\n",
       "      <td>11.009222</td>\n",
       "      <td>10.216348</td>\n",
       "      <td>11.099187</td>\n",
       "      <td>11.172276</td>\n",
       "      <td>10.561021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>5.066343</td>\n",
       "      <td>4.767264</td>\n",
       "      <td>5.010981</td>\n",
       "      <td>6.139047</td>\n",
       "      <td>4.619361</td>\n",
       "      <td>4.751761</td>\n",
       "      <td>5.818550</td>\n",
       "      <td>5.342529</td>\n",
       "      <td>5.483750</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314438</td>\n",
       "      <td>7.423571</td>\n",
       "      <td>7.507645</td>\n",
       "      <td>7.417087</td>\n",
       "      <td>7.147801</td>\n",
       "      <td>7.747930</td>\n",
       "      <td>7.093641</td>\n",
       "      <td>7.672685</td>\n",
       "      <td>7.511290</td>\n",
       "      <td>6.890117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>4.696881</td>\n",
       "      <td>4.638401</td>\n",
       "      <td>4.956299</td>\n",
       "      <td>6.942556</td>\n",
       "      <td>5.101252</td>\n",
       "      <td>4.730307</td>\n",
       "      <td>8.457690</td>\n",
       "      <td>4.526411</td>\n",
       "      <td>4.908300</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250233</td>\n",
       "      <td>4.974993</td>\n",
       "      <td>5.747498</td>\n",
       "      <td>5.252167</td>\n",
       "      <td>5.210531</td>\n",
       "      <td>7.083187</td>\n",
       "      <td>5.252222</td>\n",
       "      <td>5.037613</td>\n",
       "      <td>5.495281</td>\n",
       "      <td>5.013987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000030</td>\n",
       "      <td>4.654278</td>\n",
       "      <td>4.537105</td>\n",
       "      <td>4.928739</td>\n",
       "      <td>5.063991</td>\n",
       "      <td>4.584168</td>\n",
       "      <td>4.911880</td>\n",
       "      <td>5.935311</td>\n",
       "      <td>4.519470</td>\n",
       "      <td>4.757861</td>\n",
       "      <td>...</td>\n",
       "      <td>4.651688</td>\n",
       "      <td>4.920573</td>\n",
       "      <td>4.636333</td>\n",
       "      <td>4.883712</td>\n",
       "      <td>4.779395</td>\n",
       "      <td>4.744335</td>\n",
       "      <td>4.513140</td>\n",
       "      <td>4.838428</td>\n",
       "      <td>4.961475</td>\n",
       "      <td>4.653340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  Ll_GSM283687  Ll_GSM284355  Ll_GSM284362  Lm_GSM283690  \\\n",
       "0  TTHERM_000000042      6.928782      7.264201      6.934214      6.732989   \n",
       "1  TTHERM_000000045      9.633489      9.977124     10.027529      9.720665   \n",
       "2   TTHERM_00000010      5.066343      4.767264      5.010981      6.139047   \n",
       "3   TTHERM_00000020      4.696881      4.638401      4.956299      6.942556   \n",
       "4   TTHERM_00000030      4.654278      4.537105      4.928739      5.063991   \n",
       "\n",
       "   Lm_GSM284357  Lm_GSM284363  Lh_GSM283691  Lh_GSM284360  Lh_GSM284364  ...  \\\n",
       "0      6.970612      7.150978      6.126826      6.868968      6.641119  ...   \n",
       "1      9.605762     10.225542     10.279608     10.459966     10.693337  ...   \n",
       "2      4.619361      4.751761      5.818550      5.342529      5.483750  ...   \n",
       "3      5.101252      4.730307      8.457690      4.526411      4.908300  ...   \n",
       "4      4.584168      4.911880      5.935311      4.519470      4.757861  ...   \n",
       "\n",
       "   C12_GSM656237  C14_GSM285580  C14_GSM285593  C14_GSM656238  C16_GSM285582  \\\n",
       "0       6.450318       8.049750       7.788162       7.052154       6.517742   \n",
       "1      11.130466      11.207738      11.009172      10.615417      11.038938   \n",
       "2       6.314438       7.423571       7.507645       7.417087       7.147801   \n",
       "3       5.250233       4.974993       5.747498       5.252167       5.210531   \n",
       "4       4.651688       4.920573       4.636333       4.883712       4.779395   \n",
       "\n",
       "   C16_GSM285595  C16_GSM656239  C18_GSM285583  C18_GSM285596  C18_GSM656240  \n",
       "0       6.918501       6.048861       7.041619       6.757932       5.817246  \n",
       "1      11.009222      10.216348      11.099187      11.172276      10.561021  \n",
       "2       7.747930       7.093641       7.672685       7.511290       6.890117  \n",
       "3       7.083187       5.252222       5.037613       5.495281       5.013987  \n",
       "4       4.744335       4.513140       4.838428       4.961475       4.653340  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ad0261c4cf84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_filtered_norm_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_expression_per_gene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filtered_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_filtered_norm_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filtered_norm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f5f36ce8757a>\u001b[0m in \u001b[0;36mnormalize_expression_per_gene\u001b[0;34m(expression_df)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mnorm_expression_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mnorm_expression_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TTHERM_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m         )\n\u001b[0;32m-> 7768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f5f36ce8757a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mnorm_expression_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mnorm_expression_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TTHERM_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f5f36ce8757a>\u001b[0m in \u001b[0;36mnormalizer\u001b[0;34m(array)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__truediv__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__truediv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rtruediv__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   4998\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5000\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m         \u001b[0;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2763\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2764\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# extract ndarray or ExtensionArray, ensure we have no PandasArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# GH#846\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cdh2.env/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mextract_numpy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_filtered_norm_df = normalize_expression_per_gene(full_filtered_df)\n",
    "raw_data = full_filtered_norm_df[list(full_filtered_norm_df.columns)[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# X, _ = make_blobs(n_samples=10000, n_features=30, centers=350, cluster_std=1.0, random_state=42)  # Use only 2 features\n",
    "# # Convert X to a DataFrame\n",
    "# columns = ['feature' + str(i) for i in range(X.shape[1])]\n",
    "# df = pd.DataFrame(X, columns=columns)\n",
    "# raw_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_distance_matrix(data_df, metric, n_jobs=-1):\n",
    "    \n",
    "    return pairwise_distances(data_df, metric=metric, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nns(data_df, nn, metric, random_state=42, n_jobs=-1):\n",
    "    \n",
    "    # num_neighbors = NearestNeighbors(n_neighbors=nn, metric='precomputed', n_jobs=-1).fit(manhattan_distance_matrix)\n",
    "    # nn_dists, nn_idxs = num_neighbors.kneighbors(return_distance=True)\n",
    "\n",
    "    n_trees = min(64, 5 + int(round((raw_data.shape[0]) ** 0.5 / 20.0)))\n",
    "    n_iters = max(5, int(round(np.log2(raw_data.shape[0]))))\n",
    "    knn_search_index = NNDescent(\n",
    "                data_df,\n",
    "                n_neighbors=nn,\n",
    "                metric=metric,\n",
    "                # metric_kwds=metric_kwds,\n",
    "                random_state=random_state,\n",
    "                n_trees=n_trees,\n",
    "                n_iters=n_iters,\n",
    "                max_candidates=60,\n",
    "                # low_memory=low_memory,\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=True,\n",
    "                compressed=False,\n",
    "            )\n",
    "    nn_idxs, nn_dists = knn_search_index.neighbor_graph\n",
    "\n",
    "    return nn_idxs, nn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_umap_graph(data_df, nn, metric, nn_idxs, nn_dists):\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data_df, nn, 42, metric, knn_indices=nn_idxs, knn_dists=nn_dists, return_dists=True)\n",
    "\n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "\n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leiden_partition(graph, resolution_parameter, random_state=42):\n",
    "        \n",
    "        partition = la.find_partition(graph, la.CPMVertexPartition, resolution_parameter = resolution_parameter, seed=random_state, weights='weight')\n",
    "        # partition = la.find_partition(g, la.ModularityVertexPartition, seed=42, weights='weight')\n",
    "\n",
    "        leiden_modules = np.array(partition.membership)\n",
    "\n",
    "        return leiden_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_communities(parition, idx_labels):\n",
    "    communities = {}\n",
    "\n",
    "    for idx, membership in enumerate(parition):\n",
    "        if membership not in communities:\n",
    "            communities[membership] = []\n",
    "        communities[membership].append(idx_labels[idx])\n",
    "\n",
    "    return communities.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_silhouette_score(distance_matrix, parition):\n",
    "    return silhouette_score(distance_matrix, parition, metric='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_modularity(graph, communities):\n",
    "    nx_g = nx.Graph(graph.get_edgelist())\n",
    "    return nx.community.quality.modularity(nx_g, communities, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_parition_for_enrichment(df, parition):\n",
    "    edf = pd.DataFrame.from_dict({'TTHERM_ID': []})\n",
    "    edf['TTHERM_ID'] = df['TTHERM_ID'].values\n",
    "    edf[f'leiden_label_full'] = parition\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment(df, parition):\n",
    "    edf = format_parition_for_enrichment(df, parition)\n",
    "\n",
    "    temp_scan_file = './temp_scan_partition.csv'\n",
    "\n",
    "    temp_enrich_file = './temp_scan_enrich.csv'\n",
    "\n",
    "    edf.to_csv(temp_scan_file, index=False)\n",
    "\n",
    "    subprocess.run(['python3', './fast_enrichment_analysis.py', temp_scan_file, temp_enrich_file])\n",
    "\n",
    "    cedf = pd.read_csv(temp_enrich_file)\n",
    "    \n",
    "    remove_file(temp_scan_file)\n",
    "\n",
    "    remove_file(temp_enrich_file)\n",
    "\n",
    "    return cedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_clusters(parition, communities=None):\n",
    "    if communities is None:\n",
    "        return len(set(parition))\n",
    "    \n",
    "    if len(set(parition)) != len(communities):\n",
    "        raise ValueError(f'The number of clusters/modules ({len(set(parition))}) in the parition != the number of communities ({len(communities)}).')\n",
    "    \n",
    "    return len(set(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_clusters(cedf):\n",
    "    return len(set(cedf['module'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_cluster_genes(edf, parition):\n",
    "    total_num_genes = 0\n",
    "\n",
    "    for m in set(edf['module'].values):\n",
    "        num_genes = np.count_nonzero(parition == int(m))\n",
    "        total_num_genes += num_genes\n",
    "    \n",
    "    return total_num_genes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(csv_file_path, data_item, header):\n",
    "    # Check if the CSV file exists and write header if it doesn't\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        with open(csv_file_path, 'w', newline='') as file:\n",
    "            writer = DictWriter(file, fieldnames=header)\n",
    "            writer.writeheader()\n",
    "\n",
    "    with open(csv_file_path, 'a', newline='') as file:\n",
    "        writer = DictWriter(file, fieldnames=header)\n",
    "        writer.writerow(data_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_labels = list(range(raw_data.shape[0]))\n",
    "\n",
    "metric = 'manhattan'\n",
    "n_jobs = -1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_nns = np.arange(12, 19, 1)\n",
    "scan_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_rps = np.arange(0.005, 0.1, 0.01)\n",
    "scan_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = compute_pairwise_distance_matrix(raw_data, metric, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, nn in enumerate(scan_nns):     \n",
    "    print(idx+1,'of',len(scan_nns))     \n",
    "    print('NNs: ', nn)\n",
    "\n",
    "    scan_dict[nn] = {}\n",
    "\n",
    "    nn_idxs, nn_dists = compute_nns(raw_data, nn, metric, random_state, n_jobs)\n",
    "    scan_dict[nn]['nn_idxs'] = nn_idxs\n",
    "    scan_dict[nn]['nn_dists'] = nn_dists\n",
    "\n",
    "    nn_graph = compute_umap_graph(raw_data, nn, metric, nn_idxs, nn_dists)\n",
    "    scan_dict[nn]['nn_graph'] = nn_graph\n",
    "\n",
    "    for rp in tqdm.tqdm(scan_rps):\n",
    "\n",
    "        scan_dict[nn][rp] = {}\n",
    "        \n",
    "        parition = compute_leiden_partition(nn_graph, rp, random_state)\n",
    "        scan_dict[nn][rp]['partition'] = parition\n",
    "\n",
    "        communities = compute_communities(parition, idx_labels)\n",
    "        scan_dict[nn][rp]['communities'] = communities\n",
    "\n",
    "        sil_score = compute_silhouette_score(distance_matrix, parition)\n",
    "        scan_dict[nn][rp]['sil_score'] = sil_score\n",
    "\n",
    "        modularity = compute_modularity(nn_graph, communities)\n",
    "        scan_dict[nn][rp]['modularity'] = modularity\n",
    "\n",
    "        enrichment_df = compute_enrichment(full_filtered_norm_df, parition)\n",
    "        scan_dict[nn][rp]['enrichment_df'] = enrichment_df\n",
    "\n",
    "        num_clusters = compute_num_clusters(parition, communities)\n",
    "        scan_dict[nn][rp]['num_clusters'] = num_clusters\n",
    "\n",
    "        num_enriched_clusters = compute_num_enriched_clusters(enrichment_df)\n",
    "        scan_dict[nn][rp]['num_enriched_clusters'] = num_enriched_clusters\n",
    "\n",
    "        num_enriched_cluster_genes = compute_num_enriched_cluster_genes(enrichment_df, parition)\n",
    "        scan_dict[nn][rp]['num_enriched_cluster_genes'] = num_enriched_cluster_genes\n",
    "\n",
    "        cluster_stats = {\n",
    "        'shuffled': shuffled,\n",
    "        'dimensionality': 'baseline',\n",
    "        'graph': 'umap_fuzzy_simplicial_set',\n",
    "        'nns': nn,\n",
    "        'clustering': 'leiden_cpm',\n",
    "        'parameter': rp,\n",
    "        'metric': metric,\n",
    "        'nclusters': num_clusters,\n",
    "        'silhouette_score': sil_score,\n",
    "        'modularity': modularity,\n",
    "        'nenriched_clusters': num_enriched_clusters,\n",
    "        'nenriched_cluster_genes': num_enriched_cluster_genes,\n",
    "        'datetime': curr_datetime\n",
    "        }\n",
    "\n",
    "        write_to_csv('./scan_stats.csv', cluster_stats, list(cluster_stats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./scan_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
