{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "import umap\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from pynndescent import NNDescent\n",
    "\n",
    "from csv import DictWriter\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_row(row):\n",
    "    shuffled_row = row.values.copy()\n",
    "    np.random.shuffle(shuffled_row)\n",
    "    return pd.Series(shuffled_row, index=row.index)\n",
    "\n",
    "def shuffle_rows(df):\n",
    "    columns_to_shuffle = df.columns[1:]\n",
    "    df[columns_to_shuffle] = df[columns_to_shuffle].apply(shuffle_row, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom_mean_expression(expression_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to take an expression dataframe from the microarrays and collapse it into the means of\n",
    "    all replicate chips.\n",
    "    \"\"\"\n",
    "    # C2 and S12 got removed during quality control\n",
    "    x = [\n",
    "        'Ll', \n",
    "        'Lm', \n",
    "        'Lh', \n",
    "        'S0', \n",
    "        'S3', \n",
    "        'S6', \n",
    "        'S9', \n",
    "        # 'S12', \n",
    "        'S15', \n",
    "        'S24', \n",
    "        'C0', \n",
    "        # 'C2', \n",
    "        'C4', \n",
    "        'C6', \n",
    "        'C8', \n",
    "        'C10', \n",
    "        'C12', \n",
    "        'C14', \n",
    "        'C16', \n",
    "        'C18']\n",
    "    \n",
    "    # cols = expression_df.columns[1:]\n",
    "    # x = [c for c in x if c in cols]\n",
    "    \n",
    "    condition_expr_dict = {c.split(\"_\")[0]: [] for c in expression_df.columns[1:]}\n",
    "    \n",
    "    for c in list(expression_df.columns)[1:]:\n",
    "        \n",
    "        cond = c.split('_')[0]\n",
    "        if cond in condition_expr_dict.keys():\n",
    "            expr_list = condition_expr_dict.get(cond, [])\n",
    "\n",
    "            # Need to avoid true zeros\n",
    "            expr_list.append(expression_df[c].values)\n",
    "            condition_expr_dict[cond] = expr_list\n",
    "        \n",
    "    condition_mean_dict = {c: (st.mstats.gmean(np.array(condition_expr_dict[c]) + 1, 0) - 1) for c in condition_expr_dict.keys() if c in x}\n",
    "    \n",
    "    mean_expr_df = pd.DataFrame(condition_mean_dict)\n",
    "    mean_expr_df['TTHERM_ID'] = expression_df['TTHERM_ID'].values\n",
    "    cols = list(mean_expr_df.columns)\n",
    "    reorder = cols[-1:] + cols[:-1]\n",
    "    mean_expr_df = mean_expr_df[reorder]\n",
    "    \n",
    "    return mean_expr_df\n",
    "\n",
    "def normalizer(array):\n",
    "    \"\"\"\n",
    "    Normalizes the values of an array to range from zero to one\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(array)\n",
    "    \n",
    "    normalized = (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_expression_per_gene(expression_df):\n",
    "    \"\"\"\n",
    "    Function to normalize all gene expression to range from zero to one.\n",
    "    \"\"\"\n",
    "    if 'TTHERM_ID' in expression_df.columns:\n",
    "        ttids = expression_df['TTHERM_ID'].values\n",
    "        data = expression_df[list(expression_df.columns)[1:]]\n",
    "        \n",
    "        norm_expression_df = data.apply(lambda row: normalizer(row), axis=1)\n",
    "        norm_expression_df['TTHERM_ID'] = ttids\n",
    "        \n",
    "        columns = norm_expression_df.columns.tolist()\n",
    "        \n",
    "        rearrangment = columns[-1:] + columns[:-1]\n",
    "        \n",
    "        norm_expression_df = norm_expression_df[rearrangment]\n",
    "        \n",
    "    else:\n",
    "        norm_expression_df = expression_df.apply(lambda row: normalizer(row), axis=1)\n",
    "    \n",
    "    return norm_expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_annotation = pd.read_csv('../eggnog/complete_eggnog_annotation.csv')\n",
    "go_df = pd.read_csv('../enrichment/go_annotations.csv')\n",
    "kegg_df = pd.read_csv('../enrichment/kegg_annotations.csv')\n",
    "ec_df = pd.read_csv('../enrichment/ec_annotations.csv')\n",
    "\n",
    "go_df['GOs_description'].loc[go_df['GOs'] == 'GO:0000001'].values[0]\n",
    "\n",
    "# As of 2020 https://www.ncbi.nlm.nih.gov/research/cog/\n",
    "COG_dict = {\n",
    "    \"A\" : \"RNA processing and modification\",\n",
    "    \"B\" : \"Chromatin structure and dynamics\",\n",
    "    \"C\" : \"Energy production and conversion\",\n",
    "    \"D\" : \"Cell cycle control, cell division, chromosome partitioning\",\n",
    "    \"E\" : \"Amino acid transport and metabolism\",\n",
    "    \"F\" : \"Nucleotide transport and metabolism\",\n",
    "    \"G\" : \"Carbohydrate transport and metabolism\",\n",
    "    \"H\" : \"Coenzyme transport and metabolism\",\n",
    "    \"I\" : \"Lipid transport and metabolism\",\n",
    "    \"J\" : \"Translation, ribosomal structure and biogenesis\",\n",
    "    \"K\" : \"Transcription\",\n",
    "    \"L\" : \"Replication, recombination, and repair\",\n",
    "    \"M\" : \"Cell wall/membrane/envelope biogenesis\",\n",
    "    \"N\" : \"Cell motility\",\n",
    "    \"O\" : \"Posttranslational modification, protein turnover, chaperones\",\n",
    "    \"P\" : \"Inorganic ion transport and metabolism\",\n",
    "    \"Q\" : \"Secondary metabolites biosynthesis, transport and catabolism\",\n",
    "    \"T\" : \"Signal transduction mechanisms\",\n",
    "    \"U\" : \"Intracellular trafficking, secretion, and vesicular transport\",\n",
    "    \"V\" : \"Defense mechanisms\",\n",
    "    \"W\" : \"Extracellular structures\",\n",
    "    \"X\" : \"Mobilome: prophages, transposons\",\n",
    "    \"Y\" : \"Nuclear structure\",\n",
    "    \"Z\" : \"Cytoskeleton\",\n",
    "    \"R\" : \"General function prediction only\",\n",
    "    \"S\" : \"Function unknown\",\n",
    "}\n",
    "def term_count_dict_from_annotation_df(annot_df, term_column):\n",
    "    \n",
    "    column = annot_df[term_column].values\n",
    "    \n",
    "    funct_terms = []\n",
    "    for entry in column:\n",
    "        if entry != '-':\n",
    "            if term_column == 'COG_category':\n",
    "                # terms = [f'{e}: {COG_dict[e]}' for e in entry]\n",
    "                terms = list(entry)\n",
    "            else:\n",
    "                terms = entry.split(',')\n",
    "            for t in terms:\n",
    "                funct_terms.append(t)\n",
    "\n",
    "#     len(terms)\n",
    "    \n",
    "    term_count_dict = {}\n",
    "    \n",
    "    for t in funct_terms:\n",
    "        count = term_count_dict.get(t, 0)\n",
    "        count += 1\n",
    "        term_count_dict[t] = count\n",
    "        \n",
    "    return term_count_dict\n",
    "def enrichment_analysis(module, leiden_label_df, phases, background_annotation, term_column):\n",
    "    \n",
    "    module_ttids = leiden_label_df.loc[leiden_label_df[f'leiden_label_{phases}'] == module]['TTHERM_ID'].values\n",
    "    \n",
    "    module_annotation = background_annotation.loc[background_annotation['TTHERM_ID'].isin(module_ttids)]\n",
    "    \n",
    "    background_term_dict = term_count_dict_from_annotation_df(background_annotation, term_column)\n",
    "    module_term_dict = term_count_dict_from_annotation_df(module_annotation, term_column)\n",
    "    \n",
    "    bs = []\n",
    "    ps = []\n",
    "    folds = []\n",
    "    terms = []\n",
    "    \n",
    "    for t, module_count in module_term_dict.items():\n",
    "        \n",
    "        background_count = background_term_dict[t]\n",
    "        module_size = len(module_annotation)\n",
    "        background_size = len(background_annotation)\n",
    "        \n",
    "        standard_contingency_table = [\n",
    "                                [module_count, background_count - module_count], \n",
    "                                [module_size - module_count, background_size - module_size - (background_count - module_count)]\n",
    "                            ]\n",
    "        \n",
    "        # The -1 and +1 make this more conservative (see explanation from the DAVID database: \n",
    "        # https://david.ncifcrf.gov/helps/functional_annotation.html#geneenrich)\n",
    "        conservative_contingency_table = [\n",
    "                                [module_count - 1, background_count - module_count + 1], \n",
    "                                [module_size - module_count, background_size - module_size - (background_count - module_count)]\n",
    "                            ]\n",
    "        \n",
    "        \n",
    "        odds, p_standard = st.fisher_exact(standard_contingency_table, 'greater')\n",
    "        odds, p_conservative = st.fisher_exact(conservative_contingency_table, 'greater')\n",
    "        \n",
    "        p_reasonable = np.mean([p_standard, p_conservative])\n",
    "        \n",
    "        bonferroni  = p_reasonable * len(module_term_dict)\n",
    "\n",
    "        fold_enrichment = (module_count/module_size) / (background_count/background_size)\n",
    "\n",
    "        if bonferroni <= 0.05:\n",
    "            \n",
    "            ps.append(p_reasonable)\n",
    "            bs.append(bonferroni)\n",
    "            folds.append(fold_enrichment)\n",
    "            terms.append(t)\n",
    "            \n",
    "#         else:\n",
    "#             ps.append('')\n",
    "#             bs.append('')\n",
    "#             folds.append('')\n",
    "#             terms.append('')\n",
    "            \n",
    "    return ps, bs, folds, terms\n",
    "            \n",
    "            \n",
    "def get_GO_info(go_term):\n",
    "    \n",
    "    name = go_df['GOs_description'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    definition = go_df['GOs_definition'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    obsolete = go_df['GOs_obsolete'].loc[go_df['GOs'] == go_term].values[0]\n",
    "    \n",
    "    return name, definition, obsolete\n",
    "\n",
    "def get_KEGG_info(term):\n",
    "    return kegg_df['KEGG_ko_description'].loc[kegg_df['KEGG_ko'] == term].values[0]\n",
    "\n",
    "def get_EC_info(term):\n",
    "    return ec_df['EC_description'].loc[ec_df['EC'] == term].values[0]\n",
    "\n",
    "def get_enrichment_df(lldf, phases, background_annotation, term_columns=['COG_category', 'GOs', 'KEGG_ko', 'EC'], outfile=None):\n",
    "    \n",
    "    module_dfs = []\n",
    "    \n",
    "    for m in tqdm.tqdm(sorted(lldf[f'leiden_label_{phases}'].unique())):\n",
    "        \n",
    "        term_dfs = []\n",
    "\n",
    "        for tc in term_columns:\n",
    "        \n",
    "            ps, bs, folds, terms = enrichment_analysis(m, lldf, phases, background_annotation, tc)\n",
    "\n",
    "            # fl.write(f'Module {m}\\n')\n",
    "            \n",
    "            info = []\n",
    "\n",
    "            if tc == 'GOs':\n",
    "\n",
    "                for t in terms:\n",
    "                    name, definition, obsolete = get_GO_info(t)\n",
    "                    if obsolete:\n",
    "                        info.append(f'{name.capitalize()}: {definition} (obsolete)')\n",
    "                    else:\n",
    "                        info.append(f'{name.capitalize()}: {definition}')\n",
    "                        \n",
    "            elif tc == 'COG_category':\n",
    "                for t in terms:\n",
    "                    info.append(COG_dict[t])\n",
    "                                \n",
    "            elif tc == 'KEGG_ko':\n",
    "                for t in terms:\n",
    "                    info.append(get_KEGG_info(t))\n",
    "                    \n",
    "            elif tc == 'EC':\n",
    "                for t in terms:\n",
    "                    info.append(get_EC_info(t))\n",
    "                    \n",
    "            term_df = pd.DataFrame({'module': [m]*len(terms),\n",
    "                                    'term': terms,\n",
    "                                    'info': info,\n",
    "                                    'fold_change': folds,\n",
    "                                    'bonferroni': bs})\n",
    "            \n",
    "            term_dfs.append(term_df)\n",
    "            \n",
    "        module_df = pd.concat(term_dfs)\n",
    "        \n",
    "        module_dfs.append(module_df)\n",
    "        \n",
    "    all_enrichment_df = pd.concat(module_dfs)\n",
    "    \n",
    "    if outfile:\n",
    "        all_enrichment_df.to_csv(outfile, index=False)\n",
    "    \n",
    "    return all_enrichment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_type = 'EXP'\n",
    "full_filtered_df = pd.read_csv('../microarray_probe_alignment_and_filtering/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')\n",
    "full_filtered_df = full_filtered_df.rename(columns={'Unnamed: 0': 'TTHERM_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>Ll_GSM283687</th>\n",
       "      <th>Ll_GSM284355</th>\n",
       "      <th>Ll_GSM284362</th>\n",
       "      <th>Lm_GSM283690</th>\n",
       "      <th>Lm_GSM284357</th>\n",
       "      <th>Lm_GSM284363</th>\n",
       "      <th>Lh_GSM283691</th>\n",
       "      <th>Lh_GSM284360</th>\n",
       "      <th>Lh_GSM284364</th>\n",
       "      <th>...</th>\n",
       "      <th>C12_GSM656237</th>\n",
       "      <th>C14_GSM285580</th>\n",
       "      <th>C14_GSM285593</th>\n",
       "      <th>C14_GSM656238</th>\n",
       "      <th>C16_GSM285582</th>\n",
       "      <th>C16_GSM285595</th>\n",
       "      <th>C16_GSM656239</th>\n",
       "      <th>C18_GSM285583</th>\n",
       "      <th>C18_GSM285596</th>\n",
       "      <th>C18_GSM656240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>6.928782</td>\n",
       "      <td>7.264201</td>\n",
       "      <td>6.934214</td>\n",
       "      <td>6.732989</td>\n",
       "      <td>6.970612</td>\n",
       "      <td>7.150978</td>\n",
       "      <td>6.126826</td>\n",
       "      <td>6.868968</td>\n",
       "      <td>6.641119</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450318</td>\n",
       "      <td>8.049750</td>\n",
       "      <td>7.788162</td>\n",
       "      <td>7.052154</td>\n",
       "      <td>6.517742</td>\n",
       "      <td>6.918501</td>\n",
       "      <td>6.048861</td>\n",
       "      <td>7.041619</td>\n",
       "      <td>6.757932</td>\n",
       "      <td>5.817246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>9.633489</td>\n",
       "      <td>9.977124</td>\n",
       "      <td>10.027529</td>\n",
       "      <td>9.720665</td>\n",
       "      <td>9.605762</td>\n",
       "      <td>10.225542</td>\n",
       "      <td>10.279608</td>\n",
       "      <td>10.459966</td>\n",
       "      <td>10.693337</td>\n",
       "      <td>...</td>\n",
       "      <td>11.130466</td>\n",
       "      <td>11.207738</td>\n",
       "      <td>11.009172</td>\n",
       "      <td>10.615417</td>\n",
       "      <td>11.038938</td>\n",
       "      <td>11.009222</td>\n",
       "      <td>10.216348</td>\n",
       "      <td>11.099187</td>\n",
       "      <td>11.172276</td>\n",
       "      <td>10.561021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>5.066343</td>\n",
       "      <td>4.767264</td>\n",
       "      <td>5.010981</td>\n",
       "      <td>6.139047</td>\n",
       "      <td>4.619361</td>\n",
       "      <td>4.751761</td>\n",
       "      <td>5.818550</td>\n",
       "      <td>5.342529</td>\n",
       "      <td>5.483750</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314438</td>\n",
       "      <td>7.423571</td>\n",
       "      <td>7.507645</td>\n",
       "      <td>7.417087</td>\n",
       "      <td>7.147801</td>\n",
       "      <td>7.747930</td>\n",
       "      <td>7.093641</td>\n",
       "      <td>7.672685</td>\n",
       "      <td>7.511290</td>\n",
       "      <td>6.890117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>4.696881</td>\n",
       "      <td>4.638401</td>\n",
       "      <td>4.956299</td>\n",
       "      <td>6.942556</td>\n",
       "      <td>5.101252</td>\n",
       "      <td>4.730307</td>\n",
       "      <td>8.457690</td>\n",
       "      <td>4.526411</td>\n",
       "      <td>4.908300</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250233</td>\n",
       "      <td>4.974993</td>\n",
       "      <td>5.747498</td>\n",
       "      <td>5.252167</td>\n",
       "      <td>5.210531</td>\n",
       "      <td>7.083187</td>\n",
       "      <td>5.252222</td>\n",
       "      <td>5.037613</td>\n",
       "      <td>5.495281</td>\n",
       "      <td>5.013987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000030</td>\n",
       "      <td>4.654278</td>\n",
       "      <td>4.537105</td>\n",
       "      <td>4.928739</td>\n",
       "      <td>5.063991</td>\n",
       "      <td>4.584168</td>\n",
       "      <td>4.911880</td>\n",
       "      <td>5.935311</td>\n",
       "      <td>4.519470</td>\n",
       "      <td>4.757861</td>\n",
       "      <td>...</td>\n",
       "      <td>4.651688</td>\n",
       "      <td>4.920573</td>\n",
       "      <td>4.636333</td>\n",
       "      <td>4.883712</td>\n",
       "      <td>4.779395</td>\n",
       "      <td>4.744335</td>\n",
       "      <td>4.513140</td>\n",
       "      <td>4.838428</td>\n",
       "      <td>4.961475</td>\n",
       "      <td>4.653340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  Ll_GSM283687  Ll_GSM284355  Ll_GSM284362  Lm_GSM283690  \\\n",
       "0  TTHERM_000000042      6.928782      7.264201      6.934214      6.732989   \n",
       "1  TTHERM_000000045      9.633489      9.977124     10.027529      9.720665   \n",
       "2   TTHERM_00000010      5.066343      4.767264      5.010981      6.139047   \n",
       "3   TTHERM_00000020      4.696881      4.638401      4.956299      6.942556   \n",
       "4   TTHERM_00000030      4.654278      4.537105      4.928739      5.063991   \n",
       "\n",
       "   Lm_GSM284357  Lm_GSM284363  Lh_GSM283691  Lh_GSM284360  Lh_GSM284364  ...  \\\n",
       "0      6.970612      7.150978      6.126826      6.868968      6.641119  ...   \n",
       "1      9.605762     10.225542     10.279608     10.459966     10.693337  ...   \n",
       "2      4.619361      4.751761      5.818550      5.342529      5.483750  ...   \n",
       "3      5.101252      4.730307      8.457690      4.526411      4.908300  ...   \n",
       "4      4.584168      4.911880      5.935311      4.519470      4.757861  ...   \n",
       "\n",
       "   C12_GSM656237  C14_GSM285580  C14_GSM285593  C14_GSM656238  C16_GSM285582  \\\n",
       "0       6.450318       8.049750       7.788162       7.052154       6.517742   \n",
       "1      11.130466      11.207738      11.009172      10.615417      11.038938   \n",
       "2       6.314438       7.423571       7.507645       7.417087       7.147801   \n",
       "3       5.250233       4.974993       5.747498       5.252167       5.210531   \n",
       "4       4.651688       4.920573       4.636333       4.883712       4.779395   \n",
       "\n",
       "   C16_GSM285595  C16_GSM656239  C18_GSM285583  C18_GSM285596  C18_GSM656240  \n",
       "0       6.918501       6.048861       7.041619       6.757932       5.817246  \n",
       "1      11.009222      10.216348      11.099187      11.172276      10.561021  \n",
       "2       7.747930       7.093641       7.672685       7.511290       6.890117  \n",
       "3       7.083187       5.252222       5.037613       5.495281       5.013987  \n",
       "4       4.744335       4.513140       4.838428       4.961475       4.653340  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_filtered_df = shuffle_rows(full_filtered_df)\n",
    "# partition_type = 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>Ll_GSM283687</th>\n",
       "      <th>Ll_GSM284355</th>\n",
       "      <th>Ll_GSM284362</th>\n",
       "      <th>Lm_GSM283690</th>\n",
       "      <th>Lm_GSM284357</th>\n",
       "      <th>Lm_GSM284363</th>\n",
       "      <th>Lh_GSM283691</th>\n",
       "      <th>Lh_GSM284360</th>\n",
       "      <th>Lh_GSM284364</th>\n",
       "      <th>...</th>\n",
       "      <th>C12_GSM656237</th>\n",
       "      <th>C14_GSM285580</th>\n",
       "      <th>C14_GSM285593</th>\n",
       "      <th>C14_GSM656238</th>\n",
       "      <th>C16_GSM285582</th>\n",
       "      <th>C16_GSM285595</th>\n",
       "      <th>C16_GSM656239</th>\n",
       "      <th>C18_GSM285583</th>\n",
       "      <th>C18_GSM285596</th>\n",
       "      <th>C18_GSM656240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>6.928782</td>\n",
       "      <td>7.264201</td>\n",
       "      <td>6.934214</td>\n",
       "      <td>6.732989</td>\n",
       "      <td>6.970612</td>\n",
       "      <td>7.150978</td>\n",
       "      <td>6.126826</td>\n",
       "      <td>6.868968</td>\n",
       "      <td>6.641119</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450318</td>\n",
       "      <td>8.049750</td>\n",
       "      <td>7.788162</td>\n",
       "      <td>7.052154</td>\n",
       "      <td>6.517742</td>\n",
       "      <td>6.918501</td>\n",
       "      <td>6.048861</td>\n",
       "      <td>7.041619</td>\n",
       "      <td>6.757932</td>\n",
       "      <td>5.817246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>9.633489</td>\n",
       "      <td>9.977124</td>\n",
       "      <td>10.027529</td>\n",
       "      <td>9.720665</td>\n",
       "      <td>9.605762</td>\n",
       "      <td>10.225542</td>\n",
       "      <td>10.279608</td>\n",
       "      <td>10.459966</td>\n",
       "      <td>10.693337</td>\n",
       "      <td>...</td>\n",
       "      <td>11.130466</td>\n",
       "      <td>11.207738</td>\n",
       "      <td>11.009172</td>\n",
       "      <td>10.615417</td>\n",
       "      <td>11.038938</td>\n",
       "      <td>11.009222</td>\n",
       "      <td>10.216348</td>\n",
       "      <td>11.099187</td>\n",
       "      <td>11.172276</td>\n",
       "      <td>10.561021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>5.066343</td>\n",
       "      <td>4.767264</td>\n",
       "      <td>5.010981</td>\n",
       "      <td>6.139047</td>\n",
       "      <td>4.619361</td>\n",
       "      <td>4.751761</td>\n",
       "      <td>5.818550</td>\n",
       "      <td>5.342529</td>\n",
       "      <td>5.483750</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314438</td>\n",
       "      <td>7.423571</td>\n",
       "      <td>7.507645</td>\n",
       "      <td>7.417087</td>\n",
       "      <td>7.147801</td>\n",
       "      <td>7.747930</td>\n",
       "      <td>7.093641</td>\n",
       "      <td>7.672685</td>\n",
       "      <td>7.511290</td>\n",
       "      <td>6.890117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>4.696881</td>\n",
       "      <td>4.638401</td>\n",
       "      <td>4.956299</td>\n",
       "      <td>6.942556</td>\n",
       "      <td>5.101252</td>\n",
       "      <td>4.730307</td>\n",
       "      <td>8.457690</td>\n",
       "      <td>4.526411</td>\n",
       "      <td>4.908300</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250233</td>\n",
       "      <td>4.974993</td>\n",
       "      <td>5.747498</td>\n",
       "      <td>5.252167</td>\n",
       "      <td>5.210531</td>\n",
       "      <td>7.083187</td>\n",
       "      <td>5.252222</td>\n",
       "      <td>5.037613</td>\n",
       "      <td>5.495281</td>\n",
       "      <td>5.013987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000030</td>\n",
       "      <td>4.654278</td>\n",
       "      <td>4.537105</td>\n",
       "      <td>4.928739</td>\n",
       "      <td>5.063991</td>\n",
       "      <td>4.584168</td>\n",
       "      <td>4.911880</td>\n",
       "      <td>5.935311</td>\n",
       "      <td>4.519470</td>\n",
       "      <td>4.757861</td>\n",
       "      <td>...</td>\n",
       "      <td>4.651688</td>\n",
       "      <td>4.920573</td>\n",
       "      <td>4.636333</td>\n",
       "      <td>4.883712</td>\n",
       "      <td>4.779395</td>\n",
       "      <td>4.744335</td>\n",
       "      <td>4.513140</td>\n",
       "      <td>4.838428</td>\n",
       "      <td>4.961475</td>\n",
       "      <td>4.653340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  Ll_GSM283687  Ll_GSM284355  Ll_GSM284362  Lm_GSM283690  \\\n",
       "0  TTHERM_000000042      6.928782      7.264201      6.934214      6.732989   \n",
       "1  TTHERM_000000045      9.633489      9.977124     10.027529      9.720665   \n",
       "2   TTHERM_00000010      5.066343      4.767264      5.010981      6.139047   \n",
       "3   TTHERM_00000020      4.696881      4.638401      4.956299      6.942556   \n",
       "4   TTHERM_00000030      4.654278      4.537105      4.928739      5.063991   \n",
       "\n",
       "   Lm_GSM284357  Lm_GSM284363  Lh_GSM283691  Lh_GSM284360  Lh_GSM284364  ...  \\\n",
       "0      6.970612      7.150978      6.126826      6.868968      6.641119  ...   \n",
       "1      9.605762     10.225542     10.279608     10.459966     10.693337  ...   \n",
       "2      4.619361      4.751761      5.818550      5.342529      5.483750  ...   \n",
       "3      5.101252      4.730307      8.457690      4.526411      4.908300  ...   \n",
       "4      4.584168      4.911880      5.935311      4.519470      4.757861  ...   \n",
       "\n",
       "   C12_GSM656237  C14_GSM285580  C14_GSM285593  C14_GSM656238  C16_GSM285582  \\\n",
       "0       6.450318       8.049750       7.788162       7.052154       6.517742   \n",
       "1      11.130466      11.207738      11.009172      10.615417      11.038938   \n",
       "2       6.314438       7.423571       7.507645       7.417087       7.147801   \n",
       "3       5.250233       4.974993       5.747498       5.252167       5.210531   \n",
       "4       4.651688       4.920573       4.636333       4.883712       4.779395   \n",
       "\n",
       "   C16_GSM285595  C16_GSM656239  C18_GSM285583  C18_GSM285596  C18_GSM656240  \n",
       "0       6.918501       6.048861       7.041619       6.757932       5.817246  \n",
       "1      11.009222      10.216348      11.099187      11.172276      10.561021  \n",
       "2       7.747930       7.093641       7.672685       7.511290       6.890117  \n",
       "3       7.083187       5.252222       5.037613       5.495281       5.013987  \n",
       "4       4.744335       4.513140       4.838428       4.961475       4.653340  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_norm_df = normalize_expression_per_gene(full_filtered_df)\n",
    "raw_data = full_filtered_norm_df[list(full_filtered_norm_df.columns)[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# X, _ = make_blobs(n_samples=10000, n_features=30, centers=350, cluster_std=1.0, random_state=42)  # Use only 2 features\n",
    "# # Convert X to a DataFrame\n",
    "# columns = ['feature' + str(i) for i in range(X.shape[1])]\n",
    "# df = pd.DataFrame(X, columns=columns)\n",
    "# raw_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_distance_matrix(data_df, metric, n_jobs=-1):\n",
    "    \n",
    "    return pairwise_distances(data_df, metric=metric, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nns(data_df, nn, metric, random_state=42, n_jobs=-1):\n",
    "    \n",
    "    # num_neighbors = NearestNeighbors(n_neighbors=nn, metric='precomputed', n_jobs=-1).fit(manhattan_distance_matrix)\n",
    "    # nn_dists, nn_idxs = num_neighbors.kneighbors(return_distance=True)\n",
    "\n",
    "    n_trees = min(64, 5 + int(round((raw_data.shape[0]) ** 0.5 / 20.0)))\n",
    "    n_iters = max(5, int(round(np.log2(raw_data.shape[0]))))\n",
    "    knn_search_index = NNDescent(\n",
    "                data_df,\n",
    "                n_neighbors=nn,\n",
    "                metric=metric,\n",
    "                # metric_kwds=metric_kwds,\n",
    "                random_state=random_state,\n",
    "                n_trees=n_trees,\n",
    "                n_iters=n_iters,\n",
    "                max_candidates=60,\n",
    "                # low_memory=low_memory,\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=False,\n",
    "                compressed=False,\n",
    "            )\n",
    "    nn_idxs, nn_dists = knn_search_index.neighbor_graph\n",
    "\n",
    "    return nn_idxs, nn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_umap_graph(data_df, nn, metric, nn_idxs, nn_dists):\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data_df, nn, 42, metric, knn_indices=nn_idxs, knn_dists=nn_dists, return_dists=True)\n",
    "\n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "\n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leiden_partition(graph, resolution_parameter, random_state=42):\n",
    "        \n",
    "        partition = la.find_partition(graph, la.CPMVertexPartition, resolution_parameter = resolution_parameter, seed=random_state, weights='weight')\n",
    "        # partition = la.find_partition(g, la.ModularityVertexPartition, seed=42, weights='weight')\n",
    "\n",
    "        leiden_modules = np.array(partition.membership)\n",
    "\n",
    "        return leiden_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_communities(parition, idx_labels):\n",
    "    communities = {}\n",
    "\n",
    "    for idx, membership in enumerate(parition):\n",
    "        if membership not in communities:\n",
    "            communities[membership] = []\n",
    "        communities[membership].append(idx_labels[idx])\n",
    "\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_silhouette_score(distance_matrix, parition):\n",
    "    return silhouette_score(distance_matrix, parition, metric='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_modularity(graph, communities):\n",
    "    nx_g = nx.Graph(graph.get_edgelist())\n",
    "    return nx.community.quality.modularity(nx_g, communities, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_parition_for_enrichment(df, parition):\n",
    "    edf = pd.DataFrame.from_dict({'TTHERM_ID': []})\n",
    "    edf['TTHERM_ID'] = df['TTHERM_ID'].values\n",
    "    edf[f'leiden_label_full'] = parition\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment(df, parition):\n",
    "    edf = format_parition_for_enrichment(df, parition)\n",
    "\n",
    "    temp_scan_file = './temp_scan_partition.csv'\n",
    "\n",
    "    temp_enrich_file = './temp_scan_enrich.csv'\n",
    "\n",
    "    edf.to_csv(temp_scan_file, index=False)\n",
    "\n",
    "    subprocess.run(['python3', './fast_enrichment_analysis.py', temp_scan_file, temp_enrich_file])\n",
    "\n",
    "    cedf = pd.read_csv(temp_enrich_file)\n",
    "    \n",
    "    remove_file(temp_scan_file)\n",
    "\n",
    "    remove_file(temp_enrich_file)\n",
    "\n",
    "    return cedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_clusters(parition, communities=None):\n",
    "    if communities is None:\n",
    "        return len(set(parition))\n",
    "    \n",
    "    if len(set(parition)) != len(communities):\n",
    "        raise ValueError(f'The number of clusters/modules ({len(set(parition))}) in the parition != the number of communities ({len(communities)}).')\n",
    "    \n",
    "    return len(set(parition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_sizes(communities):\n",
    "    return [len(community) for community in communities.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enriched_cluster_sizes(communities, cedf):\n",
    "    enriched_cluster_mods = set(cedf['module'].values)\n",
    "    return [len(community) for mod, community in communities.items() if mod in enriched_cluster_mods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_size_mean(cluster_sizes):\n",
    "    return np.mean(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_median(cluster_sizes):\n",
    "    return np.median(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_sd(cluster_sizes):\n",
    "    return np.std(cluster_sizes)\n",
    "\n",
    "def compute_cluster_size_sd(cluster_sizes):\n",
    "    return np.std(cluster_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_clusters(cedf):\n",
    "    return len(set(cedf['module'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_enriched_cluster_genes(edf, parition):\n",
    "    total_num_genes = 0\n",
    "\n",
    "    for m in set(edf['module'].values):\n",
    "        num_genes = np.count_nonzero(parition == int(m))\n",
    "        total_num_genes += num_genes\n",
    "    \n",
    "    return total_num_genes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(csv_file_path, data_item, header):\n",
    "    # Check if the CSV file exists and write header if it doesn't\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        with open(csv_file_path, 'w', newline='') as file:\n",
    "            writer = DictWriter(file, fieldnames=header)\n",
    "            writer.writeheader()\n",
    "\n",
    "    with open(csv_file_path, 'a', newline='') as file:\n",
    "        writer = DictWriter(file, fieldnames=header)\n",
    "        writer.writerow(data_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_labels = list(range(raw_data.shape[0]))\n",
    "\n",
    "metric = 'manhattan'\n",
    "n_jobs = -1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_nns = np.arange(2, 13, 1)\n",
    "# scan_nns = [3]\n",
    "scan_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.005, 0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045,\n",
       "       0.05 , 0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 ,\n",
       "       0.095, 0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 , 0.135,\n",
       "       0.14 , 0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175, 0.18 ,\n",
       "       0.185, 0.19 , 0.195, 0.2  , 0.205, 0.21 , 0.215, 0.22 , 0.225,\n",
       "       0.23 , 0.235, 0.24 , 0.245, 0.25 , 0.255, 0.26 , 0.265, 0.27 ,\n",
       "       0.275, 0.28 , 0.285, 0.29 , 0.295, 0.3  , 0.305, 0.31 , 0.315,\n",
       "       0.32 , 0.325, 0.33 , 0.335, 0.34 , 0.345, 0.35 , 0.355, 0.36 ,\n",
       "       0.365, 0.37 , 0.375, 0.38 , 0.385, 0.39 , 0.395, 0.4  , 0.405,\n",
       "       0.41 , 0.415, 0.42 , 0.425, 0.43 , 0.435, 0.44 , 0.445, 0.45 ,\n",
       "       0.455, 0.46 , 0.465, 0.47 , 0.475, 0.48 , 0.485, 0.49 , 0.495,\n",
       "       0.5  , 0.505, 0.51 , 0.515, 0.52 , 0.525, 0.53 , 0.535, 0.54 ,\n",
       "       0.545, 0.55 , 0.555, 0.56 , 0.565, 0.57 , 0.575, 0.58 , 0.585,\n",
       "       0.59 , 0.595, 0.6  , 0.605, 0.61 , 0.615, 0.62 , 0.625, 0.63 ,\n",
       "       0.635, 0.64 , 0.645, 0.65 , 0.655, 0.66 , 0.665, 0.67 , 0.675,\n",
       "       0.68 , 0.685, 0.69 , 0.695, 0.7  , 0.705, 0.71 , 0.715, 0.72 ,\n",
       "       0.725, 0.73 , 0.735, 0.74 , 0.745, 0.75 , 0.755, 0.76 , 0.765,\n",
       "       0.77 , 0.775, 0.78 , 0.785, 0.79 , 0.795, 0.8  , 0.805, 0.81 ,\n",
       "       0.815, 0.82 , 0.825, 0.83 , 0.835, 0.84 , 0.845, 0.85 , 0.855,\n",
       "       0.86 , 0.865, 0.87 , 0.875, 0.88 , 0.885, 0.89 , 0.895, 0.9  ,\n",
       "       0.905, 0.91 , 0.915, 0.92 , 0.925, 0.93 , 0.935, 0.94 , 0.945,\n",
       "       0.95 , 0.955, 0.96 , 0.965, 0.97 , 0.975, 0.98 , 0.985, 0.99 ,\n",
       "       0.995, 1.   , 1.005, 1.01 , 1.015, 1.02 , 1.025, 1.03 , 1.035,\n",
       "       1.04 , 1.045, 1.05 , 1.055, 1.06 , 1.065, 1.07 , 1.075, 1.08 ,\n",
       "       1.085, 1.09 , 1.095, 1.1  ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scan_rps = np.arange(0.005, 1.1, 0.005)\n",
    "scan_rps = np.arange(0.1, 1.1, 0.1)\n",
    "# scan_rps = [0.6]\n",
    "scan_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = compute_pairwise_distance_matrix(raw_data, metric, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, nn in enumerate(scan_nns):     \n",
    "    print(idx+1,'of',len(scan_nns))     \n",
    "    print('NNs: ', nn)\n",
    "\n",
    "    scan_dict[nn] = {}\n",
    "\n",
    "    nn_idxs, nn_dists = compute_nns(raw_data, nn, metric, random_state, n_jobs)\n",
    "    scan_dict[nn]['nn_idxs'] = nn_idxs\n",
    "    scan_dict[nn]['nn_dists'] = nn_dists\n",
    "\n",
    "    nn_graph = compute_umap_graph(raw_data, nn, metric, nn_idxs, nn_dists)\n",
    "    scan_dict[nn]['nn_graph'] = nn_graph\n",
    "\n",
    "    for rp in tqdm.tqdm(scan_rps):\n",
    "\n",
    "        scan_dict[nn][rp] = {}\n",
    "        \n",
    "        parition = compute_leiden_partition(nn_graph, rp, random_state)\n",
    "        scan_dict[nn][rp]['partition'] = parition\n",
    "\n",
    "        communities = compute_communities(parition, idx_labels)\n",
    "        scan_dict[nn][rp]['communities'] = communities\n",
    "\n",
    "        sil_score = compute_silhouette_score(distance_matrix, parition)\n",
    "        scan_dict[nn][rp]['sil_score'] = sil_score\n",
    "\n",
    "        modularity = compute_modularity(nn_graph, communities.values())\n",
    "        scan_dict[nn][rp]['modularity'] = modularity\n",
    "\n",
    "        enrichment_df = compute_enrichment(full_filtered_norm_df, parition)\n",
    "        scan_dict[nn][rp]['enrichment_df'] = enrichment_df\n",
    "\n",
    "        num_clusters = compute_num_clusters(parition, communities.values())\n",
    "        scan_dict[nn][rp]['num_clusters'] = num_clusters\n",
    "\n",
    "        num_enriched_clusters = compute_num_enriched_clusters(enrichment_df)\n",
    "        scan_dict[nn][rp]['num_enriched_clusters'] = num_enriched_clusters\n",
    "\n",
    "        num_enriched_cluster_genes = compute_num_enriched_cluster_genes(enrichment_df, parition)\n",
    "        scan_dict[nn][rp]['num_enriched_cluster_genes'] = num_enriched_cluster_genes\n",
    "\n",
    "        cluster_sizes = compute_cluster_sizes(communities)\n",
    "        scan_dict[nn][rp]['cluster_sizes'] = cluster_sizes\n",
    "\n",
    "        enriched_cluster_sizes = compute_enriched_cluster_sizes(communities, enrichment_df)\n",
    "        scan_dict[nn][rp]['enriched_cluster_sizes'] = enriched_cluster_sizes\n",
    "\n",
    "        cluster_stats = {\n",
    "        'partition_type': partition_type,\n",
    "\n",
    "        'dimensionality': 'baseline',\n",
    "\n",
    "        'metric': metric,\n",
    "        'graph': 'umap_fuzzy_simplicial_set',\n",
    "        'nns': nn,\n",
    "\n",
    "        'clustering': 'leiden_cpm',\n",
    "        'parameter': rp,\n",
    "\n",
    "        'silhouette_score': sil_score,\n",
    "        'modularity': modularity,\n",
    "\n",
    "        'nclusters': num_clusters,\n",
    "        'mean_cluster_size': compute_cluster_size_mean(cluster_sizes),\n",
    "        'median_cluster_size': compute_cluster_size_median(cluster_sizes),\n",
    "        'sd_cluster_size': compute_cluster_size_sd(cluster_sizes),\n",
    "\n",
    "        'nenriched_clusters': num_enriched_clusters,\n",
    "        'mean_enriched_cluster_size': compute_cluster_size_mean(enriched_cluster_sizes),\n",
    "        'median_enriched_cluster_size': compute_cluster_size_median(enriched_cluster_sizes),\n",
    "        'sd_enriched_cluster_size': compute_cluster_size_sd(enriched_cluster_sizes),\n",
    "        'nenriched_cluster_genes': num_enriched_cluster_genes,\n",
    "\n",
    "        'datetime': curr_datetime\n",
    "        }\n",
    "\n",
    "        write_to_csv('./scan_stats_v1.csv', cluster_stats, list(cluster_stats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition_type</th>\n",
       "      <th>dimensionality</th>\n",
       "      <th>metric</th>\n",
       "      <th>graph</th>\n",
       "      <th>nns</th>\n",
       "      <th>clustering</th>\n",
       "      <th>parameter</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>modularity</th>\n",
       "      <th>nclusters</th>\n",
       "      <th>mean_cluster_size</th>\n",
       "      <th>median_cluster_size</th>\n",
       "      <th>sd_cluster_size</th>\n",
       "      <th>nenriched_clusters</th>\n",
       "      <th>mean_enriched_cluster_size</th>\n",
       "      <th>median_enriched_cluster_size</th>\n",
       "      <th>sd_enriched_cluster_size</th>\n",
       "      <th>nenriched_cluster_genes</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXP</td>\n",
       "      <td>baseline</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>umap_fuzzy_simplicial_set</td>\n",
       "      <td>3</td>\n",
       "      <td>leiden_cpm</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.422344</td>\n",
       "      <td>7759</td>\n",
       "      <td>2.619667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.842902</td>\n",
       "      <td>491</td>\n",
       "      <td>3.034623</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.856759</td>\n",
       "      <td>1490</td>\n",
       "      <td>2024-02-02 14:43:14.355357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXP</td>\n",
       "      <td>baseline</td>\n",
       "      <td>clr</td>\n",
       "      <td>umap_fuzzy_simplicial_set</td>\n",
       "      <td>12</td>\n",
       "      <td>leiden_cpm</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.016423</td>\n",
       "      <td>0.294406</td>\n",
       "      <td>1905</td>\n",
       "      <td>10.669816</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.476522</td>\n",
       "      <td>316</td>\n",
       "      <td>12.841772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.938527</td>\n",
       "      <td>4058</td>\n",
       "      <td>2024-02-02 15:37:14.079288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXP</td>\n",
       "      <td>baseline</td>\n",
       "      <td>clr</td>\n",
       "      <td>umap_fuzzy_simplicial_set</td>\n",
       "      <td>12</td>\n",
       "      <td>leiden_cpm</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.299335</td>\n",
       "      <td>1839</td>\n",
       "      <td>11.052746</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.651367</td>\n",
       "      <td>301</td>\n",
       "      <td>14.926910</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.206584</td>\n",
       "      <td>4493</td>\n",
       "      <td>2024-02-02 15:47:45.611361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXP</td>\n",
       "      <td>baseline</td>\n",
       "      <td>clr</td>\n",
       "      <td>umap_fuzzy_simplicial_set</td>\n",
       "      <td>3</td>\n",
       "      <td>leiden_cpm</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.536167</td>\n",
       "      <td>2714</td>\n",
       "      <td>7.489315</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.523887</td>\n",
       "      <td>345</td>\n",
       "      <td>8.631884</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.948962</td>\n",
       "      <td>2978</td>\n",
       "      <td>2024-02-02 15:50:51.602937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition_type dimensionality     metric                      graph  nns  \\\n",
       "0            EXP       baseline  manhattan  umap_fuzzy_simplicial_set    3   \n",
       "1            EXP       baseline        clr  umap_fuzzy_simplicial_set   12   \n",
       "2            EXP       baseline        clr  umap_fuzzy_simplicial_set   12   \n",
       "3            EXP       baseline        clr  umap_fuzzy_simplicial_set    3   \n",
       "\n",
       "   clustering  parameter  silhouette_score  modularity  nclusters  \\\n",
       "0  leiden_cpm      0.600          0.024209    0.422344       7759   \n",
       "1  leiden_cpm      0.095         -0.016423    0.294406       1905   \n",
       "2  leiden_cpm      0.095          0.020106    0.299335       1839   \n",
       "3  leiden_cpm      0.100          0.015219    0.536167       2714   \n",
       "\n",
       "   mean_cluster_size  median_cluster_size  sd_cluster_size  \\\n",
       "0           2.619667                  2.0         0.842902   \n",
       "1          10.669816                 10.0         5.476522   \n",
       "2          11.052746                 10.0         5.651367   \n",
       "3           7.489315                  7.0         2.523887   \n",
       "\n",
       "   nenriched_clusters  mean_enriched_cluster_size  \\\n",
       "0                 491                    3.034623   \n",
       "1                 316                   12.841772   \n",
       "2                 301                   14.926910   \n",
       "3                 345                    8.631884   \n",
       "\n",
       "   median_enriched_cluster_size  sd_enriched_cluster_size  \\\n",
       "0                           3.0                  0.856759   \n",
       "1                          12.0                  5.938527   \n",
       "2                          13.0                  7.206584   \n",
       "3                           8.0                  2.948962   \n",
       "\n",
       "   nenriched_cluster_genes                    datetime  \n",
       "0                     1490  2024-02-02 14:43:14.355357  \n",
       "1                     4058  2024-02-02 15:37:14.079288  \n",
       "2                     4493  2024-02-02 15:47:45.611361  \n",
       "3                     2978  2024-02-02 15:50:51.602937  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./scan_stats_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
