{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils import file_utils, microarray_utils, clustering_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_2d_arr(arr: np.array):\n",
    "\n",
    "    flat_arr = arr.flatten()\n",
    "\n",
    "    non_inf_mask = flat_arr != float('inf')\n",
    "\n",
    "    max_val = max(flat_arr[non_inf_mask])\n",
    "    min_val = min(flat_arr)\n",
    "\n",
    "    scaled_arr = (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19152, 19153)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>TTHERM_00161860</th>\n",
       "      <th>TTHERM_00161850</th>\n",
       "      <th>TTHERM_00161840</th>\n",
       "      <th>TTHERM_00161830</th>\n",
       "      <th>TTHERM_00161790</th>\n",
       "      <th>TTHERM_00161780</th>\n",
       "      <th>TTHERM_000161759</th>\n",
       "      <th>YF00000015.t1</th>\n",
       "      <th>TTHERM_00161750</th>\n",
       "      <th>...</th>\n",
       "      <th>YF00038356.t1</th>\n",
       "      <th>YF00038359.t1</th>\n",
       "      <th>YF00038369.t1</th>\n",
       "      <th>TTHERM_01068130</th>\n",
       "      <th>YF00038374.t1</th>\n",
       "      <th>TTHERM_01082890</th>\n",
       "      <th>YF00038376.t1</th>\n",
       "      <th>YF00038377.t1</th>\n",
       "      <th>TTHERM_000989489</th>\n",
       "      <th>YF00038707.t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_00161860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543918</td>\n",
       "      <td>0.564497</td>\n",
       "      <td>1.795590</td>\n",
       "      <td>0.313840</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>2.419623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.033022</td>\n",
       "      <td>0.389918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083429</td>\n",
       "      <td>2.279135e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_00161850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686763</td>\n",
       "      <td>2.135465</td>\n",
       "      <td>1.699125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.486166</td>\n",
       "      <td>1.705012</td>\n",
       "      <td>1.051820</td>\n",
       "      <td>0.215377</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>0.369555</td>\n",
       "      <td>1.415799</td>\n",
       "      <td>0.090829</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_00161840</td>\n",
       "      <td>0.543918</td>\n",
       "      <td>0.686763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.483143</td>\n",
       "      <td>3.913495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.180952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.743875</td>\n",
       "      <td>...</td>\n",
       "      <td>2.070992</td>\n",
       "      <td>3.006552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.100472</td>\n",
       "      <td>7.434962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.123949</td>\n",
       "      <td>0.266449</td>\n",
       "      <td>6.463274e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00161830</td>\n",
       "      <td>0.564497</td>\n",
       "      <td>2.135465</td>\n",
       "      <td>5.483143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.678584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660915</td>\n",
       "      <td>1.176764</td>\n",
       "      <td>7.790436</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388236</td>\n",
       "      <td>0.444909</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>2.406114</td>\n",
       "      <td>3.187094</td>\n",
       "      <td>0.833351</td>\n",
       "      <td>0.160117</td>\n",
       "      <td>1.502441</td>\n",
       "      <td>0.501382</td>\n",
       "      <td>3.658593e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00161790</td>\n",
       "      <td>1.795590</td>\n",
       "      <td>1.699125</td>\n",
       "      <td>3.913495</td>\n",
       "      <td>1.678584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>2.805641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043043</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347756</td>\n",
       "      <td>0.413893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.885174</td>\n",
       "      <td>1.073879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.052553</td>\n",
       "      <td>3.613635e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TTHERM_ID  TTHERM_00161860  TTHERM_00161850  TTHERM_00161840  \\\n",
       "0  TTHERM_00161860         0.000000         0.000000         0.543918   \n",
       "1  TTHERM_00161850         0.000000         0.000000         0.686763   \n",
       "2  TTHERM_00161840         0.543918         0.686763         0.000000   \n",
       "3  TTHERM_00161830         0.564497         2.135465         5.483143   \n",
       "4  TTHERM_00161790         1.795590         1.699125         3.913495   \n",
       "\n",
       "   TTHERM_00161830  TTHERM_00161790  TTHERM_00161780  TTHERM_000161759  \\\n",
       "0         0.564497         1.795590         0.313840          0.007242   \n",
       "1         2.135465         1.699125         0.000000          0.000000   \n",
       "2         5.483143         3.913495         0.000000          3.180952   \n",
       "3         0.000000         1.678584         0.000000          1.660915   \n",
       "4         1.678584         0.000000         0.014669          2.805641   \n",
       "\n",
       "   YF00000015.t1  TTHERM_00161750  ...  YF00038356.t1  YF00038359.t1  \\\n",
       "0       2.419623         0.000000  ...       0.000000       0.070759   \n",
       "1       0.000000         0.056121  ...       0.000000       1.486166   \n",
       "2       0.000000         2.743875  ...       2.070992       3.006552   \n",
       "3       1.176764         7.790436  ...       1.388236       0.444909   \n",
       "4       0.000000         0.043043  ...       1.347756       0.413893   \n",
       "\n",
       "   YF00038369.t1  TTHERM_01068130  YF00038374.t1  TTHERM_01082890  \\\n",
       "0       0.000000         2.033022       0.389918         0.000000   \n",
       "1       1.705012         1.051820       0.215377         0.083254   \n",
       "2       0.000000         4.100472       7.434962         0.000000   \n",
       "3       0.804840         2.406114       3.187094         0.833351   \n",
       "4       0.000000         4.885174       1.073879         0.000000   \n",
       "\n",
       "   YF00038376.t1  YF00038377.t1  TTHERM_000989489  YF00038707.t1  \n",
       "0       0.690990       0.000000          0.083429   2.279135e+00  \n",
       "1       0.369555       1.415799          0.090829   0.000000e+00  \n",
       "2       0.000000       1.123949          0.266449   6.463274e-01  \n",
       "3       0.160117       1.502441          0.501382   3.658593e-07  \n",
       "4       0.005489       0.030675          0.052553   3.613635e+00  \n",
       "\n",
       "[5 rows x 19153 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.read_csv('./clr_network_for_distances.csv')\n",
    "clr_df.rename(columns={'Unnamed: 0':'TTHERM_ID'}, inplace=True)\n",
    "print(clr_df.shape)\n",
    "clr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n",
      "(array([    0,     0,     0, ..., 19151, 19151, 19151]), array([    0,     1,     8, ..., 19148, 19150, 19151]))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "max_zscore = clr_df.max(axis=None, numeric_only=True)\n",
    "min_zscore = clr_df.min(axis=None, numeric_only=True)\n",
    "zscore_arr = clr_df.loc[:,clr_df.columns[1:]].to_numpy()\n",
    "\n",
    "info = np.finfo(np.float64)\n",
    "smallest_float = info.eps\n",
    "\n",
    "# sys.float_info.min\n",
    "# sys.float_info.epsilon\n",
    "\n",
    "scaled_zscore_arr = min_max_scale_2d_arr(zscore_arr)\n",
    "zero_zscore_idxs = np.where(scaled_zscore_arr == 0)\n",
    "clr_dist_arr = (1 - scaled_zscore_arr) + smallest_float\n",
    "\n",
    "print(min((clr_dist_arr[np.where(clr_dist_arr > 0)]).flatten()))\n",
    "print(np.where(clr_dist_arr > 1))\n",
    "print(np.where(clr_dist_arr == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_type = 'EXP'\n",
    "full_filtered_df = pd.read_csv('../microarray_probe_alignment_and_filtering/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')\n",
    "full_filtered_df = full_filtered_df.rename(columns={'Unnamed: 0': 'TTHERM_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_filtered_df = shuffle_rows(full_filtered_df)\n",
    "# partition_type = 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_norm_df = microarray_utils.normalize_expression_per_gene(full_filtered_df)\n",
    "raw_data = full_filtered_norm_df[list(full_filtered_norm_df.columns)[1:]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_labels = list(range(raw_data.shape[0]))\n",
    "\n",
    "p_minkowski = None\n",
    "# metrics = ['manhattan', 'euclidean', 'cosine'] + [f'minkowski_{str(p)}' for p in np.array([0.5, 1, 2, 3, 4, 5])]\n",
    "# metrics = ['clr', 'manhattan', 'euclidean', 'cosine'] + [f'minkowski_{str(p)}' for p in np.array([0.5, 1, 2, 3, 4, 5])]\n",
    "metrics = ['clr']\n",
    "# metrics = ['manhattan']\n",
    "n_jobs = -1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_nns = np.arange(2, 13, 1)\n",
    "# scan_nns = [5]\n",
    "scan_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_rps = np.arange(0.005, 1.1, 0.005)\n",
    "scan_rps = np.arange(0.1, 1.1, 0.1)\n",
    "# scan_rps = [0.030, 0.035]\n",
    "scan_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_p in metrics:\n",
    "    metric_p_split = metric_p.split('_')\n",
    "\n",
    "    metric = metric_p\n",
    "\n",
    "    if metric_p_split[0] == 'minkowski':\n",
    "        metric = metric_p_split[0]\n",
    "        p_minkowski = float(metric_p_split[1])\n",
    "\n",
    "    if metric != 'clr':\n",
    "        distance_matrix = clustering_utils.compute_pairwise_distance_matrix(raw_data, metric, n_jobs, p_minkowski)\n",
    "    else:\n",
    "        distance_matrix = clr_dist_arr\n",
    "\n",
    "    nn_idxs, nn_dists = clustering_utils.compute_nns(raw_data, max(scan_nns), metric, random_state, n_jobs, p_minkowski, distance_matrix)\n",
    "\n",
    "    for idx, nn in enumerate(scan_nns):     \n",
    "        print(idx+1,'of',len(scan_nns))     \n",
    "        print('NNs: ', nn)\n",
    "\n",
    "        scan_dict[nn] = {}\n",
    "\n",
    "        scan_dict[nn]['nn_idxs'] = nn_idxs\n",
    "        scan_dict[nn]['nn_dists'] = nn_dists\n",
    "\n",
    "        nn_graph = clustering_utils.compute_umap_graph(raw_data, nn, metric, nn_idxs, nn_dists)\n",
    "        scan_dict[nn]['nn_graph'] = nn_graph\n",
    "\n",
    "        for rp in tqdm.tqdm(scan_rps):\n",
    "\n",
    "            scan_dict[nn][rp] = {}\n",
    "            \n",
    "            partition = clustering_utils.compute_leiden_partition(nn_graph, rp, random_state)\n",
    "            scan_dict[nn][rp]['partition'] = partition\n",
    "\n",
    "            communities = clustering_utils.compute_communities(partition, idx_labels)\n",
    "            scan_dict[nn][rp]['communities'] = communities\n",
    "\n",
    "            sil_score = clustering_utils.compute_silhouette_score(distance_matrix, partition)\n",
    "            scan_dict[nn][rp]['sil_score'] = sil_score\n",
    "\n",
    "            modularity = clustering_utils.compute_modularity(nn_graph, communities.values())\n",
    "            scan_dict[nn][rp]['modularity'] = modularity\n",
    "\n",
    "            enrichment_df = clustering_utils.compute_enrichment(full_filtered_norm_df, partition)\n",
    "            scan_dict[nn][rp]['enrichment_df'] = enrichment_df\n",
    "\n",
    "            num_clusters = clustering_utils.compute_num_clusters(partition, communities.values())\n",
    "            scan_dict[nn][rp]['num_clusters'] = num_clusters\n",
    "\n",
    "            num_enriched_clusters = clustering_utils.compute_num_enriched_clusters(enrichment_df)\n",
    "            scan_dict[nn][rp]['num_enriched_clusters'] = num_enriched_clusters\n",
    "\n",
    "            num_enriched_cluster_genes = clustering_utils.compute_num_enriched_cluster_genes(enrichment_df, partition)\n",
    "            scan_dict[nn][rp]['num_enriched_cluster_genes'] = num_enriched_cluster_genes\n",
    "\n",
    "            cluster_sizes = clustering_utils.compute_cluster_sizes(communities)\n",
    "            scan_dict[nn][rp]['cluster_sizes'] = cluster_sizes\n",
    "\n",
    "            enriched_cluster_sizes = clustering_utils.compute_enriched_cluster_sizes(communities, enrichment_df)\n",
    "            scan_dict[nn][rp]['enriched_cluster_sizes'] = enriched_cluster_sizes\n",
    "\n",
    "            cluster_stats = {\n",
    "            'partition_type': partition_type,\n",
    "\n",
    "            'dimensionality': 'baseline',\n",
    "\n",
    "            'metric': metric_p,\n",
    "            'graph': 'umap_fuzzy_simplicial_set',\n",
    "            'nns': nn,\n",
    "\n",
    "            'clustering': 'leiden_cpm',\n",
    "            'parameter': rp,\n",
    "\n",
    "            'silhouette_score': sil_score,\n",
    "            'modularity': modularity,\n",
    "\n",
    "            'nclusters': num_clusters,\n",
    "            'mean_cluster_size': clustering_utils.compute_cluster_size_mean(cluster_sizes),\n",
    "            'median_cluster_size': clustering_utils.compute_cluster_size_median(cluster_sizes),\n",
    "            'sd_cluster_size': clustering_utils.compute_cluster_size_sd(cluster_sizes),\n",
    "\n",
    "            'nenriched_clusters': num_enriched_clusters,\n",
    "            'mean_enriched_cluster_size': clustering_utils.compute_cluster_size_mean(enriched_cluster_sizes),\n",
    "            'median_enriched_cluster_size': clustering_utils.compute_cluster_size_median(enriched_cluster_sizes),\n",
    "            'sd_enriched_cluster_size': clustering_utils.compute_cluster_size_sd(enriched_cluster_sizes),\n",
    "            'nenriched_cluster_genes': num_enriched_cluster_genes,\n",
    "\n",
    "            'datetime': curr_datetime\n",
    "            }\n",
    "\n",
    "            file_utils.write_to_csv('./scan_stats_mar2024.csv', cluster_stats, list(cluster_stats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./scan_stats_mar2024.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
