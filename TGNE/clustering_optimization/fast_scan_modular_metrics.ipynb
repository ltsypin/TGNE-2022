{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils import file_utils, microarray_utils, clustering_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19152, 19153)\n",
      "357.178117897014\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.read_csv('./clr_network_for_distances.csv')\n",
    "clr_df.rename(columns={'Unnamed: 0':'TTHERM_ID'}, inplace=True)\n",
    "print(clr_df.shape)\n",
    "clr_df.head()\n",
    "max_zscore = clr_df.max(axis=None, numeric_only=True)\n",
    "max_zscore\n",
    "min_zscore = clr_df.min(axis=None, numeric_only=True)\n",
    "min_zscore\n",
    "zscore_arr = clr_df.loc[:,clr_df.columns[1:]].to_numpy()\n",
    "zscore_arr\n",
    "\n",
    "def min_max_scale_2d_arr(arr: np.array):\n",
    "\n",
    "    flat_arr = arr.flatten()\n",
    "\n",
    "    non_inf_mask = flat_arr != float('inf')\n",
    "\n",
    "    max_val = max(flat_arr[non_inf_mask])\n",
    "    min_val = min(flat_arr)\n",
    "\n",
    "    print(max_val)\n",
    "    print(min_val)\n",
    "\n",
    "    scaled_arr = (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_arr\n",
    "\n",
    "info = np.finfo(np.float64)\n",
    "smallest_float = info.eps\n",
    "\n",
    "sys.float_info.min\n",
    "sys.float_info.epsilon\n",
    "\n",
    "scaled_zscore_arr = min_max_scale_2d_arr(zscore_arr)\n",
    "scaled_zscore_arr\n",
    "zero_zscore_idxs = np.where(scaled_zscore_arr == 0)\n",
    "zero_zscore_idxs\n",
    "clr_dist_arr = (1 - scaled_zscore_arr) + smallest_float\n",
    "clr_dist_arr\n",
    "clr_dist_arr\n",
    "min((clr_dist_arr[np.where(clr_dist_arr > 0)]).flatten())\n",
    "np.where(clr_dist_arr > (1 + sys.float_info.min))\n",
    "np.where(clr_dist_arr == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_type = 'EXP'\n",
    "full_filtered_df = pd.read_csv('../microarray_probe_alignment_and_filtering/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')\n",
    "full_filtered_df = full_filtered_df.rename(columns={'Unnamed: 0': 'TTHERM_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_filtered_df = shuffle_rows(full_filtered_df)\n",
    "# partition_type = 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_filtered_norm_df = microarray_utils.normalize_expression_per_gene(full_filtered_df)\n",
    "raw_data = full_filtered_norm_df[list(full_filtered_norm_df.columns)[1:]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_datetime = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_labels = list(range(raw_data.shape[0]))\n",
    "\n",
    "p_minkowski = None\n",
    "metrics = ['clr', 'manhattan', 'euclidean', 'cosine'] + [f'minkowski_{str(p)}' for p in np.array([0.5, 1, 2, 3, 4, 5])]\n",
    "# metrics = ['manhattan']\n",
    "n_jobs = -1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_nns = np.arange(2, 13, 1)\n",
    "# scan_nns = [5]\n",
    "scan_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_rps = np.arange(0.005, 1.1, 0.005)\n",
    "scan_rps = np.arange(0.1, 1.1, 0.1)\n",
    "# scan_rps = [0.030, 0.035]\n",
    "scan_rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_p in metrics:\n",
    "    metric_p_split = metric_p.split('_')\n",
    "\n",
    "    metric = metric_p\n",
    "\n",
    "    if metric_p_split[0] == 'minkowski':\n",
    "        metric = metric_p_split[0]\n",
    "        p_minkowski = float(metric_p_split[1])\n",
    "\n",
    "    if metric != 'clr':\n",
    "        distance_matrix = clustering_utils.compute_pairwise_distance_matrix(raw_data, metric, n_jobs, p_minkowski)\n",
    "    else:\n",
    "        distance_matrix = clr_dist_arr\n",
    "\n",
    "    nn_idxs, nn_dists = clustering_utils.compute_nns(raw_data, max(scan_nns), metric, random_state, n_jobs, p_minkowski, distance_matrix)\n",
    "\n",
    "    for idx, nn in enumerate(scan_nns):     \n",
    "        print(idx+1,'of',len(scan_nns))     \n",
    "        print('NNs: ', nn)\n",
    "\n",
    "        scan_dict[nn] = {}\n",
    "\n",
    "        scan_dict[nn]['nn_idxs'] = nn_idxs\n",
    "        scan_dict[nn]['nn_dists'] = nn_dists\n",
    "\n",
    "        nn_graph = clustering_utils.compute_umap_graph(raw_data, nn, metric, nn_idxs, nn_dists)\n",
    "        scan_dict[nn]['nn_graph'] = nn_graph\n",
    "\n",
    "        for rp in tqdm.tqdm(scan_rps):\n",
    "\n",
    "            scan_dict[nn][rp] = {}\n",
    "            \n",
    "            partition = clustering_utils.compute_leiden_partition(nn_graph, rp, random_state)\n",
    "            scan_dict[nn][rp]['partition'] = partition\n",
    "\n",
    "            communities = clustering_utils.compute_communities(partition, idx_labels)\n",
    "            scan_dict[nn][rp]['communities'] = communities\n",
    "\n",
    "            sil_score = clustering_utils.compute_silhouette_score(distance_matrix, partition)\n",
    "            scan_dict[nn][rp]['sil_score'] = sil_score\n",
    "\n",
    "            modularity = clustering_utils.compute_modularity(nn_graph, communities.values())\n",
    "            scan_dict[nn][rp]['modularity'] = modularity\n",
    "\n",
    "            enrichment_df = clustering_utils.compute_enrichment(full_filtered_norm_df, partition)\n",
    "            scan_dict[nn][rp]['enrichment_df'] = enrichment_df\n",
    "\n",
    "            num_clusters = clustering_utils.compute_num_clusters(partition, communities.values())\n",
    "            scan_dict[nn][rp]['num_clusters'] = num_clusters\n",
    "\n",
    "            num_enriched_clusters = clustering_utils.compute_num_enriched_clusters(enrichment_df)\n",
    "            scan_dict[nn][rp]['num_enriched_clusters'] = num_enriched_clusters\n",
    "\n",
    "            num_enriched_cluster_genes = clustering_utils.compute_num_enriched_cluster_genes(enrichment_df, partition)\n",
    "            scan_dict[nn][rp]['num_enriched_cluster_genes'] = num_enriched_cluster_genes\n",
    "\n",
    "            cluster_sizes = clustering_utils.compute_cluster_sizes(communities)\n",
    "            scan_dict[nn][rp]['cluster_sizes'] = cluster_sizes\n",
    "\n",
    "            enriched_cluster_sizes = clustering_utils.compute_enriched_cluster_sizes(communities, enrichment_df)\n",
    "            scan_dict[nn][rp]['enriched_cluster_sizes'] = enriched_cluster_sizes\n",
    "\n",
    "            cluster_stats = {\n",
    "            'partition_type': partition_type,\n",
    "\n",
    "            'dimensionality': 'baseline',\n",
    "\n",
    "            'metric': metric_p,\n",
    "            'graph': 'umap_fuzzy_simplicial_set',\n",
    "            'nns': nn,\n",
    "\n",
    "            'clustering': 'leiden_cpm',\n",
    "            'parameter': rp,\n",
    "\n",
    "            'silhouette_score': sil_score,\n",
    "            'modularity': modularity,\n",
    "\n",
    "            'nclusters': num_clusters,\n",
    "            'mean_cluster_size': clustering_utils.compute_cluster_size_mean(cluster_sizes),\n",
    "            'median_cluster_size': clustering_utils.compute_cluster_size_median(cluster_sizes),\n",
    "            'sd_cluster_size': clustering_utils.compute_cluster_size_sd(cluster_sizes),\n",
    "\n",
    "            'nenriched_clusters': num_enriched_clusters,\n",
    "            'mean_enriched_cluster_size': clustering_utils.compute_cluster_size_mean(enriched_cluster_sizes),\n",
    "            'median_enriched_cluster_size': clustering_utils.compute_cluster_size_median(enriched_cluster_sizes),\n",
    "            'sd_enriched_cluster_size': clustering_utils.compute_cluster_size_sd(enriched_cluster_sizes),\n",
    "            'nenriched_cluster_genes': num_enriched_cluster_genes,\n",
    "\n",
    "            'datetime': curr_datetime\n",
    "            }\n",
    "\n",
    "            file_utils.write_to_csv('./scan_stats_mar2024.csv', cluster_stats, list(cluster_stats.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./scan_stats_mar2024.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
