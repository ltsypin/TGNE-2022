---
title: "Gene Filtering for new and improved 2021 TGN"
output: html_notebook
---

## Load libraries and set env
```{r}
setwd("~/git/TGNE-2022/TGNE/microarray_probe_alignment_and_filtering/")
library(geneplotter)
library(RColorBrewer)
library(maSigPro)
library(actuar)
library(fitdistrplus)
library(ggplot2)
library(Hmisc)
library(WGCNA)
options(stringsAsFactors = FALSE)
allowWGCNAThreads()
```

## Filter dataset
First, load unfiltered data
```{r}
unfiltered <- read.csv(
  './agg_tidy_2021aligned_qc_rma_expression_full.csv', 
  row.names = 1
)

unfiltered.sex <- read.csv(
  './agg_tidy_2021aligned_qc_rma_expression_sex.csv',
  row.names = 1
)

unfiltered.starve <- read.csv(
  './agg_tidy_2021aligned_qc_rma_expression_starve.csv',
  row.names = 1
)

unfiltered.grow <- read.csv(
  './agg_tidy_2021aligned_qc_rma_expression_grow.csv',
  row.names = 1
)

unfiltered.veg <- read.csv(
  './agg_tidy_2021aligned_qc_rma_expression_veg.csv',
  row.names = 1
)

head(unfiltered)
head(unfiltered.sex)
head(unfiltered.starve)
head(unfiltered.grow)
head(unfiltered.veg)
```

```{r}
dim(unfiltered)
```

Now, check out simple clustering to see if there are any aberrant batch effects
```{r}
sampleTree = hclust(dist(t(unfiltered)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "unfiltered, all chips", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for growth case
```{r}
sampleTree = hclust(dist(t(unfiltered.grow)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "grow unfiltered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for vegetative case
```{r}
sampleTree = hclust(dist(t(unfiltered.veg)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "veg unfiltered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

The above plots show that Yifan Liu's samples (S0_GSM647651, S0_GSM647652, 
S9_GSM647653, and S9_GSM647654) are uniquely different from the others. All the
others cluster very well according to the physiological phases, beyond the
expermenter. I will exlude Yifan Liu's microarrays from further analyses.

Now, check out simple clustering for sexual case
```{r}
sampleTree = hclust(dist(t(unfiltered.sex)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "sex unfiltered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```
Here's we can see that Ron Pearlman's samples for C12 and C14 (GSM656237 and 
GSM656238) don't quite correspond to Wei Miao's and Marty
Gorovsky's, but it does not seem appropriate to exclude them from the analysis 
because Pearlman's other samples seem well-aligned.

Remove Yifan Liu's chips and write to csv
```{r}
unfiltered.clean <- subset(unfiltered, 
                        select = -c(S0_GSM647651, 
                                    S0_GSM647652, 
                                    S9_GSM647653, 
                                    S9_GSM647654)
                        )

unfiltered.starve.clean <- subset(unfiltered.starve, 
                        select = -c(S0_GSM647651, 
                                    S0_GSM647652, 
                                    S9_GSM647653, 
                                    S9_GSM647654)
                        )

unfiltered.veg.clean <- subset(unfiltered.veg, 
                        select = -c(S0_GSM647651, 
                                    S0_GSM647652, 
                                    S9_GSM647653, 
                                    S9_GSM647654)
                        )

unfiltered.sex.clean <- unfiltered.sex

unfiltered.grow.clean <- unfiltered.grow
```

```{r}
dim(unfiltered.clean)
```

Now, check the vegetative clustering again to see what changed.
```{r}
sampleTree = hclust(dist(t(unfiltered.clean)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "unfiltered clean", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for starvation case
```{r}
sampleTree = hclust(dist(t(unfiltered.starve.clean)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "starve unfiltered clean", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for starvation case
```{r}
sampleTree = hclust(dist(t(unfiltered.sex.clean)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "sex unfiltered clean", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

This is much better!


Visualize histogram of the expression data directly:
```{r}
log.unfiltered.clean = log(unfiltered.clean)
par(mar = c(1, 1, 1, 1))

hist.data.frame(log.unfiltered.clean, main='Log Expression Hist', breaks=sqrt(length(unfiltered.clean)))

# hist(log.unfiltered.clean, main='Log Expression Hist', breaks=sqrt(length(unfiltered.clean)))
```

Now, take a look a some statistics of variation. From the histograms above,
which indicate that the expression data might be log-normally distributed, it
looks like the geometric mean and geometric coefficient of variation may be
the appropriate metrics.
```{r}
wei.range.fun <- function(v) {
        return(max(v) - min(v))
}

maxfold.fun <- function(v) {
        return(max(v) / min(v))
}

geom.mean.fun <- function(v) {
  return(exp(mean(log(v))))
}

geom.cv.fun <- function(v) {
  return(sqrt(exp(sd(log(v))^2)-1))
}

expr.wei.range <- apply(unfiltered.clean, 1, wei.range.fun)
expr.maxfold <- apply(unfiltered.clean, 1, maxfold.fun)
expr.mean <- apply(unfiltered.clean, 1, mean)
expr.geom.mean <- apply(unfiltered.clean, 1, geom.mean.fun)
expr.geom.cv <- apply(unfiltered.clean, 1, geom.cv.fun)
expr.sd <- apply(unfiltered.clean, 1, sd)
expr.cv <- expr.sd / expr.mean
expr.iqr <- apply(unfiltered.clean, 1, IQR)
expr.med <- apply(unfiltered.clean, 1, median)
expr.mad <- apply(unfiltered.clean, 1, mad)

# I want to take genes that change at least four-fold in expression. Let's see
# if this is reasonable
maxfold.ecdf <- ecdf(expr.maxfold)
maxfold.ecdf(4)
```



Visualize histograms of metrics
```{r}
# sizeGrWindow(12,9)
hist(log(expr.geom.mean), main='Geometric mean expression hist', breaks=sqrt(length(expr.geom.mean)))
abline(v=quantile(log(expr.geom.mean), probs=c(0.25)), lwd=1, col='red')
abline(v=median(log(expr.geom.mean)), lwd=1, col='blue')
```

```{r}
# sizeGrWindow(12,9)
hist(log(expr.geom.cv), main='Geometric CV hist', breaks=sqrt(length(expr.geom.cv)))
abline(v=quantile(log(expr.geom.cv), probs=c(0.25)), lwd=1, col='red')
abline(v=median(log(expr.geom.cv)), lwd=1, col='blue')
```

```{r}
# sizeGrWindow(12,9)
hist(log(expr.wei.range), main='Log Wei Range Hist', breaks=sqrt(length(expr.wei.range)))
abline(v=quantile(log(expr.wei.range), probs=c(0.1)), lwd=1, col='red')
abline(v=median(log(expr.wei.range)), lwd=1, col='blue')
```
Interestingly, just correcting against the 2021 genome already removed a lot
of the left (noise) peak, relative to the original analysis.


```{r}
# sizeGrWindow(12,9)
hist(log2(expr.maxfold), main='Log2 Max Fold-change Hist', breaks=sqrt(length(expr.maxfold)))
abline(v=quantile(log2(expr.maxfold), probs=c(maxfold.ecdf(4))), lwd=1, col='red')
abline(v=median(log2(expr.maxfold)), lwd=1, col='blue')
```

```{r}
# sizeGrWindow(12,9)
hist(log(expr.mean), main='Log Mean Expr. Hist', breaks=sqrt(length(expr.mean)))
abline(v=quantile(log(expr.mean), probs=c(0.25)), lwd=1, col='red')
abline(v=median(log(expr.mean)), lwd=1, col='blue')
```


```{r}
# sizeGrWindow(12,9)
hist(log(expr.cv), main='Log CV Hist', breaks=sqrt(length(expr.cv)))
abline(v=quantile(log(expr.cv), probs=c(0.15)), lwd=1, col='red')
abline(v=median(log(expr.cv)), lwd=1, col='blue')
```
It looks like only the absolute range (Wei-range) and mean expression
distributions show clear evidence of noise that should be filtered out.

Now, try to visualize potential filters. First, let's look at mean expression vs. coefficient of 
variation
```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.mean),
                 log(expr.cv),
                 colramp=blues.ramp)
plot(expr.mean, expr.cv, main='Coef. Var. vs. Mean Expr.', log='xy', col=dCol, pch=16, cex=0.1, ylim=c(0.01, 1000))
abline(v=quantile(expr.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(expr.cv, probs=c(0.25)), lwd=1, col='red')

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.geom.mean),
                 log(expr.geom.cv),
                 colramp=blues.ramp)
plot(expr.geom.mean, expr.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr.', log='xy', col=dCol, pch=16, cex=0.1, ylim=c(0.01, 1000))
abline(v=quantile(expr.geom.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(expr.geom.cv, probs=c(0.5)), lwd=1, col='red')

```
This actually already looks very good. The y-axis scales for the two plots are
very different, so it seems that there are some genes that have huge geometric
CVs that are outliers. In both plots, however, there is no apparent irregularity
in dispersion (i.e., there is no apparent heteroskedasticity) to the right of
the 25th percentile mean filter. Some very highly expressed genes seem a very 
low CV. Check below if this is a problem. But it seems that it will be okay to
normalize all the gene expression and be concerned with only the gene
expression patterns after filtering.

We can verify that there aren't weird outlier effects using the interquartile
range and median instead of the CV and mean. The Median Absolute Deviation (MAD) might be more robust than IQR

```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.iqr / expr.med),
                 log(expr.med),
                 colramp=blues.ramp)
plot(expr.med, expr.iqr/expr.med, main='IQR/med vs. med', log='xy', col=dCol, pch=16, cex=0.1, ylim=c(0.01, 1000))
abline(v=quantile(expr.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(expr.iqr/expr.med, probs=c(0.25)), lwd=1, col='red')

# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.mad/expr.med),
                 log(expr.med),
                 colramp=blues.ramp)
plot(expr.med, expr.mad/expr.med, main='MAD/med vs. med', log='xy', col=dCol, pch=16, cex=0.1, ylim=c(0.01, 1000))
abline(v=quantile(expr.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(expr.mad/expr.med, probs=c(0.5)), lwd=1, col='red')
```

We see that the Median Absolute Distance does tighten the dispersion of tje
points more than all the other approaches, which indicates that there are
indeed outlying genes that have a very high variability in their expression.
Nonetheless, all these metrics indicate that it should be possible to filter
and select a subset of genes that is generally non-heteroskedastic.


This helps confirm that a normalization approach will bring all the genes'
expression profiles into the same range without introducing any pathological
transformations. The tail of very highly expressed genes with a very low
spread is still apparent, too. This plot also seems to imply that trying to
use an OR filter to grab genes in the upper left quadrant might not be very
bad either... I think this is a question of whether we want to be greedy for
the number of genes or greedy for the quality of the dataset.


Now, check the absolute range metric
```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.mean),
                 log(expr.wei.range),
                 colramp=blues.ramp)
plot(expr.mean, expr.wei.range, main='Wei Range vs. Mean Expr.', log='xy', col=dCol, pch=16, cex=0.1)
abline(v=quantile(expr.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(expr.wei.range, probs=c(0.1)), lwd=1, col='red')
```
Here, it's clear that the higher the mean expression the greater the range
of expression, which makes sense.


Now, look at max fold-change vs mean
```{r}
# sizeGrWindow(12,9) 
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.geom.mean),
                 log2(expr.maxfold),
                 colramp=blues.ramp)
plot(expr.geom.mean, log2(expr.maxfold), main='Max. Fold Change vs. Geom. Mean Expr.', log='x', col=dCol, pch=16, cex=0.1)
abline(v=quantile(expr.geom.mean, probs=c(0.25)), lwd=1, col='red')
abline(h=quantile(log2(expr.maxfold), probs=c(0.5)), lwd=1, col='red')
```
It looks like the genes with intermediate expression have the highest fold-
change in their expression, which also makes sense: if you have both very
high and very low values, the average will be somewhere in the middle. Looking
at this, if we take the upper left quadrant, we would be taking genes that
have, for example a mean expression of 50 AU and at least a 10-fold maximum
change in expression. It seems plausible that those could be useful genes to
keep.



Now, look at the absolute range vs. fold-change
```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log2(expr.wei.range),
                 log2(expr.maxfold),
                 colramp=blues.ramp)
plot(log2(expr.wei.range), log2(expr.maxfold), main='Max. Fold-change vs. Wei Range', col=dCol, pch=16, cex=0.1)
abline(v=quantile(log2(expr.wei.range), probs=c(0.1)), lwd=1, col='red')
abline(h=quantile(log2(expr.maxfold), probs=c(0.4)), lwd=1, col='red')
```

Now, look at the absolute range vs. coefficient of variation
```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.wei.range),
                 log(expr.cv),
                 colramp=blues.ramp)
plot(expr.wei.range, expr.geom.cv, main='Geom. Coef. Var. vs. Wei Range', log='xy', col=dCol, pch=16, cex=0.1)
abline(v=quantile(expr.wei.range, probs=c(0.1)), lwd=1, col='red')
abline(h=quantile(expr.cv, probs=c(0.5)), lwd=1, col='red')

```

Now, look at the max fold-change vs. coefficient of variation
```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log2(expr.geom.cv),
                 log2(expr.maxfold),
                 colramp=blues.ramp)
plot(log2(expr.geom.cv), log2(expr.maxfold), main='Max. Fold-Change vs. Geom. CV', col=dCol, pch=16, cex=0.1)
abline(v=quantile(log2(expr.geom.cv), probs=c(0.5)), lwd=1, col='red')
abline(h=quantile(log2(expr.maxfold), probs=c(0.5)), lwd=1, col='red')
```
Maximum fold-change and CV are very highly correlated. It looks like, if we
want to be greedy and still get good genes, it makes sense to take ones that
have their maximum fold-change, CV, and IQR/med all above the 50% mark.

It's pretty clear that a fairly stringent (25%) filter for mean expression will give me a very solid dataset on its own.

See what different filtering approaches give
```{r}
# Just the geometric mean
filt.geom.mean <- expr.geom.mean >= quantile(expr.geom.mean, probs=c(0.25))

# Main filter by the mean, but also allow some exceptionally well-behaved
# genes with a low expression
filt.greedy.med.only <- (expr.geom.mean >= quantile(expr.geom.mean, probs=c(0.25))) | ((expr.geom.cv >= quantile(expr.geom.cv, probs=c(0.5))) & (expr.maxfold >= quantile(expr.maxfold, probs=c(0.5))) & expr.iqr/expr.med >= quantile(expr.iqr/expr.med, probs=c(0.5)))

filt.greedy.mad.only <- (expr.geom.mean >= quantile(expr.geom.mean, probs=c(0.5))) | ((expr.geom.cv >= quantile(expr.geom.cv, probs=c(0.5))) & (expr.maxfold >= quantile(expr.maxfold, probs=c(0.5))) & expr.mad/expr.med >= quantile(expr.mad/expr.med, probs=c(0.5)))

filt.greedy <- (expr.geom.mean >= quantile(expr.geom.mean, probs=c(0.25))) | 
  ((expr.geom.cv >= quantile(expr.geom.cv, probs=c(0.5))) & 
     (expr.maxfold >= quantile(expr.maxfold, probs=c(0.5))) &
     (
       expr.iqr/expr.med >= quantile(expr.iqr/expr.med, probs=c(0.5)) |
       expr.mad/expr.med >= quantile(expr.mad/expr.med, probs=c(0.5))
        )
   )

# Take genes by mean and also a CV above a low threshold
filt.geom.mean.cv <- (expr.geom.mean >= quantile(expr.geom.mean, probs=c(0.5))) & (expr.geom.cv >= quantile(expr.geom.cv, probs=c(0.05)))

# filt.range.mean <- (expr.wei.range >= quantile(expr.wei.range, probs=c(0.1))) & (expr.mean >= quantile(expr.mean, probs=c(0.25)))
# 
# filt.fold.mean <- (expr.maxfold >= quantile(expr.maxfold, probs=c(maxfold.ecdf(4))))  & (expr.mean >= quantile(expr.mean, probs=c(0.25)))
# 
# filt.range.fold <- (expr.wei.range >= quantile(expr.wei.range, probs=c(0.1))) & (expr.maxfold >= quantile(expr.maxfold, probs=c(maxfold.ecdf(4))))
# 
# filt.range.cv <- (expr.cv >= quantile(expr.cv, probs=c(0.15))) & (expr.wei.range >= quantile(expr.wei.range, probs=c(0.1)))
# 
# filt.fold.cv <- (expr.cv >= quantile(expr.cv, probs=c(0.15))) & (expr.maxfold >= quantile(expr.maxfold, probs=c(maxfold.ecdf(4))))
```

```{r}
sum(filt.geom.mean)
sum(filt.greedy.med.only)
sum(filt.greedy.mad.only)
sum(filt.greedy)
sum(filt.geom.mean.cv)

# sum(filt.range.mean)
# sum(filt.fold.mean)
# sum(filt.range.fold)
# sum(filt.range.cv)
# sum(filt.fold.cv)

quantile(expr.geom.mean, probs=c(0.25))
quantile(expr.geom.cv, probs=c(0.05))
quantile(expr.geom.cv, probs=c(0.5))
quantile(expr.iqr/expr.med, probs=c(0.5))
quantile(expr.mad/expr.med, probs=c(0.5))
quantile(expr.maxfold, probs=c(0.5))
```



Both filters give something useful, so I am going to combine them with OR
above to make the definitive greedy filter.

It looks like it is safe to be greedy in this case, and maybe even better.


```{r}
filtered <- unfiltered.clean[filt.geom.mean, ]

filtered.expr.geom.mean <- apply(filtered, 1, geom.mean.fun)
# filtered.expr.sd <- apply(filtered, 1, sd)
filtered.expr.geom.cv <- apply(filtered, 1, geom.cv.fun)
filtered.expr.maxfold <- apply(filtered, 1, maxfold.fun)

greedy.filtered <- unfiltered.clean[filt.greedy, ]

greedy.filtered.expr.geom.mean <- apply(greedy.filtered, 1, geom.mean.fun)
# greedy.filtered.expr.sd <- apply(greedy.filtered, 1, sd)
greedy.filtered.expr.geom.cv <- apply(greedy.filtered, 1, geom.cv.fun)
greedy.filtered.expr.maxfold <- apply(greedy.filtered, 1, maxfold.fun)


```

```{r}
# sizeGrWindow(12,9)
hist(log(filtered.expr.geom.mean), main='Log Mean Expr. Hist of geom. mean-filtered expression', breaks=sqrt(length(filtered.expr.geom.mean)))
```

```{r}
hist(log(greedy.filtered.expr.geom.mean), main='Log Mean Expr. Hist of greedily filtered expression', breaks=sqrt(length(filtered.expr.geom.mean)))
```



```{r}
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(filtered.expr.geom.mean),
                 log(filtered.expr.geom.cv),
                 colramp=blues.ramp)
plot(filtered.expr.geom.mean, filtered.expr.geom.cv, main='Geom.Coef. Var. vs. Geom. Mean Expr. of geom. mean-filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4,16), ylim=c(0.01, 500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(greedy.filtered.expr.geom.mean),
                 log(greedy.filtered.expr.geom.cv),
                 colramp=blues.ramp)
plot(greedy.filtered.expr.geom.mean, greedy.filtered.expr.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. of greedily filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4,16), ylim=c(0.01, 500))
```

If you squint, you can see that there is a rectangular corner of points missing
in the lower left of the gene cloud, but it looks like the greedy filter left
a very nice set of genes. The histogram by itself also looks very realistic.


Interestingly, I independently arrived at a similar intensity filter as Wei and
Gorovsky in the 2009 microarray paper 
(http://doi.org/10.1371/journal.pone.0004429), which they got to by subtracting 
3x the average negative control fluorescence (99 AU). My geometric mean expression filter 
is >= 66.6 AU. This gives me confidence that its a reasonable cutoff to use,
especially since I arrived at it by independent means. 

An alternative approach to this kind of filtering would be to identify genes
that have significant changes in their expression over the chips. To do this,
I'll use maSigPro, which is designed to assess changes in gene expresssion from
microarray data over a timecourse. I'll pretend that all the chips correspond
to a time course, even though there are actually three different timecourses
within the dataset.
```{r}
microarray.edesign <- read.csv('./microarray_experiment_design_for_maSigPro.csv',
                              row.names = 1)

microarray.edesign <- subset(microarray.edesign, rownames(microarray.edesign) %in% colnames(unfiltered.clean))
head(microarray.edesign)
```

```{r}
design <- make.design.matrix(microarray.edesign, degree=19)
```

```{r}
# DIFFERENCE OCCURING HERE aarch64-apple-darwin20 (64-bit) vs. x86_64-apple-darwin13.4.0 (64-bit)
fit <- p.vector(unfiltered.clean, design, Q = 0.001, MT.adjust = "BH")
```

```{r}
fit$i # DIFFERENT
de.genes <- rownames(fit$SELEC)
head(fit$SELEC)
```

Now, compare what maSigPro selected to the filter
```{r}
greedy <- names(filt.greedy[filt.greedy])
length(greedy)
length(de.genes)
only.masigpro <- setdiff(de.genes, greedy)
only.greedy <- setdiff(greedy, de.genes)
length(only.masigpro)
length(only.greedy)
```
It looks like there are some real differences. Let's make some plots:

```{r}
masigpro.maxfold <- apply(fit$SELEC, 1, maxfold.fun)
masigpro.geom.mean <- apply(fit$SELEC, 1, geom.mean.fun)
# masigpro.sd <- apply(fit$SELEC, 1, sd)
masigpro.geom.cv <- apply(fit$SELEC, 1, geom.cv.fun)
masigpro.iqr <- apply(fit$SELEC, 1, IQR)
masigpro.med <- apply(fit$SELEC, 1, median)
masigpro.mad <- apply(fit$SELEC, 1, mad)
```

```{r}
hist(log(greedy.filtered.expr.geom.mean), main='Log Mean Expr. Hist of greedily filtered expression', breaks=sqrt(length(filtered.expr.geom.mean)), ylim=c(0, 260))
hist(log(masigpro.geom.mean), main='Log Mean Expr. Hist of maSigPro-filtered expression', breaks=sqrt(length(masigpro.geom.mean)), ylim=c(0, 260))
```

```{r}
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.geom.mean),
                 log(expr.geom.cv),
                 colramp=blues.ramp)
plot(expr.geom.mean, expr.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. (unfiltered)', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4,16), ylim=c(0.01, 500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(greedy.filtered.expr.geom.mean),
                 log(greedy.filtered.expr.geom.cv),
                 colramp=blues.ramp)
plot(greedy.filtered.expr.geom.mean, greedy.filtered.expr.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. of greedily filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4,16), ylim=c(0.01, 500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(masigpro.geom.mean),
                 log(masigpro.geom.cv),
                 colramp=blues.ramp)
plot(masigpro.geom.mean, masigpro.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. of maSigPro-filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4,16), ylim=c(0.01, 500))
```

```{r}
length(only.masigpro)
```

```{r}
length(only.greedy)
```


```{r}
all.good.genes <- union(de.genes, greedy)
length(all.good.genes)
```

```{r}
masigpro.filtered <- subset(unfiltered.clean, rownames(unfiltered.clean) %in% de.genes)
all.good.filtered <- subset(unfiltered.clean, rownames(unfiltered.clean) %in% all.good.genes)
head(masigpro.filtered)
head(all.good.filtered)
```

```{r}
all.good.maxfold <- apply(all.good.filtered, 1, maxfold.fun)
all.good.geom.mean <- apply(all.good.filtered, 1, geom.mean.fun)
# expr.geom.mean <- apply(all.good.filtered, 1, geom.mean.fun)
# all.good.sd <- apply(all.good.filtered, 1, sd)
# all.good.cv <- all.good.sd / all.good.mean
all.good.geom.cv <- apply(all.good.filtered, 1, geom.cv.fun)
all.good.iqr <- apply(all.good.filtered, 1, IQR)
all.good.med <- apply(all.good.filtered, 1, median)
all.good.mad <- apply(all.good.filtered, 1, mad)
```



```{r}
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(expr.geom.mean),
                 log(expr.geom.cv),
                 colramp=blues.ramp)
plot(expr.geom.mean, expr.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. (unfiltered)', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4, 16), ylim=c(0.01,500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(greedy.filtered.expr.geom.mean),
                 log(greedy.filtered.expr.geom.cv),
                 colramp=blues.ramp)
plot(greedy.filtered.expr.geom.mean, greedy.filtered.expr.geom.cv, main='Geom. Coef. Var. vs. geom. Mean Expr. of greedily filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4, 16), ylim=c(0.01,500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(masigpro.geom.mean),
                 log(masigpro.geom.cv),
                 colramp=blues.ramp)
plot(masigpro.geom.mean, masigpro.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. of maSigPro-filtered data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4, 16), ylim=c(0.01,500))

blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(log(all.good.geom.mean),
                 log(all.good.geom.cv),
                 colramp=blues.ramp)
plot(all.good.geom.mean, all.good.geom.cv, main='Geom. Coef. Var. vs. Geom. Mean Expr. of "all good" data', log='xy', col=dCol, pch=16, cex=0.1, xlim=c(4, 16), ylim=c(0.01,500))
```

```{r}
hist(log(greedy.filtered.expr.geom.mean), main='Log Geom. Mean Expr. Hist of greedily filtered expression', breaks=sqrt(length(filtered.expr.geom.mean)), ylim=c(0,250))
hist(log(masigpro.geom.mean), main='Log Geom.Mean Expr. Hist of maSigPro-filtered expression', breaks=sqrt(length(masigpro.geom.mean)), ylim=c(0,250))
hist(log(all.good.geom.mean), main='Log Geom.Mean Expr. Hist of "all good" expression', breaks=sqrt(length(all.good.geom.mean)), ylim=c(0,250))
```
Now, look at all the chips expression histograms
```{r}
par(mar = c(1, 1, 1, 1))
log.masigpro.filtered = log(masigpro.filtered)
hist(log.masigpro.filtered, main='Log Expr. Hist of maSigPro-filtered expression', breaks=sqrt(length(log.masigpro.filtered)), ylim=c(0,250))
```

```{r}
par(mar = c(1, 1, 1, 1))
hist(log(greedy.filtered), main='Log Expr. Hist of "greedy" expression', breaks=sqrt(length(greedy.filtered)), ylim=c(0,250))
```

```{r}
par(mar = c(1, 1, 1, 1))
hist(log(all.good.filtered), main='Log Expr. Hist of "all good" expression', breaks=sqrt(length(all.good.filtered)), ylim=c(0,250))
```
Comparing the chips' histograms themselves, it looks like actually my greedy
filter is doing a better job of achieving approximately log-normal distributions
for the most chips. Not sure if log-normal is really what we should be looking
for here...

It's really not clear whether to go with the original greedy filter
or with the "all good" gene set. MaSigPro likely catches genes that have a low
expression under most conditions, but a high one in some, which leads to the
more bimodal distributions of expression. As always, it's probably best to 
compare the two.

```{r}
filtered <- subset(unfiltered.clean, rownames(unfiltered.clean) %in% greedy)
filtered.sex <- subset(unfiltered.sex.clean, rownames(unfiltered.sex.clean) %in% greedy)
filtered.starve <- subset(unfiltered.starve.clean, rownames(unfiltered.starve.clean) %in% greedy)
filtered.grow <- subset(unfiltered.grow.clean, rownames(unfiltered.grow.clean) %in% greedy)
filtered.veg <- subset(unfiltered.veg.clean, rownames(unfiltered.veg.clean) %in% greedy)

write.csv(filtered, './greedy_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv')
# write.csv(filtered.starve, './greedy_filt_agg_tidy_2021aligned_qc_rma_expression_starve.csv')
# write.csv(filtered.sex, './greedy_filt_agg_tidy_2021aligned_qc_rma_expression_sex.csv')
# write.csv(filtered.grow, './greedy_filt_agg_tidy_2021aligned_qc_rma_expression_grow.csv')
# write.csv(filtered.veg, './greedy_filt_agg_tidy_2021aligned_qc_rma_expression_veg.csv')
head(filtered)
```

```{r}
all.good <- subset(unfiltered.clean, rownames(unfiltered.clean) %in% all.good.genes)
all.good.sex <- subset(unfiltered.sex.clean, rownames(unfiltered.sex.clean) %in% all.good.genes)
all.good.starve <- subset(unfiltered.starve.clean, rownames(unfiltered.starve.clean) %in% all.good.genes)
all.good.grow <- subset(unfiltered.grow.clean, rownames(unfiltered.grow.clean) %in% all.good.genes)
all.good.veg <- subset(unfiltered.veg.clean, rownames(unfiltered.veg.clean) %in% all.good.genes)

all.good <- cbind(RowNames = rownames(all.good), all.good)
rownames(all.good) <- NULL  # Remove row names now that they've been added as a column

colnames(all.good)[1] <- "TTHERM_ID"

write.csv(all.good, '../../active_files/allgood_filt_agg_tidy_2021aligned_qc_rma_expression_full.csv', row.names = FALSE)
# write.csv(all.good.starve, './allgood_filt_agg_tidy_2021aligned_qc_rma_expression_starve.csv')
# write.csv(all.good.sex, './allgood_filt_agg_tidy_2021aligned_qc_rma_expression_sex.csv')
# write.csv(all.good.grow, './allgood_filt_agg_tidy_2021aligned_qc_rma_expression_grow.csv')
# write.csv(all.good.veg, './allgood_filt_agg_tidy_2021aligned_qc_rma_expression_veg.csv')
head(all.good)
```

Now, also make a normalized dataset, where the expression of each gene ranges from zero to one

```{r}
normalizer <- function(vec, df) {
  rname <- row.names((vec))
  v <- as.numeric(vec)
  n <- (v - min(v)) / (max(v) - min(v))
  df[rname ,] <- n
}
```

Create the normalized dataset
```{r}
filtered.norm <- t(apply(filtered, 1, normalizer, filtered))
colnames(filtered.norm) <- colnames(filtered)

filtered.sex.norm <- t(apply(filtered.sex, 1, normalizer, filtered.sex))
colnames(filtered.sex.norm) <- colnames(filtered.sex)

filtered.starve.norm <- t(apply(filtered.starve, 1, normalizer, filtered.starve))
colnames(filtered.starve.norm) <- colnames(filtered.starve)

filtered.grow.norm <- t(apply(filtered.grow, 1, normalizer, filtered.grow))
colnames(filtered.grow.norm) <- colnames(filtered.grow)

filtered.veg.norm <- t(apply(filtered.veg, 1, normalizer, filtered.veg))
colnames(filtered.veg.norm) <- colnames(filtered.veg)
```

Now, check out simple clustering
```{r}
sampleTree = hclust(dist(t(filtered)), method = "average")
sampleTree.norm = hclust(dist(t(filtered.norm)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "filtered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)

# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree.norm, main = "filtered and normalized", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for starvation case
```{r}
sampleTree = hclust(dist(t(filtered.starve)), method = "average")
sampleTree.norm = hclust(dist(t(filtered.starve.norm)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "starvation filtered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)

# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree.norm, main = " starvation filtered and normalized", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```

Now, check out simple clustering for sexual case
```{r}
sampleTree = hclust(dist(t(filtered.sex)), method = "average")
sampleTree.norm = hclust(dist(t(filtered.sex.norm)), method = "average")
```

Plot clustered trees
```{r}
# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "sex filtered", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)

# sizeGrWindow(12,9)
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree.norm, main = "sex filtered and normalized", sub="", xlab="", cex.lab = 1.5,cex.axis = 1.5, cex.main = 2)
```
In general, it looks like the normalization has done its job: the different
chips are now less different from each other, as evidenced by shorter branch
lengths and sizes of sub-trees, but the degrees of clustering of chips
corresponding to the same condition remains basically the same.

Now that the genes have been filtered and normalized, we can save the data

```{r}
# write.csv(filtered.norm, './full_norm_filt_agg_tidy_2021aligned_qc_rma_expression.csv')
# write.csv(filtered.sex.norm, './sex_norm_filt_agg_tidy_2021aligned_qc_rma_expression.csv')
# write.csv(filtered.starve.norm, './starve_norm_filt_agg_tidy_2021aligned_qc_rma_expression.csv')
# write.csv(filtered.grow.norm, './grow_norm_filt_agg_tidy_2021aligned_qc_rma_expression.csv')
# write.csv(filtered.veg.norm, './veg_norm_filt_agg_tidy_2021aligned_qc_rma_expression.csv')
```

Now, I want to checkout what happens if I take the log2 of the expression data
(prior to normalization) to compare to Wei and Jie's analysis:

```{r}
log2.filtered = log2(filtered)

geom.mean.expr.log2 <- apply(log2.filtered, 1, geom.mean.fun)
geom.cv.expr.log2 <- apply(log2.filtered, 1, geom.cv.fun)
# sd.expr.log2 <- apply(log2.filtered, 1, sd)
# cv.expr.log2 <- sd.expr.log2/mean.expr.log2
```

```{r}
# sizeGrWindow(12,9)
blues.ramp <- colorRampPalette(brewer.pal(9,"Blues")[-1])
dCol <- densCols(geom.mean.expr.log2,
                 geom.cv.expr.log2,
                 colramp=blues.ramp)
plot(geom.mean.expr.log2, geom.cv.expr.log2, main='Geom. Coef. Var. vs. Geom. Mean Expr. of log2-transformed greedily filtered data', col=dCol, pch=16, cex=0.1)
# abline(v=quantile(expr.mean, probs=c(0.20)), lwd=1, col='red')
# abline(h=quantile(expr.cv, probs=c(0.05)), lwd=1, col='red')
```

This doesn't look as extreme as it did in my replication of the 2011 analysis,
but it still looks heteroskedastic and doesn't seem to improve anything about
the dataset.

```{r}
sessionInfo()
```
