{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e305761-a971-4232-8a21-5907cfeedfad",
   "metadata": {},
   "source": [
    "## Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9163ea-8dc4-46e8-9542-ba27cc741b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import bokeh\n",
    "from bokeh.plotting import show as show_interactive\n",
    "from bokeh.plotting import output_file, output_notebook\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import CustomJS, TextInput, LassoSelectTool, Select, MultiSelect, ColorBar, Legend, LegendItem\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn, Button, HTMLTemplateFormatter\n",
    "from bokeh.events import SelectionGeometry\n",
    "from bokeh.transform import linear_cmap, jitter\n",
    "from matplotlib.pyplot import show as show_static\n",
    "# from clustergrammer2 import net, Network, CGM2\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "import scipy.stats as st\n",
    "import scipy.spatial\n",
    "import scipy.cluster.hierarchy\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import umap\n",
    "import pymde\n",
    "\n",
    "import torch\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cf4cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23880"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df = pd.read_csv('../../new_raw_data/rna_seq_processed/kallisto.csv')\n",
    "num_genes = full_filtered_df.shape[0]\n",
    "num_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74699d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4494897427831788"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max((full_filtered_df.iloc[:, 1:].to_numpy()).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c04c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.428790564518942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min((full_filtered_df.iloc[:, 1:].to_numpy()).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653c711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>000min</th>\n",
       "      <th>030min</th>\n",
       "      <th>060min</th>\n",
       "      <th>090min</th>\n",
       "      <th>120min</th>\n",
       "      <th>150min</th>\n",
       "      <th>180min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>-1.365347</td>\n",
       "      <td>-1.148579</td>\n",
       "      <td>-0.747968</td>\n",
       "      <td>0.326896</td>\n",
       "      <td>1.162457</td>\n",
       "      <td>1.223924</td>\n",
       "      <td>0.548616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>1.624606</td>\n",
       "      <td>1.127653</td>\n",
       "      <td>-0.375801</td>\n",
       "      <td>-0.049446</td>\n",
       "      <td>-0.968655</td>\n",
       "      <td>-1.415563</td>\n",
       "      <td>0.057206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_000000090</td>\n",
       "      <td>1.142246</td>\n",
       "      <td>-1.681917</td>\n",
       "      <td>-1.085635</td>\n",
       "      <td>0.091523</td>\n",
       "      <td>0.154576</td>\n",
       "      <td>1.283089</td>\n",
       "      <td>0.096118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>1.990007</td>\n",
       "      <td>1.031465</td>\n",
       "      <td>-0.706626</td>\n",
       "      <td>-0.669459</td>\n",
       "      <td>-0.833015</td>\n",
       "      <td>-0.358390</td>\n",
       "      <td>-0.453982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>-0.476728</td>\n",
       "      <td>-0.547781</td>\n",
       "      <td>1.301147</td>\n",
       "      <td>-1.215550</td>\n",
       "      <td>0.859255</td>\n",
       "      <td>-1.091681</td>\n",
       "      <td>1.171338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID    000min    030min    060min    090min    120min  \\\n",
       "0  TTHERM_000000042 -1.365347 -1.148579 -0.747968  0.326896  1.162457   \n",
       "1  TTHERM_000000045  1.624606  1.127653 -0.375801 -0.049446 -0.968655   \n",
       "2  TTHERM_000000090  1.142246 -1.681917 -1.085635  0.091523  0.154576   \n",
       "3   TTHERM_00000010  1.990007  1.031465 -0.706626 -0.669459 -0.833015   \n",
       "4   TTHERM_00000020 -0.476728 -0.547781  1.301147 -1.215550  0.859255   \n",
       "\n",
       "     150min    180min  \n",
       "0  1.223924  0.548616  \n",
       "1 -1.415563  0.057206  \n",
       "2  1.283089  0.096118  \n",
       "3 -0.358390 -0.453982  \n",
       "4 -1.091681  1.171338  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b88f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000min', '030min', '060min', '090min', '120min', '150min', '180min'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_df.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ace6be-7982-4461-bc6e-f49a60b1e56c",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9493def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nns(data_df, nn, metric, random_state=42, n_jobs=-1, p_minkowski=1, distance_matrix=None):\n",
    "    \n",
    "    # if metric == 'clr':\n",
    "    num_neighbors = NearestNeighbors(n_neighbors=nn-1, metric='precomputed', n_jobs=-1).fit(distance_matrix)\n",
    "    nn_dists, nn_idxs = num_neighbors.kneighbors(return_distance=True)\n",
    "\n",
    "    nn_dists_list = []\n",
    "    nn_idxs_list = []\n",
    "\n",
    "    # add the node itself to the nearest neighbors data \n",
    "    for idx in range(len(nn_dists)):\n",
    "        nn_dists_list.append(np.flip(np.append(np.flip(nn_dists[idx]), 0)))\n",
    "        nn_idxs_list.append(np.flip(np.append(np.flip(nn_idxs[idx]), idx)))\n",
    "\n",
    "    return np.array(nn_idxs_list), np.array(nn_dists_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674c6371-69ed-44cd-891b-f9bdcb1ee41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geom_mean_expression(expression_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to take an expression dataframe from the microarrays and collapse it into the means of\n",
    "    all replicate chips.\n",
    "    \"\"\"\n",
    "    # C2 and S12 got removed during quality control\n",
    "    x = [\n",
    "        'Ll', \n",
    "        'Lm', \n",
    "        'Lh', \n",
    "        'S0', \n",
    "        'S3', \n",
    "        'S6', \n",
    "        'S9', \n",
    "        # 'S12', \n",
    "        'S15', \n",
    "        'S24', \n",
    "        'C0', \n",
    "        # 'C2', \n",
    "        'C4', \n",
    "        'C6', \n",
    "        'C8', \n",
    "        'C10', \n",
    "        'C12', \n",
    "        'C14', \n",
    "        'C16', \n",
    "        'C18']\n",
    "    \n",
    "    # cols = expression_df.columns[1:]\n",
    "    # x = [c for c in x if c in cols]\n",
    "    \n",
    "    condition_expr_dict = {c.split(\"_\")[0]: [] for c in expression_df.columns[1:]}\n",
    "    \n",
    "    for c in list(expression_df.columns)[1:]:\n",
    "        \n",
    "        cond = c.split('_')[0]\n",
    "        if cond in condition_expr_dict.keys():\n",
    "            expr_list = condition_expr_dict.get(cond, [])\n",
    "\n",
    "            # Need to avoid true zeros\n",
    "            expr_list.append(expression_df[c].values)\n",
    "            condition_expr_dict[cond] = expr_list\n",
    "        \n",
    "    condition_mean_dict = {c: (st.mstats.gmean(np.array(condition_expr_dict[c]) + 1, 0) - 1) for c in condition_expr_dict.keys() if c in x}\n",
    "    \n",
    "    mean_expr_df = pd.DataFrame(condition_mean_dict)\n",
    "    mean_expr_df['TTHERM_ID'] = expression_df['TTHERM_ID'].values\n",
    "    cols = list(mean_expr_df.columns)\n",
    "    reorder = cols[-1:] + cols[:-1]\n",
    "    mean_expr_df = mean_expr_df[reorder]\n",
    "    \n",
    "    return mean_expr_df\n",
    "\n",
    "def normalizer(array):\n",
    "    \"\"\"\n",
    "    Normalizes the values of an array to range from zero to one\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(array)\n",
    "    \n",
    "    normalized = (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_expression_per_gene(expression_df):\n",
    "    \"\"\"\n",
    "    Function to normalize all gene expression to range from zero to one.\n",
    "    \"\"\"\n",
    "    if 'TTHERM_ID' in expression_df.columns:\n",
    "        ttids = expression_df['TTHERM_ID'].values\n",
    "        data = expression_df[list(expression_df.columns)[1:]]\n",
    "        \n",
    "        norm_expression_df = data.apply(lambda row: normalizer(row), axis=1)\n",
    "        norm_expression_df['TTHERM_ID'] = ttids\n",
    "        \n",
    "        columns = norm_expression_df.columns.tolist()\n",
    "        \n",
    "        rearrangment = columns[-1:] + columns[:-1]\n",
    "        \n",
    "        norm_expression_df = norm_expression_df[rearrangment]\n",
    "        \n",
    "    else:\n",
    "        norm_expression_df = expression_df.apply(lambda row: normalizer(row), axis=1)\n",
    "    \n",
    "    return norm_expression_df\n",
    "    \n",
    "\n",
    "\n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in order of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "    \n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in ortder of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "    \n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in ortder of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "    \n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in ortder of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "    \n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in ortder of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "    \n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    \n",
    "    \n",
    "def run_leiden(df, n_components=2, n_neighbors=3, random_state=42, metric='manhattan', leiden_type='modularity', la_res_param=1.0, return_dists=True):\n",
    "    \"\"\"\n",
    "    Function to compute the simplicial sets for coexpression using UMAP and to then apply\n",
    "    the Leiden algorithm to cluster the resulting graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        the expression data\n",
    "    n_components : int (default 2)\n",
    "        the number of dimensions onto which the data should be projected\n",
    "    n_neighbors : int (default 15)\n",
    "        a parameter for the UMAP algorithm. I think it has to do with balancing\n",
    "        local vs. global topology in the data\n",
    "    random_state : float (default 42)\n",
    "        Constraining this parameter makes the output reproducible\n",
    "    metric : str (default \"euclidean\")\n",
    "        The distance function\n",
    "    return_dists : Bool (default True)\n",
    "        Whether the function should return the computed distances\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    leiden_modules : np array\n",
    "        An array of ints, each corresponding to the module (or cluster) to which a gene belongs,\n",
    "        listed in ortder of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[list(df.columns)[1:]].values\n",
    "\n",
    "    labels_idxs = list(range(data.shape[0]))  \n",
    "\n",
    "#     mapper = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors).fit(data)\n",
    "    \n",
    "    manhattan_distance_matrix = pairwise_distances(data, metric='manhattan', n_jobs=-1)\n",
    "    # nn = NearestNeighbors(n_neighbors=n_neighbors, metric='precomputed', n_jobs=-1).fit(manhattan_distance_matrix)\n",
    "    # nn_dists, nn_idxs = nn.kneighbors(return_distance=True)\n",
    "\n",
    "    nn_idxs, nn_dists = compute_nns(data, n_neighbors, metric, random_state, distance_matrix=manhattan_distance_matrix)\n",
    "    \n",
    "    result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, knn_indices=nn_idxs, knn_dists=nn_dists, return_dists=return_dists)\n",
    "    # result, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(data, n_neighbors, random_state, metric, return_dists=return_dists)\n",
    "\n",
    "\n",
    "    \n",
    "    sources, targets = result.nonzero()\n",
    "    edge_list = zip(sources, targets)\n",
    "    weights = result.data\n",
    "    \n",
    "    g = ig.Graph(edges=edge_list, edge_attrs={'weight': weights})\n",
    "    nx_g = nx.Graph(g.get_edgelist())\n",
    "    \n",
    "    if leiden_type == 'modularity':\n",
    "        partition = la.find_partition(g, la.ModularityVertexPartition, seed=random_state, weights='weight')\n",
    "    elif leiden_type == 'cpm':\n",
    "        partition = la.find_partition(g, la.CPMVertexPartition, resolution_parameter = la_res_param, seed=random_state, weights='weight')\n",
    "    else:\n",
    "        raise ValueError('Invalid value for leiden_type parameter')\n",
    "    leiden_modules = np.array(partition.membership)\n",
    "\n",
    "    communities = {}\n",
    "\n",
    "    for idx, membership in enumerate(leiden_modules):\n",
    "        if membership not in communities:\n",
    "            communities[membership] = []\n",
    "        communities[membership].append(labels_idxs[idx])\n",
    "\n",
    "    sscore = silhouette_score(manhattan_distance_matrix, leiden_modules, metric='precomputed')\n",
    "    modularity = nx.community.quality.modularity(nx_g, communities.values(), weight='weight')\n",
    "    \n",
    "    return leiden_modules, dists, sscore, modularity\n",
    "\n",
    "\n",
    "def build_leiden_label_df(data_df, phases, random_state=42, n_neighbors=3, metric='manhattan', leiden_type='modularity', la_res_param=1.0, lldf=None):\n",
    "    \"\"\"\n",
    "    Function to build a dataframe of genes labeled according to their UMAP/Leiden modules\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_df : pandas DataFrame\n",
    "        The expression data\n",
    "    phases : str ('full', 'veg', or 'sex')\n",
    "        The physiological phases for which expression data is being provided\n",
    "    lldf : pandas DataFrame (default None)\n",
    "        Another leiden label df (lldf) to which to add a column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    lldf : pandas DataFrame\n",
    "        Leiden Label DataFrame. Gene IDs and their corresponding UMAP/Leiden module\n",
    "        computed for a specific physiological regime (full set (full), vegetative only\n",
    "        (veg), or sexual only (sex))\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(lldf) == type(None):\n",
    "        lldf = pd.DataFrame.from_dict({'TTHERM_ID': []})\n",
    "    \n",
    "    leiden_modules, dists, sscore, modularity = run_leiden(data_df, random_state=random_state, n_neighbors=n_neighbors, metric=metric, leiden_type=leiden_type, la_res_param=la_res_param)\n",
    "    lldf['TTHERM_ID'] = data_df['TTHERM_ID'].values\n",
    "    \n",
    "    lldf[f'leiden_label_{phases}'] = leiden_modules\n",
    "    \n",
    "    return lldf, dists, sscore, modularity\n",
    "\n",
    "\n",
    "# The two functions below are taken and adapted from the UMAP package\n",
    "def _get_umap_embedding(umap_object):\n",
    "    if hasattr(umap_object, \"embedding_\"):\n",
    "        return umap_object.embedding_\n",
    "    elif hasattr(umap_object, \"embedding\"):\n",
    "        return umap_object.embedding\n",
    "    else:\n",
    "        raise ValueError(\"Could not find embedding attribute of umap_object\")\n",
    "        \n",
    "def plot_enrichment(enrich_column_data_source):\n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    # y_range = FactorRange(factors=[str(y) for y in enrich_df['module'].unique()])\n",
    "    \n",
    "    # grouped = enrich_df.groupby('module')\n",
    "    \n",
    "    hover = [\n",
    "        ('module', '@module'),\n",
    "        ('term', '@term'),\n",
    "        ('info', '@info'),\n",
    "        ('fold-change', '@fold_change'),\n",
    "        ('bonferroni', '@bonferroni')\n",
    "    ]\n",
    "    \n",
    "    p = bokeh.plotting.figure(\n",
    "        height=1000,\n",
    "        width=400,\n",
    "        # y_range=y_range,\n",
    "        title='Functional term enrichment in modules',\n",
    "        x_axis_label='fold-change',\n",
    "        y_axis_label='module',\n",
    "        x_axis_type='log',\n",
    "        tooltips=hover,\n",
    "        # background_fill_color='black'\n",
    "    )\n",
    "    \n",
    "    # cds = bokeh.models.ColumnDataSource(enrich_df)\n",
    "    # print(enrich_df.head())\n",
    "    \n",
    "    p.circle(y=jitter('module', width=0.4), x='fold_change', source=enrich_column_data_source, alpha=0.3, size=7, color='color', line_color='black')\n",
    "    # p.xaxis.major_label_orientation = 45\n",
    "    p.ygrid.minor_grid_line_color = 'navy'\n",
    "    p.ygrid.minor_grid_line_alpha = 0.1\n",
    "    # p.xgrid.band_fill_alpha = 0.1\n",
    "    # p.xgrid.band_fill_color = \"navy\"\n",
    "    ticker = []\n",
    "    for m in enrich_column_data_source.data['module']:\n",
    "        if m not in ticker:\n",
    "            ticker.append(m)\n",
    "    p.yaxis.ticker = ticker\n",
    "    p.y_range.flipped = True\n",
    "    p.xaxis.major_label_text_font_size = '12pt'\n",
    "    p.yaxis.major_label_text_font_size = '12pt'\n",
    "    p.yaxis.axis_label_text_font_size = '12pt'\n",
    "    p.xaxis.axis_label_text_font_size = '12pt'\n",
    "    \n",
    "    return p\n",
    "\n",
    "def heatmap(column_data_source, ls_color_palette, r_low, r_high, x_axis_factors, y_axis_factors, s_z=\"normalized_expression\", index_name='TTHERM_ID', col_name='phase'):\n",
    "    # adapted from https://gitlab.com/biotransistor/bokehheat/-/blob/master/bokehheat/heat.py\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_matrx: a dataframe in same xy orientation as the final heatmap.\n",
    "          the index should cary the y axis label.\n",
    "          the column should cary the x axis label.\n",
    "          the matrix as such should only cary the z axis values.\n",
    "\n",
    "        ls_color_palette: a list color strings to specify the color spectrum.\n",
    "            this variable is compatible with the ordinary bokeh palettes:\n",
    "            https://bokeh.pydata.org/en/latest/docs/reference/palettes.html\n",
    "\n",
    "        r_low: quantitative minimum value. the dataset can contain lower values,\n",
    "            but for color labeling they will be mapped to this minimum value.\n",
    "            e.g.: -8.\n",
    "\n",
    "        r_high: quantitative maximum value. the dataset can contain lower values,\n",
    "            but for color labeling they will be mapped to this maximum value.\n",
    "            e.g.: 8.\n",
    "\n",
    "        s_z: string. label that specifies what the values in the matrix actually\n",
    "            are. e.g.: 'gene expression [log2]'\n",
    "\n",
    "    output:\n",
    "        p: bokeh plot object.\n",
    "\n",
    "    description:\n",
    "        this function will return a bokeh based interactive heatmap plot.\n",
    "        the color are representing the z value.\n",
    "    \"\"\"\n",
    "    # index as string\n",
    "#     df_matrix.index = df_matrix.index.astype(str)\n",
    "#     df_matrix.columns = df_matrix.columns.astype(str)\n",
    "\n",
    "#     # handle y and x axis name\n",
    "#     if (df_matrix.index.name == None):\n",
    "#         df_matrix.index.name = \"y_axis\"\n",
    "#     if (df_matrix.columns.name == None):\n",
    "#         df_matrix.columns.name = \"x_axis\"\n",
    "    # pdb.set_trace()\n",
    "    s_y = index_name\n",
    "    \n",
    "    # df_matrix.columns.name = 'phase'\n",
    "    s_x = col_name\n",
    "    \n",
    "    \n",
    "    # print(df_matrix.head())\n",
    "    \n",
    "    # melt dataframe\n",
    "    # df_tidy = df_matrix.reset_index().melt(\n",
    "    #     id_vars=[df_matrix.index.name],\n",
    "    #     value_name=s_z\n",
    "    # )\n",
    "    # print(df_tidy.head())\n",
    "    # color declaration\n",
    "    d_zcolormapper = linear_cmap(\n",
    "        field_name=s_z,\n",
    "        palette=ls_color_palette,\n",
    "        low=r_low,\n",
    "        high=r_high\n",
    "    )\n",
    "    # tooltip declaration\n",
    "    lt_tooltip = [\n",
    "        (s_y, f\"@{s_y}\"),\n",
    "        (s_x, f\"@{s_x}\"),\n",
    "        (s_z, f\"@{s_z}\"),\n",
    "        ('module', f'@module')\n",
    "    ]\n",
    "    # generate figure\n",
    "    o_colorbar = ColorBar(color_mapper=d_zcolormapper['transform'])\n",
    "    p = bokeh.plotting.figure(\n",
    "        y_range=y_axis_factors,\n",
    "        x_range=x_axis_factors,\n",
    "        width=400,\n",
    "        height=1000,\n",
    "        tools = \"box_zoom,hover,pan,reset,wheel_zoom,save\",  # have to be set hardcoded\n",
    "        active_drag = \"box_zoom\",  # have to be set hardcoded\n",
    "        tooltips=lt_tooltip,\n",
    "        title=s_z,\n",
    "        toolbar_location='right',\n",
    "        \n",
    "    )\n",
    "    \n",
    "    p.rect(\n",
    "        source=column_data_source,\n",
    "        x=s_x,\n",
    "        y=s_y,\n",
    "        color=d_zcolormapper,\n",
    "        width=1,\n",
    "        height=1,\n",
    "        fill_alpha='fill_alpha',\n",
    "        line_alpha='line_alpha',\n",
    "        # line_color='white',\n",
    "        nonselection_fill_alpha=0.01,\n",
    "        nonselection_line_alpha=0.01,\n",
    "        # nonselection_line_color=\"white\"\n",
    "    )\n",
    "    p.add_layout(o_colorbar, place='left')\n",
    "    # p.yaxis.major_label_orientation = \"horizontal\"\n",
    "    p.xaxis.major_label_orientation = 45\n",
    "    # p.yaxis.major_label_text_font_size = '0pt'\n",
    "    p.yaxis.visible = False\n",
    "    p.xaxis.major_label_text_font_size = '12pt'\n",
    "\n",
    "    # out\n",
    "    return(p)\n",
    "        \n",
    "def interactive(\n",
    "    embedding_df,\n",
    "    x,\n",
    "    # mean_expression_df,\n",
    "    title=None,\n",
    "    labels=None,\n",
    "    values=None,\n",
    "    hover_data=None,\n",
    "    theme=None,\n",
    "    cmap=\"Blues\",\n",
    "    color_key=None,\n",
    "    color_key_cmap=\"Spectral\",\n",
    "    background=\"white\",\n",
    "#     width=800,\n",
    "#     height=800,\n",
    "    point_size=None,\n",
    "    radius=None, # My contribution\n",
    "#     subset_points=None,\n",
    "    interactive_text_search=False,\n",
    "    interactive_text_search_columns=None,\n",
    "    interactive_text_search_alpha_contrast=0.999,\n",
    "    alpha=None,\n",
    "    normalized=True\n",
    "):\n",
    "    \"\"\"Create an interactive bokeh plot of a UMAP embedding.\n",
    "    While static plots are useful, sometimes a plot that\n",
    "    supports interactive zooming, and hover tooltips for\n",
    "    individual points is much more desireable. This function\n",
    "    provides a simple interface for creating such plots. The\n",
    "    result is a bokeh plot that will be displayed in a notebook.\n",
    "    Note that more complex tooltips etc. will require custom\n",
    "    code -- this is merely meant to provide fast and easy\n",
    "    access to interactive plotting.\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_df: pandas DataFrame\n",
    "        A expression dataframe with columns x and y, which are the\n",
    "        2D embedding of a model (e.g., UMAP or pyMDE) on the expression data, and all the\n",
    "        annotations, geometric means of expression, etc.\n",
    "    x: list\n",
    "        The categories for the x-axes of the heatmap and expression profiles\n",
    "    labels: array, shape (n_samples,) (optional, default None)\n",
    "        An array of labels (assumed integer or categorical),\n",
    "        one for each data sample.\n",
    "        This will be used for coloring the points in\n",
    "        the plot according to their label. Note that\n",
    "        this option is mutually exclusive to the ``values``\n",
    "        option.\n",
    "    values: array, shape (n_samples,) (optional, default None)\n",
    "        An array of values (assumed float or continuous),\n",
    "        one for each sample.\n",
    "        This will be used for coloring the points in\n",
    "        the plot according to a colorscale associated\n",
    "        to the total range of values. Note that this\n",
    "        option is mutually exclusive to the ``labels``\n",
    "        option.\n",
    "    hover_data: DataFrame, shape (n_samples, n_tooltip_features)\n",
    "    (optional, default None)\n",
    "        A dataframe of tooltip data. Each column of the dataframe\n",
    "        should be a Series of length ``n_samples`` providing a value\n",
    "        for each data point. Column names will be used for\n",
    "        identifying information within the tooltip.\n",
    "    theme: string (optional, default None)\n",
    "        A color theme to use for plotting. A small set of\n",
    "        predefined themes are provided which have relatively\n",
    "        good aesthetics. Available themes are:\n",
    "           * 'blue'\n",
    "           * 'red'\n",
    "           * 'green'\n",
    "           * 'inferno'\n",
    "           * 'fire'\n",
    "           * 'viridis'\n",
    "           * 'darkblue'\n",
    "           * 'darkred'\n",
    "           * 'darkgreen'\n",
    "    cmap: string (optional, default 'Blues')\n",
    "        The name of a matplotlib colormap to use for coloring\n",
    "        or shading points. If no labels or values are passed\n",
    "        this will be used for shading points according to\n",
    "        density (largely only of relevance for very large\n",
    "        datasets). If values are passed this will be used for\n",
    "        shading according the value. Note that if theme\n",
    "        is passed then this value will be overridden by the\n",
    "        corresponding option of the theme.\n",
    "    color_key: dict or array, shape (n_categories) (optional, default None)\n",
    "        A way to assign colors to categoricals. This can either be\n",
    "        an explicit dict mapping labels to colors (as strings of form\n",
    "        '#RRGGBB'), or an array like object providing one color for\n",
    "        each distinct category being provided in ``labels``. Either\n",
    "        way this mapping will be used to color points according to\n",
    "        the label. Note that if theme\n",
    "        is passed then this value will be overridden by the\n",
    "        corresponding option of the theme.\n",
    "    color_key_cmap: string (optional, default 'Spectral')\n",
    "        The name of a matplotlib colormap to use for categorical coloring.\n",
    "        If an explicit ``color_key`` is not given a color mapping for\n",
    "        categories can be generated from the label list and selecting\n",
    "        a matching list of colors from the given colormap. Note\n",
    "        that if theme\n",
    "        is passed then this value will be overridden by the\n",
    "        corresponding option of the theme.\n",
    "    background: string (optional, default 'white')\n",
    "        The color of the background. Usually this will be either\n",
    "        'white' or 'black', but any color name will work. Ideally\n",
    "        one wants to match this appropriately to the colors being\n",
    "        used for points etc. This is one of the things that themes\n",
    "        handle for you. Note that if theme\n",
    "        is passed then this value will be overridden by the\n",
    "        corresponding option of the theme.\n",
    "    width: int (optional, default 800)\n",
    "        The desired width of the plot in pixels.\n",
    "    height: int (optional, default 800)\n",
    "        The desired height of the plot in pixels\n",
    "    point_size: int (optional, default None)\n",
    "        The size of each point marker\n",
    "    radius: int (optional, default None)\n",
    "        The radius of each point marker (adjusts the point size while zooming)\n",
    "    subset_points: array, shape (n_samples,) (optional, default None)\n",
    "        A way to select a subset of points based on an array of boolean\n",
    "        values.\n",
    "    interactive_text_search: bool (optional, default False)\n",
    "        Whether to include a text search widget above the interactive plot\n",
    "    interactive_text_search_columns: list (optional, default None)\n",
    "        Columns of data source to search. Searches labels and hover_data by default.\n",
    "    interactive_text_search_alpha_contrast: float (optional, default 0.95)\n",
    "        Alpha value for points matching text search. Alpha value for points\n",
    "        not matching text search will be 1 - interactive_text_search_alpha_contrast\n",
    "    alpha: float (optional, default: None)\n",
    "        The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if theme is not None:\n",
    "        cmap = _themes[theme][\"cmap\"]\n",
    "        color_key_cmap = _themes[theme][\"color_key_cmap\"]\n",
    "        background = _themes[theme][\"background\"]\n",
    "\n",
    "    if labels is not None and values is not None:\n",
    "        raise ValueError(\n",
    "            \"Conflicting options; only one of labels or values should be set\"\n",
    "        )\n",
    "        \n",
    "    if alpha is not None:\n",
    "        if not 0.0 <= alpha <= 1.0:\n",
    "            raise ValueError(\"Alpha must be between 0 and 1 inclusive\")\n",
    "\n",
    "    if point_size is None and radius is None:\n",
    "        point_size = 100.0 / np.sqrt(points.shape[0])\n",
    "        \n",
    "    data = embedding_df\n",
    "    # data = data.set_index('TTHERM_ID')\n",
    "    # pdb.set_trace()\n",
    "    if radius is not None:\n",
    "        data['radius'] = radius\n",
    "\n",
    "    if labels is not None:\n",
    "        data[\"label\"] = labels\n",
    "\n",
    "        if color_key is None:\n",
    "            unique_labels = np.unique(labels)\n",
    "            num_labels = unique_labels.shape[0]\n",
    "            color_key = _to_hex(\n",
    "                plt.get_cmap(color_key_cmap)(np.linspace(0, 1, num_labels))\n",
    "            )\n",
    "\n",
    "        if isinstance(color_key, dict):\n",
    "            data[\"color\"] = pd.Series(labels).map(color_key)\n",
    "        else:\n",
    "            # print('here')\n",
    "            unique_labels = np.unique(labels)\n",
    "            if len(color_key) < unique_labels.shape[0]:\n",
    "                # raise ValueError(\n",
    "                #     \"Color key must have enough colors for the number of labels\"\n",
    "                # )\n",
    "                \n",
    "                print('Color key has fewer colors than labels. Making all white')\n",
    "                data['color'] = ['white']*len(labels)\n",
    "            else:\n",
    "\n",
    "                new_color_key = {k: color_key[i] for i, k in enumerate(unique_labels)}\n",
    "                data[\"color\"] = pd.Series(labels).map(new_color_key)\n",
    "\n",
    "        colors = \"color\"\n",
    "\n",
    "    elif values is not None:\n",
    "        data[\"value\"] = values\n",
    "        palette = _to_hex(plt.get_cmap(cmap)(np.linspace(0, 1, 256)))\n",
    "        colors = btr.linear_cmap(\n",
    "            \"value\", palette, low=np.min(values), high=np.max(values)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        colors = matplotlib.colors.rgb2hex(plt.get_cmap(cmap)(0.5))\n",
    "\n",
    "    # print(data['color'].unique())\n",
    "    # print(colors)\n",
    "\n",
    "    if hover_data is not None:\n",
    "        tooltip_dict = {}\n",
    "        for col_name in hover_data:\n",
    "            data[col_name] = hover_data[col_name]\n",
    "            tooltip_dict[col_name] = \"@{\" + col_name + \"}\"\n",
    "        tooltips = list(tooltip_dict.items())\n",
    "    else:\n",
    "        tooltips = None\n",
    "\n",
    "    if alpha is not None:\n",
    "        data[\"alpha\"] = alpha\n",
    "    else:\n",
    "        alpha = 1\n",
    "        data[\"alpha\"] = alpha\n",
    "\n",
    "    data_source = bokeh.plotting.ColumnDataSource(data)\n",
    "    data_source.data['module'] = hover_data['module']\n",
    "    data_source.data['ID'] = hover_data['ID']\n",
    "    data_source.data['radius'] = np.ones_like(hover_data['ID']) * radius\n",
    "    data_source.data['alpha'] = np.ones_like(hover_data['ID']) * alpha\n",
    "    \n",
    "    # print(data_source.data['ID'][:5])\n",
    "\n",
    "    plot = bokeh.plotting.figure(\n",
    "        width=800,\n",
    "        height=500,\n",
    "        tooltips=tooltips,\n",
    "        tools=\"tap,box_select,pan,wheel_zoom,box_zoom,reset,save\",\n",
    "        background_fill_color=background,\n",
    "        title=title\n",
    "#             x_range=(np.floor(min(points[:,0])), np.ceil(max(points[:,0]))), # Get axes\n",
    "#             y_range=(np.floor(min(points[:,1])), np.ceil(max(points[:,1])))\n",
    "    )\n",
    "\n",
    "    if point_size is not None:\n",
    "\n",
    "        plot.circle(\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            source=data_source,\n",
    "            color=colors,\n",
    "            size=point_size,\n",
    "            alpha=\"alpha\",\n",
    "            line_color='black'\n",
    "        )\n",
    "\n",
    "    elif radius is not None:\n",
    "        plot.circle(\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            source=data_source,\n",
    "            color=colors,\n",
    "            radius=radius,\n",
    "            alpha=\"alpha\",\n",
    "            line_color='black'\n",
    "        )\n",
    "\n",
    "    plot.grid.visible = False\n",
    "    plot.axis.visible = False\n",
    "\n",
    "    \n",
    "    x_heatmap_profile = x\n",
    "    \n",
    "    # ['Ll', \n",
    "    #      'Lm', \n",
    "    #      'Lh', \n",
    "    #      'S0', \n",
    "    #      'S3', \n",
    "    #      'S6', \n",
    "    #      'S9', \n",
    "    #      # 'S12', \n",
    "    #      'S15', \n",
    "    #      'S24', \n",
    "    #      'C0', \n",
    "    #      # 'C2', \n",
    "    #      'C4', \n",
    "    #      'C6', \n",
    "    #      'C8', \n",
    "    #      'C10', \n",
    "    #      'C12', \n",
    "    #      'C14', \n",
    "    #      'C16', \n",
    "    #      'C18']\n",
    "    \n",
    "    if normalized:\n",
    "        hm_min = 0\n",
    "        hm_max = 1\n",
    "        \n",
    "    else:\n",
    "        hm_min = 2\n",
    "        hm_max = 16\n",
    "    \n",
    "    # For companion heatmap plot\n",
    "    ttherm_ids = embedding_df['TTHERM_ID'].values\n",
    "    hm_df = embedding_df[['TTHERM_ID'] + x_heatmap_profile]\n",
    "    hm_df['module'] = hover_data['module'].values\n",
    "    hm_df_tidy = hm_df.melt(id_vars=['TTHERM_ID', 'module'], var_name='phase', value_name='normalized_expression')\n",
    "    hm_cds = bokeh.plotting.ColumnDataSource(hm_df_tidy)\n",
    "    hm_cds.data['fill_alpha'] = [0.7]*len(hm_df_tidy)\n",
    "    hm_cds.data['line_alpha'] = [0.7]*len(hm_df_tidy)\n",
    "    # hm_cds.data['y_axis'] = ttherm_ids\n",
    "    \n",
    "    hm = heatmap(hm_cds, bokeh.palettes.Inferno256, hm_min, hm_max, x_heatmap_profile, ttherm_ids)\n",
    "    \n",
    "    \n",
    "\n",
    "    # For companion expression plot\n",
    "\n",
    "    expr_source = bokeh.plotting.ColumnDataSource(dict(\n",
    "        ID=['blah'], \n",
    "        expr_xs=[['Ll']], \n",
    "        expr_ys=[[0]],\n",
    "        alpha=[0],\n",
    "        color=['black']))\n",
    "    \n",
    "    if normalized:\n",
    "        y_axis_label = 'Geometric mean expression of normalized replicates'\n",
    "        y_range = (-0.01, 1.01)\n",
    "        \n",
    "    else:\n",
    "        y_axis_label = 'Geometric mean expression of replicates (log2-scale)'\n",
    "        y_range = (3.9, 16.1)\n",
    "    \n",
    "    expr_fig = bokeh.plotting.figure(width=800, \n",
    "                                     height=500,\n",
    "                                     background_fill_color=background,\n",
    "                                     # x_axis_label='Phase or condition',\n",
    "                                     y_axis_label=y_axis_label,\n",
    "                                     x_range=x_heatmap_profile, \n",
    "                                     y_range=y_range\n",
    "                                    )\n",
    "\n",
    "    expr_fig.multi_line('expr_xs', \n",
    "                        'expr_ys', \n",
    "                        source=expr_source, \n",
    "                        alpha='alpha', \n",
    "                        line_width=3, \n",
    "                        line_join='round',\n",
    "                        line_color=\"color\"\n",
    "                       )\n",
    "\n",
    "    expr_fig.xaxis.major_label_orientation = np.pi/4\n",
    "    expr_fig.xaxis.major_label_text_font_size = '12pt'\n",
    "    expr_fig.yaxis.major_label_text_font_size = '12pt'\n",
    "    expr_fig.yaxis.axis_label_text_font_size = '12pt'\n",
    "    expr_fig.xgrid.grid_line_color='whitesmoke'\n",
    "    expr_fig.xgrid.grid_line_alpha=0.2\n",
    "    expr_fig.ygrid.grid_line_color='whitesmoke'\n",
    "    expr_fig.ygrid.grid_line_alpha=0.2\n",
    "\n",
    "    # For data table\n",
    "    s2 = bokeh.plotting.ColumnDataSource(data=dict(ID=[]))\n",
    "\n",
    "    columns = [TableColumn(field=\"ID\",  title=\"TTHERM_ID\", width=160, formatter=HTMLTemplateFormatter(template='<a href=\"http://tet.ciliate.org/index.php/feature/details/feature_details.php?feature_name=<%= ID %>\"target=\"_blank\"><%= ID %></a>')),\n",
    "               TableColumn(field=\"module\",  title=\"Module\", width=160),\n",
    "               TableColumn(field='TGD2021_description', title='TGD2021_description', width=160),\n",
    "               TableColumn(field=\"Description\", title=\"eggNOG_description\", width=160),\n",
    "               TableColumn(field=\"Preferred_name\", title=\"eggNOG_preferred_name\", width=160),\n",
    "               TableColumn(field=\"max_annot_lvl\", title=\"max_annot_lvl\", width=160),\n",
    "               TableColumn(field=\"COG_category\", title=\"COG_category\", width=160),\n",
    "               TableColumn(field='EC', title='EC', width=160),\n",
    "               TableColumn(field='GOs', title='GOs', width=160),\n",
    "               TableColumn(field='KEGG_ko', title='KEGG_ko', width=160),\n",
    "               TableColumn(field='KEGG_Pathway', title='KEGG_Pathway', width=160),\n",
    "               TableColumn(field='KEGG_Module', title='KEGG_Module', width=160),\n",
    "               TableColumn(field='KEGG_Reaction', title='KEGG_Reaction', width=160),\n",
    "               TableColumn(field='KEGG_rclass', title='KEGG_rclass', width=160),\n",
    "               TableColumn(field='BRITE', title='BRITE', width=160),\n",
    "               TableColumn(field='KEGG_TC', title='KEGG_TC', width=160),\n",
    "               TableColumn(field='CAZy', title='CAZy', width=160),\n",
    "               TableColumn(field='BiGG_Reaction', title='BiGG_Reaction', width=160),\n",
    "#                    TableColumn(field=\"x\",  title=\"x\"),\n",
    "#                    TableColumn(field=\"y\",  title=\"y\")\n",
    "              ]\n",
    "    table = DataTable(source=s2, \n",
    "                      columns=columns, \n",
    "                      width=1600, \n",
    "                      height=500,\n",
    "                      editable=True,\n",
    "                      selectable=True,\n",
    "                      sortable=True,\n",
    "                      index_width=10,\n",
    "                      fit_columns=False,\n",
    "                     )\n",
    "    \n",
    "    heatmap_callback = CustomJS(\n",
    "        args=dict(\n",
    "            s1=data_source,\n",
    "            s_hm=hm_cds,\n",
    "            cols=x_heatmap_profile\n",
    "        ),\n",
    "        code=\"\"\"\n",
    "        var d1 = s1.data;\n",
    "        var d_hm = s_hm.data;\n",
    "        \n",
    "        var inds = s1.selected.indices;\n",
    "        const num_cols = cols.length;\n",
    "        \n",
    "        //d_hm['TTHERM_ID'] = []\n",
    "        //d_hm['normalized_expression'] = []\n",
    "        d_hm['fill_alpha'] = []\n",
    "        d_hm['line_alpha'] = []\n",
    "        \n",
    "        var selected_ttherm_ids = [];\n",
    "        \n",
    "        //Careful here! Number is hardcoded to match the number of genes in dataset EDIT: now it is dynamic)\n",
    "        var ttids = d_hm['TTHERM_ID'].slice(0, \"\"\"+str(num_genes)+\"\"\");\n",
    "        \n",
    "        if (inds.length == 0) {\n",
    "            d_hm['fill_alpha'] = Array(d_hm['TTHERM_ID'].length).fill(0.7)\n",
    "            d_hm['line_alpha'] = Array(d_hm['TTHERM_ID'].length).fill(0.7)\n",
    "        }else{\n",
    "        \n",
    "            // Start with everything deselected\n",
    "            d_hm['fill_alpha'] = Array(d_hm['TTHERM_ID'].length).fill(0.01)\n",
    "            d_hm['line_alpha'] = Array(d_hm['TTHERM_ID'].length).fill(0.01)\n",
    "        \n",
    "            // Get the selected indices\n",
    "            for (var i = 0; i < inds.length; i++) {\n",
    "                selected_ttherm_ids.push(d1['ID'][inds[i]])\n",
    "            }\n",
    "            console.log(selected_ttherm_ids);\n",
    "            \n",
    "            // iterate over the selected ttherm ids\n",
    "            for (var j = 0; j < selected_ttherm_ids.length; j++) {\n",
    "            \n",
    "                // var selected_gene = selected_ttherm_ids[j];\n",
    "                // console.log(selected_gene);\n",
    "\n",
    "                // ad hoc function to find if ttherm ids match\n",
    "                var match = (element) => element == selected_ttherm_ids[j];\n",
    "            \n",
    "                // get index of matching ttherm id in heatmap\n",
    "                var gene_index = ttids.findIndex(match);\n",
    "                console.log(gene_index);\n",
    "                \n",
    "                // loop over the columns and highlight the selected genes\n",
    "                for (var k = 0; k < num_cols; k++) {\n",
    "                \n",
    "                    d_hm['fill_alpha'][gene_index] = 0.7\n",
    "                    d_hm['line_alpha'][gene_index] = 0.7\n",
    "\n",
    "                    gene_index = gene_index + ttids.length\n",
    "                \n",
    "                }\n",
    "            \n",
    "            }\n",
    "            \n",
    "        }\n",
    "        \n",
    "        console.log(d_hm);\n",
    "        \n",
    "        s_hm.change.emit();\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    expression_callback = CustomJS(\n",
    "        args=dict(\n",
    "            s1=data_source,\n",
    "            s_expr=expr_source,\n",
    "            alpha=alpha,\n",
    "        ),\n",
    "        code=\"\"\"\n",
    "        var d1 = s1.data;\n",
    "        var d_expr = s_expr.data;\n",
    "\n",
    "        var inds = s1.selected.indices;\n",
    "        // console.log(inds)\n",
    "\n",
    "        // console.log(d1['ID'].length)\n",
    "\n",
    "        // d1['alpha'] = Array(d1['ID'].length).fill(0.2)\n",
    "\n",
    "        // console.log(d_expr['ID'].length, d_expr['expr_xs'].length, d_expr['expr_ys'].length)\n",
    "\n",
    "        d_expr['ID'] = [['blah']]\n",
    "        d_expr['expr_xs'] = [['Ll']]\n",
    "        d_expr['expr_ys'] = [[0]]\n",
    "        d_expr['alpha'] = [0]\n",
    "        d_expr['color'] = ['black']\n",
    "        // s_expr.change.emit();\n",
    "\n",
    "        // debugger;\n",
    "\n",
    "        for (var i = 0; i < inds.length; i++) {\n",
    "            // d_expr['alpha'][inds[i]] = 1/(inds.length * 2)\n",
    "            // console.log(inds[i], i)\n",
    "            d_expr['ID'].push(Array(18).fill(d1['ID'][inds[i]]))\n",
    "            d_expr['expr_xs'].push(d1['expr_xs'][inds[i]])\n",
    "            d_expr['expr_ys'].push(d1['expr_ys'][inds[i]])\n",
    "            d_expr['alpha'].push(Math.min(1, Math.max(7/(inds.length), 0.05)))\n",
    "            d_expr['color'].push(d1['color'][inds[i]])\n",
    "            // console.log(d_expr)\n",
    "            // console.log(i)\n",
    "            // console.log(\n",
    "            //     d_expr['ID'].length, \n",
    "            //     d_expr['expr_xs'].length, \n",
    "            //     d_expr['expr_ys'].length\n",
    "            // )\n",
    "        }\n",
    "\n",
    "        // s1.change.emit();\n",
    "        s_expr.change.emit();\n",
    "        // console.log(s_expr.data)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    )\n",
    "\n",
    "    selection_callback =  CustomJS(args=dict(\n",
    "                                          s1=data_source, \n",
    "                                          s2=s2,\n",
    "                                          table=table), \n",
    "                                               code=\"\"\"\n",
    "\n",
    "        var d1 = s1.data;\n",
    "        var d2 = s2.data;\n",
    "\n",
    "\n",
    "        var inds = s1.selected.indices;\n",
    "\n",
    "        d2['module'] = []\n",
    "        d2['ID'] = []\n",
    "        d2['TGD2021_description'] = []\n",
    "        d2['Description'] = []\n",
    "        d2['Preferred_name'] = []\n",
    "        d2['max_annot_lvl'] = []\n",
    "        d2['COG_category'] = []\n",
    "        d2['EC'] = []\n",
    "        d2['GOs'] = []\n",
    "        d2['KEGG_ko'] = []\n",
    "        d2['KEGG_Pathway'] = []\n",
    "        d2['KEGG_Module'] = []\n",
    "        d2['KEGG_Reaction'] = []\n",
    "        d2['KEGG_rclass'] = []\n",
    "        d2['BRITE'] = []\n",
    "        d2['KEGG_TC'] = []\n",
    "        d2['CAZy'] = []\n",
    "        d2['BiGG_Reaction'] = []\n",
    "\n",
    "        for (var i = 0; i < inds.length; i++) {\n",
    "            d2['module'].push(d1['module'][inds[i]])\n",
    "            d2['ID'].push(d1['ID'][inds[i]])\n",
    "            d2['TGD2021_description'].push(d1['TGD2021_description'][inds[i]])\n",
    "            d2['Description'].push(d1['Description'][inds[i]])\n",
    "            d2['Preferred_name'].push(d1['Preferred_name'][inds[i]])\n",
    "            d2['max_annot_lvl'].push(d1['max_annot_lvl'][inds[i]])\n",
    "            d2['COG_category'].push(d1['COG_category'][inds[i]])\n",
    "            d2['EC'].push(d1['EC'][inds[i]])\n",
    "            d2['GOs'].push(d1['GOs'][inds[i]])\n",
    "            d2['KEGG_ko'].push(d1['KEGG_ko'][inds[i]])\n",
    "            d2['KEGG_Pathway'].push(d1['KEGG_Pathway'][inds[i]])\n",
    "            d2['KEGG_Module'].push(d1['KEGG_Module'][inds[i]])\n",
    "            d2['KEGG_Reaction'].push(d1['KEGG_Reaction'][inds[i]])\n",
    "            d2['KEGG_rclass'].push(d1['KEGG_rclass'][inds[i]])\n",
    "            d2['BRITE'].push(d1['BRITE'][inds[i]])\n",
    "            d2['KEGG_TC'].push(d1['KEGG_TC'][inds[i]])\n",
    "            d2['CAZy'].push(d1['CAZy'][inds[i]])\n",
    "            d2['BiGG_Reaction'].push(d1['BiGG_Reaction'][inds[i]])\n",
    "        }\n",
    "        s2.change.emit();\n",
    "        table.change.emit();\n",
    "    \"\"\")\n",
    "\n",
    "    data_source.selected.js_on_change('indices', selection_callback, expression_callback, heatmap_callback)\n",
    "\n",
    "    if interactive_text_search:\n",
    "        text_input = TextInput(value=\"Search module(s) or TTHERM_ID(s), e.g. TTHERM_00321680, TTHERM_00313130...\", width=600)\n",
    "\n",
    "        if interactive_text_search_columns is None:\n",
    "            interactive_text_search_columns = []\n",
    "            if hover_data is not None:\n",
    "                interactive_text_search_columns.extend(hover_data.columns)\n",
    "            if labels is not None:\n",
    "                interactive_text_search_columns.append(\"label\")\n",
    "\n",
    "        if len(interactive_text_search_columns) == 0:\n",
    "            warn(\n",
    "                \"interactive_text_search_columns set to True, but no hover_data or labels provided.\"\n",
    "                \"Please provide hover_data or labels to use interactive text search.\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            callback = CustomJS(\n",
    "                args=dict(\n",
    "                    source=data_source,\n",
    "                    s2=s2,\n",
    "                    table=table,\n",
    "                    matching_alpha=interactive_text_search_alpha_contrast,\n",
    "                    non_matching_alpha=1 - interactive_text_search_alpha_contrast,\n",
    "                    search_columns=interactive_text_search_columns,\n",
    "                    default_radius=radius,\n",
    "                    default_alpha=alpha\n",
    "                ),\n",
    "                code=\"\"\"\n",
    "                var data = source.data;\n",
    "                var text_search = cb_obj.value;\n",
    "                var d2 = s2.data;\n",
    "\n",
    "                // var ref_expr = ref_e_s.data;\n",
    "                // var d3 = sel_e_s.data;\n",
    "\n",
    "                var search_terms = text_search.split(',');\n",
    "\n",
    "                d2['module'] = []\n",
    "                d2['ID'] = []\n",
    "\n",
    "                // d3['xs'] = []\n",
    "                // d3['ys'] = []\n",
    "\n",
    "                var search_columns_dict = {}\n",
    "                for (var col in search_columns){\n",
    "                    search_columns_dict[col] = search_columns[col]\n",
    "                }\n",
    "\n",
    "                // First, clear the data table and selection\n",
    "                data['alpha'] = []\n",
    "                data['radius'] = []\n",
    "                source.selected.indices = []\n",
    "\n",
    "                // source.change.emit();\n",
    "                s2.change.emit();\n",
    "                // sel_e_s.change.emit();\n",
    "                table.change.emit();\n",
    "\n",
    "                // Run search\n",
    "                if (text_search.length > 0){\n",
    "                    // Loop over columns and values\n",
    "                    // If there is no match for any column for a given row, change the alpha value\n",
    "                    var string_match = false;\n",
    "                    for (var i = 0; i < data.x.length; i++) {\n",
    "                        string_match = false\n",
    "                        for (var j in search_columns_dict) {\n",
    "                            if (search_terms.some(t => String(data[search_columns_dict[j]][i]).includes(t.trim()))) {\n",
    "                                string_match = true\n",
    "                            }\n",
    "                        }\n",
    "                        if (string_match){\n",
    "                            data['alpha'][i] = matching_alpha\n",
    "                            data['radius'][i] = 1\n",
    "                            d2['module'].push(data['module'][i])\n",
    "                            d2['ID'].push(data['ID'][i])\n",
    "\n",
    "                            // d3['xs'].push(ref_expr['xs'][i])\n",
    "                            // d3['ys'].push(ref_expr['ys'][i])\n",
    "\n",
    "                            // So that these points are actually considered selected\n",
    "                            source.selected.indices.push(i)\n",
    "\n",
    "                        }else{\n",
    "                            data['alpha'][i] = non_matching_alpha\n",
    "                            data['radius'][i] = 0.01\n",
    "                        }\n",
    "                    }\n",
    "                    source.change.emit();\n",
    "                    s2.change.emit();\n",
    "                    // sel_e_s.change.emit();\n",
    "                    table.change.emit();\n",
    "\n",
    "                } else {\n",
    "\n",
    "                    // Loop over columns and values\n",
    "                    // If there is no match for any column for a given row, change the alpha value\n",
    "                    var string_match = false;\n",
    "                    for (var i = 0; i < data.x.length; i++) {\n",
    "                        string_match = false\n",
    "                        for (var j in search_columns_dict) {\n",
    "                            if (search_terms.some(t => String(data[search_columns_dict[j]][i]).includes(t.trim()))) {\n",
    "                                string_match = true\n",
    "                            }\n",
    "                        }\n",
    "                        if (string_match){\n",
    "                            data['alpha'][i] = default_alpha\n",
    "                            data['radius'][i] = default_radius\n",
    "                            d2['module'].push()\n",
    "                            d2['ID'].push()\n",
    "\n",
    "                            // d3['xs'].push()\n",
    "                            // d3['ys'].push()\n",
    "\n",
    "                        }else{\n",
    "                            data['alpha'][i] = non_matching_alpha\n",
    "                            data['radius'][i] = 0.01\n",
    "                        }\n",
    "                    }\n",
    "                    source.change.emit();\n",
    "                    s2.change.emit();\n",
    "                    // sel_e_s.change.emit();\n",
    "                    table.change.emit();\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \"\"\",\n",
    "            )\n",
    "\n",
    "            text_input.js_on_change(\"value\", callback, selection_callback, expression_callback, heatmap_callback)\n",
    "\n",
    "    # Lifted from https://stackoverflow.com/questions/31824124/is-there-a-way-to-save-bokeh-data-table-content\n",
    "    button1 = Button(label=\"Download Annotation Table\", button_type=\"success\", width=550)\n",
    "    button1.js_on_click(\n",
    "        CustomJS(\n",
    "            args=dict(source_data=data_source),\n",
    "            code=\"\"\"\n",
    "            var inds = source_data.selected.indices;\n",
    "            var data = source_data.data;\n",
    "            var out = \"TTHERM_ID\\tmodule\\tTGD2021_description\\teggNOG_description\\teggNOG_preferred_name\\tmax_annot_lvl\\tCOG_category\\tGOs\\tEC\\tKEGG_ko\\tKEGG_Pathway\\tKEGG_Module\\tKEGG_Reaction\\tKEGG_rclass\\tBRITE\\tKEGG_TC\\tCAZy\\tBiGG_Reaction\\\\n\";\n",
    "            for (var i = 0; i < inds.length; i++) {\n",
    "                out += data['ID'][inds[i]] + \"\\t\" + data['module'][inds[i]] + \"\\t\" + data['TGD2021_description'][inds[i]] + \"\\t\" + data['Description'][inds[i]] + \"\\t\" + data['Preferred_name'][inds[i]] + \"\\t\" + data['max_annot_lvl'][inds[i]] + \"\\t\" + data['COG_category'][inds[i]] + \"\\t\" + data['GOs'][inds[i]] + \"\\t\" + data['EC'][inds[i]] + \"\\t\" + data['KEGG_ko'][inds[i]] + \"\\t\" + data['KEGG_Pathway'][inds[i]] + \"\\t\" + data['KEGG_Module'][inds[i]] + \"\\t\" + data['KEGG_Reaction'][inds[i]] + \"\\t\" + data['KEGG_rclass'][inds[i]] + \"\\t\" + data['BRITE'][inds[i]] + \"\\t\" + data['KEGG_TC'][inds[i]] + \"\\t\" + data['CAZy'][inds[i]] + \"\\t\" + data['BiGG_Reaction'][inds[i]] + \"\\\\n\";\n",
    "            }\n",
    "            var file = new Blob([out], {type: 'text/plain'});\n",
    "            var elem = window.document.createElement('a');\n",
    "            elem.href = window.URL.createObjectURL(file);\n",
    "            elem.download = 'selected-annotation-data.tsv';\n",
    "            document.body.appendChild(elem);\n",
    "            elem.click();\n",
    "            document.body.removeChild(elem);\n",
    "            \"\"\"))        \n",
    "    \n",
    "    # NEED TO STOP HARDCODING THIS FILE\n",
    "    enrich_df = pd.read_csv('../enrichment/test_nn3_full_enrichment.csv')\n",
    "    colors = [color_key[int(m)] for m in enrich_df['module'].values]\n",
    "    enrich_df['color'] = colors\n",
    "    \n",
    "    enrich_cds = bokeh.models.ColumnDataSource(enrich_df)\n",
    "    enrich_p = plot_enrichment(enrich_cds)\n",
    "    \n",
    "    button2 = Button(label=\"Download Functional Enrichment Data\", button_type=\"success\", width=450)\n",
    "    button2.js_on_click(\n",
    "        CustomJS(\n",
    "            args=dict(source_data=enrich_cds),\n",
    "            code=\"\"\"\n",
    "            // var inds = source_data.selected.indices;\n",
    "            var data = source_data.data;\n",
    "            var out = \"module\\tterm\\tinfo\\tfold_change\\tbonferroni\\\\n\";\n",
    "            for (var i = 0; i < data['module'].length; i++) {\n",
    "                out += data['module'][i] + \"\\t\" + data['term'][i] + \"\\t\" + data['info'][i] + \"\\t\" + data['fold_change'][i] + \"\\t\" + data['bonferroni'][i] + \"\\\\n\";\n",
    "            }\n",
    "            var file = new Blob([out], {type: 'text/plain'});\n",
    "            var elem = window.document.createElement('a');\n",
    "            elem.href = window.URL.createObjectURL(file);\n",
    "            elem.download = 'enrichment-data.tsv';\n",
    "            document.body.appendChild(elem);\n",
    "            elem.click();\n",
    "            document.body.removeChild(elem);\n",
    "            \"\"\"))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if interactive_text_search:\n",
    "        plot = column(row(column(plot, expr_fig), hm, enrich_p), row(text_input, button1, button2), table)\n",
    "    else:\n",
    "        plot = column(row(column(plot, expr_fig), hm, enrich_p), row(button1, button2), table)\n",
    "\n",
    "    return plot\n",
    "\n",
    "def get_centroid(module_df):\n",
    "    \n",
    "    # get rid of ttherm_ids\n",
    "    data_cols = [c for c in module_df.columns if ('TTHERM' not in c) and ('label' not in c)]\n",
    "    data = module_df[data_cols]\n",
    "    \n",
    "    centroid = data.apply(np.mean, axis=0).values\n",
    "    \n",
    "    return centroid\n",
    "\n",
    "def get_module_centroid_df(expr_df, cluster_label_df, alg, phases):\n",
    "\n",
    "    print(expr_df.columns)\n",
    "    print(cluster_label_df.columns)\n",
    "    \n",
    "    merge = expr_df.merge(cluster_label_df, on='TTHERM_ID')\n",
    "    \n",
    "    grouped = merge.groupby(f'{alg}_label_{phases}')\n",
    "    \n",
    "    centroid_rows = []\n",
    "    \n",
    "    for label, grp_df in grouped:\n",
    "        # print(grp_df.head())\n",
    "        centroid = get_centroid(grp_df)\n",
    "        centroid_rows.append(centroid)\n",
    "    \n",
    "    data_cols = [c for c in merge.columns if ('TTHERM' not in c) and ('label' not in c)]\n",
    "    \n",
    "    centroid_df = pd.DataFrame(centroid_rows)\n",
    "    centroid_df.columns = data_cols\n",
    "    centroid_df.index.rename('module', inplace=True)\n",
    "        \n",
    "    return centroid_df\n",
    "\n",
    "def get_all_module_centroids(expr_df, cluster_label_df, alg, phases):\n",
    "    \n",
    "    merge = expr_df.merge(cluster_label_df, on='TTHERM_ID')\n",
    "    \n",
    "    grouped = merge.groupby(f'{alg}_label_{phases}')\n",
    "    \n",
    "    module_centroid_list = []\n",
    "    \n",
    "    for label, grp_df in grouped:\n",
    "        \n",
    "        centroid = get_centroid(grp_df)\n",
    "        module_centroid_list.append( (label, centroid) )\n",
    "        \n",
    "    return module_centroid_list\n",
    "\n",
    "def arrange_modules(expr_df, cluster_label_df, alg, phases):\n",
    "    \n",
    "    if phases == 'full':\n",
    "        \n",
    "        x = ['Ll', \n",
    "             'Lm', \n",
    "             'Lh', \n",
    "             'S0', \n",
    "             'S3', \n",
    "             'S6', \n",
    "             'S9', \n",
    "             # 'S12',\n",
    "             'S15', \n",
    "             'S24', \n",
    "             'C0', \n",
    "             # 'C2', \n",
    "             'C4', \n",
    "             'C6', \n",
    "             'C8', \n",
    "             'C10', \n",
    "             'C12', \n",
    "             'C14', \n",
    "             'C16', \n",
    "             'C18']\n",
    "        \n",
    "        \n",
    "    elif phases == 'veg':\n",
    "        \n",
    "        x = ['Ll', \n",
    "             'Lm', \n",
    "             'Lh', \n",
    "             'S0', \n",
    "             'S3', \n",
    "             'S6', \n",
    "             'S9', \n",
    "             # 'S12', \n",
    "             'S15', \n",
    "             'S24']\n",
    "        \n",
    "    elif phases == 'sex':\n",
    "        \n",
    "        x = ['C0', \n",
    "             # 'C2', \n",
    "             'C4', \n",
    "             'C6', \n",
    "             'C8', \n",
    "             'C10',\n",
    "             'C12',\n",
    "             'C14', \n",
    "             'C16', \n",
    "             'C18']\n",
    "    \n",
    "    elif phases == 'rna_seq':\n",
    "        x = ['000min', '030min', '060min', '090min', '120min', '150min',\n",
    "       '180min']\n",
    "        \n",
    "    cols = ['TTHERM_ID'] + [c for c in expr_df.columns if c.split('_')[0] in x]\n",
    "\n",
    "    print(expr_df.columns)\n",
    "    \n",
    "    module_centroid_df = get_module_centroid_df(expr_df[cols], cluster_label_df, alg, phases)\n",
    "\n",
    "    print(module_centroid_df)\n",
    "    \n",
    "    linkage = scipy.cluster.hierarchy.linkage(module_centroid_df, method='average', metric='correlation', optimal_ordering=True)\n",
    "    r_cophcorre, ar_copdist = scipy.cluster.hierarchy.cophenet(linkage, scipy.spatial.distance.pdist(module_centroid_df, metric='correlation'))\n",
    "    \n",
    "    # print(f'The Copheretic correlation is: {r_cophcorre}')\n",
    "    \n",
    "    d_dendro = scipy.cluster.hierarchy.dendrogram(linkage, no_plot=True)\n",
    "    cat_sorted = list(module_centroid_df.iloc[d_dendro['leaves'],:].index)\n",
    "    \n",
    "    sorter_index = dict(zip(cat_sorted, range(len(cat_sorted))))\n",
    "    \n",
    "    reassigned_df = cluster_label_df.copy(deep=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    reassigned_df[f'{alg}_label_{phases}'] = reassigned_df[f'{alg}_label_{phases}'].map(sorter_index)\n",
    "    print(len(reassigned_df))\n",
    "    \n",
    "    arranged_dfs = []\n",
    "    \n",
    "    for cat in cat_sorted:\n",
    "        \n",
    "        mini_df = reassigned_df.loc[reassigned_df[f'{alg}_label_{phases}'] == cat]\n",
    "        # gene_count += len(mini_df)\n",
    "\n",
    "        arranged_dfs.append(mini_df)\n",
    "        \n",
    "#     gene_count = 0\n",
    "    \n",
    "#     for mdf in arranged_dfs:\n",
    "#         gene_count += len(mdf)\n",
    "    \n",
    "#     print(gene_count)\n",
    "        \n",
    "    arranged_df = pd.concat(arranged_dfs)\n",
    "    \n",
    "    \n",
    "    return arranged_df\n",
    "\n",
    "def plot_embedding(expression_df, embedding_df, annotation_df, label_df, clust_alg, phases, palette, n_components=2, n_neighbors=15, title=None, random_state=42, radius=0.01, normalized=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to plot the UMAP of expression data.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # get new index for clustered heatmap\n",
    "    label_df = arrange_modules(expression_df, label_df, clust_alg, phases)\n",
    "    \n",
    "    # Weirdly, the heatmap looks better-arranged when I just sort by the modules, as\n",
    "    # given by the hierarchical clustering done by arrange_modules(), than if\n",
    "    # I stay with the order they were given automatically\n",
    "    label_df = label_df.sort_values(by=[f'{clust_alg}_label_{phases}', 'TTHERM_ID'], ascending=False)\n",
    "    new_index = label_df.index\n",
    "    \n",
    "    labels = label_df[f'{clust_alg}_label_{phases}'].values\n",
    "    \n",
    "    data = expression_df[list(expression_df.columns)[1:]].values\n",
    "    \n",
    "    embedding_df['TTHERM_ID'] = expression_df['TTHERM_ID'].values\n",
    "    \n",
    "    merge = expression_df.merge(embedding_df, on='TTHERM_ID')\n",
    "    \n",
    "    merge = merge.reindex(new_index)\n",
    "    \n",
    "    # take part of annotation df that shared TTHERM_IDs with expression df\n",
    "    relevant_annot = annotation_df.iloc[np.in1d(annotation_df['TTHERM_ID'].values, merge['TTHERM_ID'].values)]\n",
    "    merge = merge.merge(relevant_annot, on='TTHERM_ID')\n",
    "    \n",
    "\n",
    "    mean_expression_df = get_geom_mean_expression(merge)\n",
    "    \n",
    "    ttherm_ids = merge['TTHERM_ID'].values\n",
    "    merge = merge.merge(mean_expression_df, on='TTHERM_ID')\n",
    "    \n",
    "    if phases == 'full':\n",
    "        \n",
    "        x = ['Ll', \n",
    "             'Lm', \n",
    "             'Lh', \n",
    "             'S0', \n",
    "             'S3', \n",
    "             'S6', \n",
    "             'S9', \n",
    "             # 'S12',\n",
    "             'S15', \n",
    "             'S24', \n",
    "             'C0', \n",
    "             # 'C2', \n",
    "             'C4', \n",
    "             'C6', \n",
    "             'C8', \n",
    "             'C10', \n",
    "             'C12', \n",
    "             'C14', \n",
    "             'C16', \n",
    "             'C18']\n",
    "        \n",
    "        \n",
    "    elif phases == 'veg':\n",
    "        \n",
    "        x = ['Ll', \n",
    "             'Lm', \n",
    "             'Lh', \n",
    "             'S0', \n",
    "             'S3', \n",
    "             'S6', \n",
    "             'S9', \n",
    "             # 'S12', \n",
    "             'S15', \n",
    "             'S24']\n",
    "        \n",
    "    elif phases == 'sex':\n",
    "        \n",
    "        x = ['C0', \n",
    "             # 'C2', \n",
    "             'C4', \n",
    "             'C6', \n",
    "             'C8', \n",
    "             'C10',\n",
    "             'C12',\n",
    "             'C14', \n",
    "             'C16', \n",
    "             'C18']\n",
    "        \n",
    "    else:\n",
    "        print('Selected phases must be one of full, sex, or veg!')\n",
    "        return\n",
    "\n",
    "    xs = [x for ttid in ttherm_ids]\n",
    "    ys = [merge.loc[merge['TTHERM_ID'] == ttid, x].values[0] for ttid in ttherm_ids]\n",
    "\n",
    "    merge['expr_xs'] = xs\n",
    "    merge['expr_ys'] = ys\n",
    "    \n",
    "    # print(merge.head())\n",
    "\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    hover_data = pd.DataFrame({\n",
    "                               # 'index':np.arange(len(data)),\n",
    "                               'ID':merge['TTHERM_ID'].values,\n",
    "                               'module':[f'm{int(l):02d}' for l in labels]})\n",
    "    \n",
    "#     palette = [palette[l] for l in sorted(label_df[label_key].unique())]\n",
    "    \n",
    "    p = interactive(merge,\n",
    "                    x,\n",
    "                    # mean_expression_df,\n",
    "                    title=title,\n",
    "                    hover_data=hover_data, \n",
    "                    labels=labels, \n",
    "                    color_key=palette, \n",
    "#                     color_key_cmap='Paired',\n",
    "                    background='black', \n",
    "                    radius=radius,\n",
    "                    alpha=0.7,\n",
    "#                     width=600, \n",
    "#                     height=500,\n",
    "                    interactive_text_search=True,\n",
    "                    normalized=normalized\n",
    "                   )\n",
    "    \n",
    "    #p.children[1].title = title\n",
    "    \n",
    "    return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ade6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_test = ['TTHERM_000013409', 'TTHERM_01321550', 'TTHERM_00011710', 'TTHERM_00321680', 'TTHERM_00355700', 'TTHERM_00938950', 'TTHERM_01372820', 'TTHERM_00013410', 'TTHERM_00390080', 'TTHERM_00516380', 'TTHERM_00038880', 'TTHERM_00059370', 'TTHERM_00473020', 'TTHERM_00497590', 'TTHERM_00558350', 'TTHERM_00052190', 'TTHERM_00392790', 'TTHERM_00410180', 'TTHERM_00685980', 'TTHERM_00445920', 'TTHERM_00471040', 'TTHERM_00140780', 'TTHERM_00145480', 'TTHERM_00321720', 'TTHERM_00628650', 'TTHERM_00526730', 'TTHERM_01156770', 'TTHERM_00312200', 'TTHERM_01332070', 'TTHERM_00318900', 'TTHERM_00340180', 'TTHERM_00592740', 'TTHERM_00440600', 'TTHERM_01321570', 'TTHERM_00537380', 'TTHERM_00585170', 'TTHERM_01197130', 'TTHERM_00554390', 'TTHERM_00649180', 'TTHERM_00691410', ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d5a38-541a-4c3a-8288-a8afcf42d7c5",
   "metadata": {},
   "source": [
    "## Define palettes for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd5123-23e9-423e-86b9-68e89a479481",
   "metadata": {},
   "source": [
    "These palettes are from the R package Polychrome. The first is just palette36 with the first color replaced by white. The second is the alphabet palette with white prepended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03ec5e-9520-4a4e-aadb-f7a16d7dd6e6",
   "metadata": {},
   "source": [
    "The R code for 64 colors:\n",
    "\n",
    "library(Polychrome);\n",
    "seed <- c(\"#000000\", \"#ff0000\", \"#00ff00\", \"#0000ff\");\n",
    "p64 <- createPalette(64, seed, range=c(40,100));\n",
    "paste(p64, sep=\"\\n\");\n",
    "\n",
    "Then, replace the first and last with ~white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680b6c31-013d-4611-97e6-78699c22ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette45 = \"\"\"\n",
    "#51635F\\n#FF1C16\\n#16FC26\\n#403DFC\\n#FE0DCE\\n#F9AA00\\n#00FFD5\\n#22BFFE\\n#BB3551\\n#E6FE97\\n#ECADFF\\n#FFBFBD\\n#CF00F5\\n#0D8B00\\n#D7FEFF\\n#8D7200\\n#F76C00\\n#AD3288\\n#5C5AB8\\n#FC0080\\n#B8FF16\\n#00AAB4\\n#FBE11C\\n#9AAAD9\\n#8BBB8C\\n#934B47\\n#6EFE99\\n#9C6D91\\n#FB9778\\n#9D32AF\\n#D40087\\n#FFDC9D\\n#FF8DB6\\n#A96AFC\\n#FDDDFB\\n#168CF7\\n#FD6CF9\\n#F64553\\n#4D6A00\\n#FAFEDB\\n#A7977D\\n#0DFBFF\\n#86B80D\\n#FD8AE4\\n#B7B126\n",
    "\"\"\".split()\n",
    "\n",
    "palette32 = \"\"\"\n",
    "white\\n#F91622\\n#16FC0D\\n#5138FB\\n#FD00CF\\n#FDD51C\\n#16FDD7\\n#FC8B8E\\n#16BFFF\\n#DF9BFD\\n#669C2A\\n#FEE7C4\\n#F31685\\n#DF16FD\\n#C1F1FE\\n#A23D7E\\n#D5FD0D\\n#8C5A0D\\n#FC790D\\n#4F5CBC\\n#FFCBEF\\n#168D72\\n#68FA93\\n#C4FDC9\\n#F7A449\\n#16789B\\n#AD0DAB\\n#C4262E\\n#0DF1FF\\n#EFF994\\n#B6C1FE\\n#8F22CD\n",
    "\"\"\".split()\n",
    "\n",
    "palette35 = \"\"\"\n",
    "#585F6A\\n#FE1626\\n#00FB0D\\n#2E40FC\\n#FD0DCE\\n#FCD200\\n#F7868C\\n#16FFDC\\n#22BEFB\\n#D28EF6\\n#609000\\n#FFE7C9\\n#F51683\\n#FF730D\\n#CAFE16\\n#AA3586\\n#BEEEFD\\n#BD00FA\\n#895D22\\n#FEC7F0\\n#495AA1\\n#73F995\\n#229270\\n#ED963B\\n#F6FE97\\n#C5FFD0\\n#C50DC8\\n#6993FF\\n#C22A35\\n#16ECFC\\n#AA707E\\n#7A3BCB\\n#7C845C\\n#358FAA\\n#BDBAF6\n",
    "\"\"\".split()\n",
    "\n",
    "palette38 = \"\"\"\n",
    "#636265\\n#F60D16\\n#00F90D\\n#3540FB\\n#FD0DD0\\n#FDDB0D\\n#00FFE2\\n#FA8884\\n#2ABEFE\\n#E5A3FF\\n#518F00\\n#FEFDD5\\n#D51CFF\\n#ED007F\\n#A33879\\n#96731C\\n#C8FB16\\n#C0ECFE\\n#FBC1DA\\n#5658BA\\n#F96900\\n#F69F1C\\n#58FA9C\\n#008E72\\n#BA22B9\\n#167D97\\n#794D8A\\n#CEFE9C\\n#BB222E\\n#954D45\\n#00DCEF\\n#FD66B0\\n#B2FDD3\\n#FDBD9F\\n#A9B4F1\\n#B371FE\\n#849566\\n#2A8EFF\n",
    "\"\"\".split()\n",
    "\n",
    "palette64 = \"\"\"\n",
    "white\\n#FA002E\\n#22FC22\\n#221CFA\\n#FF3DD6\\n#FFDA00\\n#00FEFB\\n#F48684\\n#CEB4FE\\n#FFFFE5\\n#0D933D\\n#CC00F8\\n#800D5D\\n#F10084\\n#22267A\\n#0DADFF\\n#CBFD71\\n#9A761C\\n#F96C00\\n#6399A6\\n#FFBCDA\\n#8D0DA3\\n#F79F26\\n#00FFBF\\n#A37CFB\\n#F68EEB\\n#720D0D\\n#F163AA\\n#7E926A\\n#826386\\n#B41C32\\n#9BEBCE\\n#E2DB83\\n#56D4FA\\n#E6E2FB\\n#925D58\\n#F7C3A7\\n#62E970\\n#220DBD\\n#5583BB\\n#7EA01C\\n#CDFDB6\\n#FD00FB\\n#B30D97\\n#F5FF00\\n#DD77FD\\n#4282FC\\n#BBA6A4\\n#0D8068\\n#AB5F26\\n#F7C26E\\n#9EFE00\\n#9B2EFD\\n#C56887\\n#FD3D68\\n#ABF2FD\\n#835FAC\\n#FF16B1\\n#325371\\n#CA16CA\\n#D26322\\n#AFCFFE\\n#91A1FA\\nfloralwhite\n",
    "\"\"\".split()\n",
    "\n",
    "palette65 = \"\"\"\n",
    "white\\ngainsboro\\n#FA002E\\n#22FC22\\n#221CFA\\n#FF3DD6\\n#FFDA00\\n#00FEFB\\n#F48684\\n#CEB4FE\\n#FFFFE5\\n#0D933D\\n#CC00F8\\n#800D5D\\n#F10084\\n#22267A\\n#0DADFF\\n#CBFD71\\n#9A761C\\n#F96C00\\n#6399A6\\n#FFBCDA\\n#8D0DA3\\n#F79F26\\n#00FFBF\\n#A37CFB\\n#F68EEB\\n#720D0D\\n#F163AA\\n#7E926A\\n#826386\\n#B41C32\\n#9BEBCE\\n#E2DB83\\n#56D4FA\\n#E6E2FB\\n#925D58\\n#F7C3A7\\n#62E970\\n#220DBD\\n#5583BB\\n#7EA01C\\n#CDFDB6\\n#FD00FB\\n#B30D97\\n#F5FF00\\n#DD77FD\\n#4282FC\\n#BBA6A4\\n#0D8068\\n#AB5F26\\n#F7C26E\\n#9EFE00\\n#9B2EFD\\n#C56887\\n#FD3D68\\n#ABF2FD\\n#835FAC\\n#FF16B1\\n#325371\\n#CA16CA\\n#D26322\\n#AFCFFE\\n#91A1FA\\nfloralwhite\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8970fc7-8ade-402d-9566-9e16c5593f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette36 = [\"#FFFFFF\", \n",
    "             \"#E4E1E3\", \n",
    "             \"#F6222E\", \n",
    "             \"#FE00FA\", \n",
    "             \"#16FF32\", \n",
    "             \"#3283FE\", \n",
    "             \"#FEAF16\", \n",
    "             \"#B00068\", \n",
    "             \"#1CFFCE\",\n",
    "             \"#90AD1C\", \n",
    "             \"#2ED9FF\", \n",
    "             \"#DEA0FD\", \n",
    "             \"#AA0DFE\", \n",
    "             \"#F8A19F\", \n",
    "             \"#325A9B\", \n",
    "             \"#C4451C\", \n",
    "             \"#1C8356\", \n",
    "             \"#85660D\",\n",
    "             \"#B10DA1\", \n",
    "             \"#FBE426\", \n",
    "             \"#1CBE4F\", \n",
    "             \"#FA0087\", \n",
    "             \"#FC1CBF\", \n",
    "             \"#F7E1A0\", \n",
    "             \"#C075A6\", \n",
    "             \"#782AB6\", \n",
    "             \"#AAF400\",\n",
    "             \"#BDCDFF\", \n",
    "             \"#822E1C\", \n",
    "             \"#B5EFB5\", \n",
    "             \"#7ED7D1\", \n",
    "             \"#1C7F93\", \n",
    "             \"#D85FF7\", \n",
    "             \"#683B79\", \n",
    "             \"#66B0FF\", \n",
    "             \"#3B00FB\",\n",
    "             \"magenta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239a9e1-9b79-4369-8931-8b33f3d5b027",
   "metadata": {},
   "source": [
    "change index 5 to #778899. Change index 9 to #2F4F4F. Add #FF7F50. Change index 9 to #FFBCD9. Change index 14 to #DEA5A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c36e65a-4442-489e-a5ef-de35adb81ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette27 = [\"#FFFFFF\", \n",
    "             \"#AA0DFE\", \n",
    "             \"#3283FE\", \n",
    "             \"#85660D\", \n",
    "             \"#782AB6\", \n",
    "             \"#778899\", \n",
    "             \"#1C8356\", \n",
    "             \"#16FF32\", \n",
    "             \"#F7E1A0\", \n",
    "#              \"#2F4F4F\",\n",
    "             \"#FFBCD9\", \n",
    "             \"#C4451C\", \n",
    "             \"#DEA0FD\", \n",
    "             \"#FE00FA\", \n",
    "#              \"#325A9B\", \n",
    "             \"#FEAF16\", \n",
    "             \"#DEA5A4\", \n",
    "             \"#90AD1C\", \n",
    "             \"#F6222E\",\n",
    "             \"#1CFFCE\", \n",
    "             \"#2ED9FF\", \n",
    "             \"#B10DA1\", \n",
    "#              \"#C075A6\", \n",
    "#              \"#FC1CBF\", \n",
    "#              \"#B00068\", \n",
    "             \"#FBE426\", \n",
    "             \"#FA0087\",\n",
    "             \"#FF7F50\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29defd25-5786-4bca-a782-59b158b7d176",
   "metadata": {},
   "source": [
    "## Round one of plotting and consensus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525b47b-7edf-4ed3-b6e7-4739c399b426",
   "metadata": {},
   "source": [
    "First, cluster accoding to UMAP/Leiden in full-dimensional space, using Manhattan distance and setting the number of neighbors to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03955e5",
   "metadata": {},
   "source": [
    "### LEIDEN MODULARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7938f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_alg = 'leiden'\n",
    "phases = 'rna_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c456b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_label_df_round_1, full_dists, sscore, modularity =  build_leiden_label_df(full_filtered_df, phases, random_state=42, n_neighbors=6, leiden_type='cpm', la_res_param=0.030)\n",
    "# leiden_label_df_round_1, full_dists, sscore, modularity = build_leiden_label_df(full_filtered_df, phases, random_state=42, n_neighbors=3, leiden_type='modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb206dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTHERM_ID</th>\n",
       "      <th>leiden_label_rna_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTHERM_000000042</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTHERM_000000045</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTHERM_000000090</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTHERM_00000010</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTHERM_00000020</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TTHERM_ID  leiden_label_rna_seq\n",
       "0  TTHERM_000000042                   130\n",
       "1  TTHERM_000000045                   661\n",
       "2  TTHERM_000000090                   118\n",
       "3   TTHERM_00000010                   580\n",
       "4   TTHERM_00000020                   789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_label_df_round_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fee6275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leiden_label_df_round_1['leiden_label_rna_seq'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "990fa55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 17,\n",
       " 27,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 21,\n",
       " 11,\n",
       " 15,\n",
       " 14,\n",
       " 21,\n",
       " 17,\n",
       " 20,\n",
       " 27,\n",
       " 20,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 26,\n",
       " 19,\n",
       " 17,\n",
       " 11,\n",
       " 18,\n",
       " 17,\n",
       " 18,\n",
       " 29,\n",
       " 20,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 21,\n",
       " 27,\n",
       " 11,\n",
       " 25,\n",
       " 37,\n",
       " 28,\n",
       " 20,\n",
       " 10,\n",
       " 29,\n",
       " 26,\n",
       " 12,\n",
       " 26,\n",
       " 17,\n",
       " 19,\n",
       " 11,\n",
       " 25,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 23,\n",
       " 19,\n",
       " 23,\n",
       " 34,\n",
       " 12,\n",
       " 8,\n",
       " 19,\n",
       " 27,\n",
       " 15,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 29,\n",
       " 18,\n",
       " 24,\n",
       " 21,\n",
       " 9,\n",
       " 21,\n",
       " 17,\n",
       " 25,\n",
       " 18,\n",
       " 15,\n",
       " 14,\n",
       " 26,\n",
       " 23,\n",
       " 8,\n",
       " 15,\n",
       " 27,\n",
       " 14,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 27,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 20,\n",
       " 19,\n",
       " 16,\n",
       " 11,\n",
       " 18,\n",
       " 21,\n",
       " 25,\n",
       " 19,\n",
       " 23,\n",
       " 6,\n",
       " 19,\n",
       " 26,\n",
       " 8,\n",
       " 20,\n",
       " 19,\n",
       " 21,\n",
       " 15,\n",
       " 33,\n",
       " 22,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 22,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 12,\n",
       " 32,\n",
       " 14,\n",
       " 16,\n",
       " 22,\n",
       " 19,\n",
       " 19,\n",
       " 11,\n",
       " 21,\n",
       " 18,\n",
       " 13,\n",
       " 21,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 11,\n",
       " 30,\n",
       " 18,\n",
       " 21,\n",
       " 7,\n",
       " 34,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 23,\n",
       " 11,\n",
       " 15,\n",
       " 25,\n",
       " 28,\n",
       " 15,\n",
       " 23,\n",
       " 20,\n",
       " 14,\n",
       " 14,\n",
       " 33,\n",
       " 10,\n",
       " 14,\n",
       " 28,\n",
       " 13,\n",
       " 28,\n",
       " 15,\n",
       " 15,\n",
       " 22,\n",
       " 26,\n",
       " 21,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 26,\n",
       " 7,\n",
       " 22,\n",
       " 28,\n",
       " 20,\n",
       " 16,\n",
       " 31,\n",
       " 12,\n",
       " 18,\n",
       " 23,\n",
       " 8,\n",
       " 19,\n",
       " 18,\n",
       " 24,\n",
       " 10,\n",
       " 23,\n",
       " 10,\n",
       " 16,\n",
       " 24,\n",
       " 16,\n",
       " 27,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 17,\n",
       " 20,\n",
       " 11,\n",
       " 12,\n",
       " 18,\n",
       " 25,\n",
       " 22,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 18,\n",
       " 15,\n",
       " 20,\n",
       " 19,\n",
       " 14,\n",
       " 13,\n",
       " 27,\n",
       " 14,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 27,\n",
       " 16,\n",
       " 34,\n",
       " 34,\n",
       " 9,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 22,\n",
       " 22,\n",
       " 13,\n",
       " 4,\n",
       " 12,\n",
       " 28,\n",
       " 17,\n",
       " 31,\n",
       " 24,\n",
       " 46,\n",
       " 15,\n",
       " 18,\n",
       " 11,\n",
       " 29,\n",
       " 22,\n",
       " 19,\n",
       " 17,\n",
       " 14,\n",
       " 11,\n",
       " 29,\n",
       " 23,\n",
       " 38,\n",
       " 24,\n",
       " 11,\n",
       " 25,\n",
       " 36,\n",
       " 26,\n",
       " 16,\n",
       " 17,\n",
       " 11,\n",
       " 20,\n",
       " 17,\n",
       " 14,\n",
       " 20,\n",
       " 12,\n",
       " 11,\n",
       " 25,\n",
       " 14,\n",
       " 23,\n",
       " 19,\n",
       " 17,\n",
       " 33,\n",
       " 21,\n",
       " 17,\n",
       " 22,\n",
       " 18,\n",
       " 18,\n",
       " 10,\n",
       " 15,\n",
       " 14,\n",
       " 21,\n",
       " 18,\n",
       " 21,\n",
       " 23,\n",
       " 29,\n",
       " 29,\n",
       " 11,\n",
       " 16,\n",
       " 23,\n",
       " 9,\n",
       " 18,\n",
       " 20,\n",
       " 31,\n",
       " 15,\n",
       " 30,\n",
       " 26,\n",
       " 12,\n",
       " 11,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 18,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 16,\n",
       " 12,\n",
       " 10,\n",
       " 17,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 20,\n",
       " 17,\n",
       " 14,\n",
       " 9,\n",
       " 20,\n",
       " 13,\n",
       " 16,\n",
       " 19,\n",
       " 26,\n",
       " 18,\n",
       " 17,\n",
       " 24,\n",
       " 19,\n",
       " 13,\n",
       " 21,\n",
       " 5,\n",
       " 20,\n",
       " 23,\n",
       " 21,\n",
       " 23,\n",
       " 18,\n",
       " 14,\n",
       " 7,\n",
       " 28,\n",
       " 5,\n",
       " 22,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 11,\n",
       " 23,\n",
       " 25,\n",
       " 18,\n",
       " 13,\n",
       " 21,\n",
       " 15,\n",
       " 8,\n",
       " 19,\n",
       " 22,\n",
       " 10,\n",
       " 17,\n",
       " 27,\n",
       " 13,\n",
       " 23,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 24,\n",
       " 18,\n",
       " 26,\n",
       " 15,\n",
       " 32,\n",
       " 8,\n",
       " 12,\n",
       " 17,\n",
       " 10,\n",
       " 33,\n",
       " 21,\n",
       " 22,\n",
       " 16,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 28,\n",
       " 20,\n",
       " 12,\n",
       " 25,\n",
       " 12,\n",
       " 27,\n",
       " 11,\n",
       " 17,\n",
       " 24,\n",
       " 17,\n",
       " 33,\n",
       " 23,\n",
       " 17,\n",
       " 12,\n",
       " 12,\n",
       " 19,\n",
       " 24,\n",
       " 12,\n",
       " 13,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 26,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 31,\n",
       " 22,\n",
       " 25,\n",
       " 12,\n",
       " 30,\n",
       " 23,\n",
       " 32,\n",
       " 20,\n",
       " 9,\n",
       " 15,\n",
       " 20,\n",
       " 11,\n",
       " 12,\n",
       " 10,\n",
       " 8,\n",
       " 17,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 18,\n",
       " 30,\n",
       " 7,\n",
       " 19,\n",
       " 20,\n",
       " 24,\n",
       " 13,\n",
       " 13,\n",
       " 32,\n",
       " 23,\n",
       " 24,\n",
       " 13,\n",
       " 23,\n",
       " 8,\n",
       " 15,\n",
       " 28,\n",
       " 14,\n",
       " 18,\n",
       " 14,\n",
       " 16,\n",
       " 22,\n",
       " 15,\n",
       " 21,\n",
       " 11,\n",
       " 19,\n",
       " 14,\n",
       " 15,\n",
       " 26,\n",
       " 22,\n",
       " 14,\n",
       " 21,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 12,\n",
       " 12,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 12,\n",
       " 18,\n",
       " 30,\n",
       " 23,\n",
       " 20,\n",
       " 24,\n",
       " 14,\n",
       " 28,\n",
       " 9,\n",
       " 10,\n",
       " 16,\n",
       " 19,\n",
       " 29,\n",
       " 12,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 11,\n",
       " 13,\n",
       " 21,\n",
       " 15,\n",
       " 25,\n",
       " 13,\n",
       " 14,\n",
       " 21,\n",
       " 21,\n",
       " 27,\n",
       " 21,\n",
       " 16,\n",
       " 18,\n",
       " 12,\n",
       " 14,\n",
       " 22,\n",
       " 25,\n",
       " 13,\n",
       " 20,\n",
       " 10,\n",
       " 9,\n",
       " 34,\n",
       " 17,\n",
       " 7,\n",
       " 27,\n",
       " 16,\n",
       " 14,\n",
       " 12,\n",
       " 28,\n",
       " 13,\n",
       " 19,\n",
       " 25,\n",
       " 20,\n",
       " 21,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 17,\n",
       " 23,\n",
       " 10,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 22,\n",
       " 20,\n",
       " 18,\n",
       " 15,\n",
       " 20,\n",
       " 14,\n",
       " 18,\n",
       " 21,\n",
       " 11,\n",
       " 5,\n",
       " 15,\n",
       " 13,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 25,\n",
       " 12,\n",
       " 12,\n",
       " 21,\n",
       " 27,\n",
       " 10,\n",
       " 19,\n",
       " 21,\n",
       " 15,\n",
       " 22,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 28,\n",
       " 24,\n",
       " 24,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 16,\n",
       " 11,\n",
       " 15,\n",
       " 14,\n",
       " 10,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 15,\n",
       " 8,\n",
       " 13,\n",
       " 19,\n",
       " 18,\n",
       " 23,\n",
       " 29,\n",
       " 11,\n",
       " 8,\n",
       " 38,\n",
       " 11,\n",
       " 12,\n",
       " 18,\n",
       " 20,\n",
       " 13,\n",
       " 20,\n",
       " 28,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 25,\n",
       " 28,\n",
       " 23,\n",
       " 19,\n",
       " 23,\n",
       " 16,\n",
       " 23,\n",
       " 8,\n",
       " 19,\n",
       " 23,\n",
       " 17,\n",
       " 11,\n",
       " 29,\n",
       " 23,\n",
       " 14,\n",
       " 18,\n",
       " 31,\n",
       " 27,\n",
       " 30,\n",
       " 12,\n",
       " 26,\n",
       " 17,\n",
       " 14,\n",
       " 12,\n",
       " 21,\n",
       " 23,\n",
       " 15,\n",
       " 22,\n",
       " 23,\n",
       " 12,\n",
       " 18,\n",
       " 32,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 12,\n",
       " 29,\n",
       " 19,\n",
       " 22,\n",
       " 26,\n",
       " 25,\n",
       " 21,\n",
       " 13,\n",
       " 30,\n",
       " 22,\n",
       " 15,\n",
       " 10,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 24,\n",
       " 16,\n",
       " 16,\n",
       " 23,\n",
       " 17,\n",
       " 20,\n",
       " 23,\n",
       " 16,\n",
       " 11,\n",
       " 28,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 17,\n",
       " 21,\n",
       " 21,\n",
       " 13,\n",
       " 25,\n",
       " 14,\n",
       " 10,\n",
       " 27,\n",
       " 14,\n",
       " 21,\n",
       " 16,\n",
       " 20,\n",
       " 25,\n",
       " 16,\n",
       " 18,\n",
       " 33,\n",
       " 9,\n",
       " 32,\n",
       " 10,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 30,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 13,\n",
       " 12,\n",
       " 23,\n",
       " 15,\n",
       " 16,\n",
       " 25,\n",
       " 21,\n",
       " 10,\n",
       " 18,\n",
       " 26,\n",
       " 25,\n",
       " 22,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 15,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 20,\n",
       " 20,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 19,\n",
       " 15,\n",
       " 19,\n",
       " 14,\n",
       " 18,\n",
       " 11,\n",
       " 18,\n",
       " 25,\n",
       " 21,\n",
       " 21,\n",
       " 26,\n",
       " 6,\n",
       " 10,\n",
       " 22,\n",
       " 26,\n",
       " 27,\n",
       " 12,\n",
       " 21,\n",
       " 20,\n",
       " 25,\n",
       " 13,\n",
       " 17,\n",
       " 7,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 28,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 27,\n",
       " 17,\n",
       " 24,\n",
       " 25,\n",
       " 21,\n",
       " 19,\n",
       " 30,\n",
       " 9,\n",
       " 17,\n",
       " 29,\n",
       " 18,\n",
       " 20,\n",
       " 16,\n",
       " 13,\n",
       " 21,\n",
       " 25,\n",
       " 28,\n",
       " 13,\n",
       " 12,\n",
       " 19,\n",
       " 9,\n",
       " 22,\n",
       " 20,\n",
       " 12,\n",
       " 20,\n",
       " 26,\n",
       " 16,\n",
       " 16,\n",
       " 30,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 12,\n",
       " 22,\n",
       " 23,\n",
       " 29,\n",
       " 27,\n",
       " 20,\n",
       " 15,\n",
       " 37,\n",
       " 13,\n",
       " 21,\n",
       " 23,\n",
       " 23,\n",
       " 18,\n",
       " 14,\n",
       " 29,\n",
       " 13,\n",
       " 8,\n",
       " 23,\n",
       " 13,\n",
       " 16,\n",
       " 14,\n",
       " 18,\n",
       " 24,\n",
       " 14,\n",
       " 12,\n",
       " 9,\n",
       " 19,\n",
       " 14,\n",
       " 13,\n",
       " 20,\n",
       " 18,\n",
       " 28,\n",
       " 13,\n",
       " 13,\n",
       " 18,\n",
       " 21,\n",
       " 16,\n",
       " 5,\n",
       " 15,\n",
       " 15,\n",
       " 27,\n",
       " 25,\n",
       " 30,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 23,\n",
       " 15,\n",
       " 13,\n",
       " 7,\n",
       " 17,\n",
       " 27,\n",
       " 18,\n",
       " 36,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 9,\n",
       " 18,\n",
       " 25,\n",
       " 16,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 8,\n",
       " 16,\n",
       " 13,\n",
       " 17,\n",
       " 11,\n",
       " 15,\n",
       " 28,\n",
       " 28,\n",
       " 15,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 22,\n",
       " 14,\n",
       " 21,\n",
       " 20,\n",
       " 18,\n",
       " 14,\n",
       " 10,\n",
       " 24,\n",
       " 8,\n",
       " 18,\n",
       " 13,\n",
       " 11,\n",
       " 21,\n",
       " 12,\n",
       " 19,\n",
       " 12,\n",
       " 20,\n",
       " 7,\n",
       " 26,\n",
       " 12,\n",
       " 22,\n",
       " 12,\n",
       " 16,\n",
       " 22,\n",
       " 28,\n",
       " 18,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 13,\n",
       " 17,\n",
       " 24,\n",
       " 24,\n",
       " 10,\n",
       " 22,\n",
       " 15,\n",
       " 7,\n",
       " 14,\n",
       " 23,\n",
       " 14,\n",
       " 17,\n",
       " 7,\n",
       " 26,\n",
       " 21,\n",
       " 24,\n",
       " 10,\n",
       " 8,\n",
       " 17,\n",
       " 10,\n",
       " 22,\n",
       " 24,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 14,\n",
       " 21,\n",
       " 6,\n",
       " 29,\n",
       " 14,\n",
       " 5,\n",
       " 18,\n",
       " 13,\n",
       " 22,\n",
       " 8,\n",
       " 13,\n",
       " 13,\n",
       " 18,\n",
       " 26,\n",
       " 19,\n",
       " 24,\n",
       " 9,\n",
       " 24,\n",
       " 12,\n",
       " 18,\n",
       " 21,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 25,\n",
       " 13,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 18,\n",
       " 12,\n",
       " 10,\n",
       " 24,\n",
       " 17,\n",
       " 34,\n",
       " 16,\n",
       " 13,\n",
       " 35,\n",
       " 17,\n",
       " 21,\n",
       " 11,\n",
       " 17,\n",
       " 12,\n",
       " 20,\n",
       " 33,\n",
       " 19,\n",
       " 26,\n",
       " 19,\n",
       " 20,\n",
       " 15,\n",
       " 16,\n",
       " 25,\n",
       " 17,\n",
       " 14,\n",
       " 23,\n",
       " 15,\n",
       " 12,\n",
       " 8,\n",
       " 13,\n",
       " 16,\n",
       " 32,\n",
       " 20,\n",
       " 18,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 21,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 7,\n",
       " 25,\n",
       " 25,\n",
       " 11,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 18,\n",
       " 10,\n",
       " 18,\n",
       " 17,\n",
       " 23,\n",
       " 14,\n",
       " 22,\n",
       " 17,\n",
       " 19,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes = []\n",
    "unique_clusters = leiden_label_df_round_1['leiden_label_rna_seq'].unique()\n",
    "for uc in unique_clusters:\n",
    "    cluster_sizes.append(np.count_nonzero(leiden_label_df_round_1['leiden_label_rna_seq'].values == uc))\n",
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff47d19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cluster_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a4c1d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cluster_sizes, 46)\n",
    "plt.ylabel('num_clusters')\n",
    "plt.xlabel('cluster_sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8d5fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TTHERM_ID', '000min', '030min', '060min', '090min', '120min', '150min',\n",
      "       '180min'],\n",
      "      dtype='object')\n",
      "Index(['TTHERM_ID', '000min', '030min', '060min', '090min', '120min', '150min',\n",
      "       '180min'],\n",
      "      dtype='object')\n",
      "Index(['TTHERM_ID', 'leiden_label_rna_seq'], dtype='object')\n",
      "          000min    030min    060min    090min    120min    150min    180min\n",
      "module                                                                      \n",
      "0      -0.012576  1.559190  1.178600 -0.167043 -1.094590 -1.280810 -0.182772\n",
      "1      -2.024280  0.107790  1.351588  0.606521  0.200007  0.097429 -0.339056\n",
      "2       2.091425  0.652772 -0.033135 -0.378930 -0.628726 -0.646577 -1.056830\n",
      "3      -0.496672 -1.265000 -1.018915 -0.226250  0.542893  1.751200  0.712744\n",
      "4      -0.705838  1.221493  1.449284  0.496324 -0.330703 -1.088274 -1.042286\n",
      "...          ...       ...       ...       ...       ...       ...       ...\n",
      "1361    1.301297  1.131397  0.402669  0.437328 -1.053609 -1.272003 -0.947080\n",
      "1362   -1.927628 -0.628173  0.537052  1.136927  1.048328  0.171967 -0.338472\n",
      "1363    2.287146 -0.769286 -0.742492  0.261454 -0.172522 -0.654887 -0.209414\n",
      "1364   -1.443043 -1.011303  0.658667  1.128072  1.096777  0.425489 -0.854659\n",
      "1365   -0.051170 -2.086102 -0.465828  0.266154  0.929060  1.169945  0.237941\n",
      "\n",
      "[1366 rows x 7 columns]\n",
      "23880\n"
     ]
    }
   ],
   "source": [
    "leiden_label_df_round_1_arranged = arrange_modules(full_filtered_df, leiden_label_df_round_1, clust_alg, phases) \n",
    "leiden_label_df_round_1_arranged_sorted = leiden_label_df_round_1.sort_values(by=[f'{clust_alg}_label_{phases}', 'TTHERM_ID'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30ff03ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0831550305635297, 0.6445742228289906)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sscore, modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6a0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_label_df_round_1_arranged_sorted.to_csv('./test_nn3_leiden_label_df_round_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e4781",
   "metadata": {},
   "source": [
    "### LEIDEN CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leiden_label_df_cpms = {}\n",
    "\n",
    "# la_res_params = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 1]\n",
    "\n",
    "# print(la_res_params)\n",
    "\n",
    "# for curr_la_res_param in la_res_params:\n",
    "#     leiden_label_df_cpm, full_dists_cpm, cpm_sscore, cpm_modularity = build_leiden_label_df(full_filtered_norm_df, 'full', random_state=42, n_neighbors=5, leiden_type='cpm', la_res_param=curr_la_res_param)\n",
    "#     leiden_label_df_cpm_sorted = leiden_label_df_cpm.sort_values(by='leiden_label_full')\n",
    "#     print(curr_la_res_param, 'generated', max(list(leiden_label_df_cpm_sorted['leiden_label_full'].values))+1, 'clusters.')\n",
    "#     leiden_label_df_cpms[curr_la_res_param] = leiden_label_df_cpm_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leiden_clustering_df_to_csv(df, export_file_path):\n",
    "    current_module = list(df['leiden_label_full'].values)[0]\n",
    "\n",
    "    new_cluster = True\n",
    "\n",
    "    with open(export_file_path, 'w') as f:\n",
    "        for idx, row in df.iterrows():\n",
    "            if current_module != row['leiden_label_full']:\n",
    "                current_module = row['leiden_label_full']\n",
    "                f.write('\\n')\n",
    "                new_cluster =True\n",
    "\n",
    "            elif not new_cluster:\n",
    "                f.write('\\t')\n",
    "            \n",
    "            f.write(row['TTHERM_ID'])\n",
    "            new_cluster = False\n",
    "\n",
    "        f.write('\\n')\n",
    "    \n",
    "    print(export_file_path, 'successfully exported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leiden_clustering_df_to_csv(leiden_label_df_round_1_sorted, './leiden_clustering.labels')\n",
    "\n",
    "# for la_param, df in leiden_label_df_cpms.items():\n",
    "#     leiden_clustering_df_to_csv(df, f'./leiden_clustering_cpm_{str(la_param)}.labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./leiden_clustering.labels', 'r') as f:\n",
    "#     num_leiden_clusters = f.readlines()\n",
    "#     print(len(num_leiden_clusters))\n",
    "\n",
    "# print(max(list(leiden_label_df_round_1_sorted['leiden_label_full'].values)) + 1) # module numbering starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0f4ee4d-b47e-4e5d-883b-f30c9a90dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcl_mcl_df.to_csv('./test_nn3_leiden_label_df_round_1_rearranged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf55445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55189b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcl_mcl_df = pd.read_csv('./mcl_rcl/mcl_rcl_label_df_round_1.csv')\n",
    "# rcl_mcl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25666f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gene in gene_list_test:\n",
    "#     print((rcl_mcl_df.loc[rcl_mcl_df['TTHERM_ID'] == gene])['leiden_label_full'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clust_alg = 'leiden'\n",
    "# phases = 'full'\n",
    "\n",
    "# arranged_rcl_mcl_df = arrange_modules(full_filtered_norm_df, rcl_mcl_df, clust_alg, phases) \n",
    "# sorted_rcl_mcl_df = arranged_rcl_mcl_df.sort_values(by=[f'{clust_alg}_label_{phases}', 'TTHERM_ID'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arranged_rcl_mcl_df.loc[arranged_rcl_mcl_df['TTHERM_ID'] == 'TTHERM_00000040']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_rcl_mcl_df.loc[sorted_rcl_mcl_df['TTHERM_ID'] == 'TTHERM_00000040']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91b739eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_rcl_mcl_df.to_csv('./mcl_rcl_label_df_round_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73c2c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange_modules(full_filtered_norm_df, rcl_mcl_df, 'leiden', 'full')['leiden_label_full'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d79a58-e289-445f-a3f5-abeb9b6b87cd",
   "metadata": {},
   "source": [
    "#### Go to ../enrichment/enrichment.ipynb to generate the functional annotation enrichment data from this clustering. Proceed once done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
