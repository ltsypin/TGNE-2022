{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = ['clr', 'manhattan', 'euclidean', 'cosine'] + [f'minkowski_{str(p)}' for p in np.array([0.5, 1, 2, 3, 4, 5])]\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually curated metrics + metrics refered to in the documentation\n",
    "all_doc_metrics = ['angular', 'clr'] + ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan'] + ['nan_euclidean'] + ['braycurtis', 'canberra', 'chebyshev', 'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']\n",
    "# manually curated metrics + metrics refered to in metric parameter ValueError (sklearn documentation is likely not updated)\n",
    "all_metrics = ['angular', 'clr'] + ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine']\n",
    "# metrics that covert data to boolean (essentially destroying all information for our data) (20 clusters are always produced with the same exact size)\n",
    "boolean_metrics = [\n",
    "'dice',\n",
    "'jaccard',\n",
    "'rogerstanimoto',\n",
    "'russellrao',\n",
    "'sokalmichener',\n",
    "'sokalsneath',\n",
    "'yule',\n",
    "]\n",
    "orig_metrics = ['clr', 'manhattan', 'euclidean', 'cosine'] + [f'minkowski_{str(p)}' for p in np.array([0.5, 1, 2, 3, 4, 5])]\n",
    "# metrics = [sys.argv[1]]\n",
    "metrics = [m for m in all_metrics if m not in orig_metrics + boolean_metrics and m[: len('minkowski')] != 'minkowski']\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([m for m in all_metrics if m not in boolean_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[m for m in all_metrics + orig_metrics if m not in boolean_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [m for m in all_metrics + orig_metrics if m not in boolean_metrics] + ['clr_lev']\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nns = np.arange(2, 13, 1)\n",
    "nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['microarray', 'rna_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_types = ['EXP', 'NC', 'TNC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition_type in partition_types:\n",
    "    for dataset in datasets:\n",
    "        for metric in metrics:\n",
    "            for nn in nns:\n",
    "\n",
    "                sbatch_str = f'''#!/bin/bash\n",
    "    #SBATCH --job-name=run_scan_{metric}_{nn}_{dataset}_{partition_type}\n",
    "    #SBATCH --account=pi-apturkew\n",
    "    #SBATCH --partition=broadwl\n",
    "    #SBATCH --ntasks-per-node=1\n",
    "    #SBATCH --cpus-per-task=20\n",
    "    #SBATCH --mem-per-cpu=2000\n",
    "    ##SBATCH --output=myjob_%j.out      # Standard output log\n",
    "    ##SBATCH --error=myjob_%j.err       # Standard error log\n",
    "    #SBATCH --mail-type=ALL\n",
    "    #SBATCH --mail-user=bertagna@rcc.uchicago.edu\n",
    "\n",
    "\n",
    "\n",
    "    source activate tgne_all.env\n",
    "\n",
    "    cmd=\"python3 fast_scan_modular_metrics.py {dataset} {metric} {nn} {partition_type}\"\n",
    "\n",
    "    echo $cmd\n",
    "\n",
    "    eval $cmd\n",
    "    '''         \n",
    "                tags = [dataset, metric, nn, partition_type]\n",
    "                output_file = f'./TGNE/clustering_optimization/{\"_\".join([str(tag) for tag in tags])}.sbatch'\n",
    "                with open(output_file, 'w') as f:\n",
    "                    f.write(sbatch_str)\n",
    "                    print('FILE CREATED:', output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
